{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3ba30f21",
   "metadata": {},
   "source": [
    "!pip install tensorflow\n",
    "!pip install -q git+https://github.com/tensorflow/docs\n",
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f618ccd3",
   "metadata": {},
   "source": [
    "https://keras.io/examples/generative/conditional_gan/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15277642",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de75ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 13:07:55.679536: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-24 13:07:56.237185: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow_docs.vis import embed\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b9add1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c756a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_channels = 1\n",
    "num_classes = 10\n",
    "image_size = 28\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa590d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 13:07:57.431552: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 13:07:57.445928: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 13:07:57.446100: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 13:07:57.447376: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 13:07:57.447517: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 13:07:57.447638: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 13:07:57.504015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 13:07:57.504198: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 13:07:57.504328: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 13:07:57.504425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9475 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (70000, 28, 28, 1)\n",
      "Shape of training labels: (70000, 10)\n"
     ]
    }
   ],
   "source": [
    "# We'll use all the available examples from both the training and test\n",
    "# sets.\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "all_digits = np.concatenate([x_train, x_test])\n",
    "all_labels = np.concatenate([y_train, y_test])\n",
    "\n",
    "# Scale the pixel values to [0, 1] range, add a channel dimension to\n",
    "# the images, and one-hot encode the labels.\n",
    "all_digits = all_digits.astype(\"float32\") / 255.0\n",
    "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "all_labels = keras.utils.to_categorical(all_labels, 10)\n",
    "\n",
    "# Create tf.data.Dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_digits, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "print(f\"Shape of training images: {all_digits.shape}\")\n",
    "print(f\"Shape of training labels: {all_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5440730b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 11\n"
     ]
    }
   ],
   "source": [
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb489180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((28, 28, discriminator_in_channels)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        # We want to generate 128 + num_classes coefficients to reshape into a\n",
    "        # 7x7x(128 + num_classes) map.\n",
    "        layers.Dense(7 * 7 * generator_in_channels),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((7, 7, generator_in_channels)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35923edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WCGAN(keras.Model):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        discriminator,\n",
    "        generator,\n",
    "        latent_dim,\n",
    "        discriminator_extra_steps=3,\n",
    "        gp_weight=10.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_steps = discriminator_extra_steps\n",
    "        self.gp_weight = gp_weight\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "        \n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
    "        \"\"\"Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = self.discriminator(interpolated, training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    def train_step(self, data):\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[image_size * image_size]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "        )\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        \n",
    "        for i in range(self.d_steps):\n",
    "            # Get the latent vector\n",
    "            random_latent_vectors = tf.random.normal(\n",
    "                shape=(batch_size, self.latent_dim)\n",
    "            )\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            random_vector_labels = tf.concat(\n",
    "                [random_latent_vectors, one_hot_labels], axis=1\n",
    "            )\n",
    "            with tf.GradientTape() as tape:\n",
    "                fake_images = self.generator(random_vector_labels)\n",
    "                fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "                fake_logits = self.discriminator(fake_image_and_labels)\n",
    "                real_logits = self.discriminator(real_image_and_labels)\n",
    "                \n",
    "                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n",
    "                gp = self.gradient_penalty(batch_size, real_image_and_labels, fake_image_and_labels)\n",
    "                \n",
    "                d_loss = d_cost + gp * self.gp_weight\n",
    "\n",
    "        d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "        \n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(d_gradient, self.discriminator.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate fake images using the generator\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)            # Get the discriminator logits for fake images\n",
    "            gen_img_logits = self.discriminator(fake_image_and_labels)\n",
    "            # Calculate the generator loss\n",
    "            g_loss = self.g_loss_fn(gen_img_logits)\n",
    "        # Get the gradients w.r.t the generator loss\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        # Update the weights of the generator using the generator optimizer\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(gen_gradient, self.generator.trainable_variables)\n",
    "        )\n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91380780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1094/1094 [==============================] - 21s 17ms/step - d_loss: -0.0610 - g_loss: -0.7585\n",
      "Epoch 2/20\n",
      "1094/1094 [==============================] - 18s 16ms/step - d_loss: -0.0614 - g_loss: -0.6325\n",
      "Epoch 3/20\n",
      "1094/1094 [==============================] - 19s 17ms/step - d_loss: -0.0613 - g_loss: -0.6167\n",
      "Epoch 4/20\n",
      "1094/1094 [==============================] - 18s 17ms/step - d_loss: -0.0609 - g_loss: -0.5539\n",
      "Epoch 5/20\n",
      "1094/1094 [==============================] - 18s 17ms/step - d_loss: -0.0604 - g_loss: -0.3996\n",
      "Epoch 6/20\n",
      "1094/1094 [==============================] - 15s 14ms/step - d_loss: -0.0594 - g_loss: -0.4706\n",
      "Epoch 7/20\n",
      "1094/1094 [==============================] - 17s 15ms/step - d_loss: -0.0596 - g_loss: -0.3989\n",
      "Epoch 8/20\n",
      "1094/1094 [==============================] - 16s 14ms/step - d_loss: -0.0551 - g_loss: -0.4836\n",
      "Epoch 9/20\n",
      "1094/1094 [==============================] - 15s 14ms/step - d_loss: -0.0541 - g_loss: -0.4590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f60d43f5f00>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='d_loss', patience=3)\n",
    "\n",
    "# Instantiate the optimizer for both networks\n",
    "# (learning_rate=0.0002, beta_1=0.5 are recommended)\n",
    "generator_optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "discriminator_optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "\n",
    "# Define the loss functions for the discriminator,\n",
    "# which should be (fake_loss - real_loss).\n",
    "# We will add the gradient penalty later to this loss function.\n",
    "def discriminator_loss(real_img, fake_img):\n",
    "    real_loss = tf.reduce_mean(real_img)\n",
    "    fake_loss = tf.reduce_mean(fake_img)\n",
    "    return fake_loss - real_loss\n",
    "\n",
    "\n",
    "# Define the loss functions for the generator.\n",
    "def generator_loss(fake_img):\n",
    "    return -tf.reduce_mean(fake_img)\n",
    "\n",
    "\n",
    "# Set the number of epochs for training.\n",
    "epochs = 20\n",
    "\n",
    "# Get the wgan model\n",
    "wgan = WCGAN(\n",
    "    discriminator=discriminator,\n",
    "    generator=generator,\n",
    "    latent_dim=latent_dim,\n",
    "    discriminator_extra_steps=5,\n",
    ")\n",
    "\n",
    "# Compile the wgan model\n",
    "wgan.compile(\n",
    "    d_optimizer=discriminator_optimizer,\n",
    "    g_optimizer=generator_optimizer,\n",
    "    g_loss_fn=generator_loss,\n",
    "    d_loss_fn=discriminator_loss,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "wgan.fit(dataset, batch_size=batch_size, epochs=epochs, callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef2561d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 14, 14, 64)        6400      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 128)               0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80385 (314.00 KB)\n",
      "Trainable params: 80385 (314.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b549488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation_noise = tf.random.normal(shape=(1, latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e9c8154",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_label = keras.utils.to_categorical([3], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "80d583e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_and_labels = tf.concat([interpolation_noise, first_label], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c2820aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "trained_gen = wgan.generator\n",
    "fake = trained_gen.predict(noise_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "26e089e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f609e5b14e0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tf.reshape(fake, (28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4736e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
