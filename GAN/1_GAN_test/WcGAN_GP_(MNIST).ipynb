{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LeWt1-0h2kC"
   },
   "source": [
    "# Description\n",
    "\n",
    "In this notebook, I will use a conditional GAN to generate numbers of the MNIST dataset. Because GANs require a lot of computational resources, I will restrict the dataset size and the number of classes used. My main objective is to see the process of training a GAN.\n",
    "\n",
    "To keep track of GAN's discriminator loss and visualize the quality of images generated, I will use the TensorBoard.\n",
    "\n",
    "> To prevent the well know mode collapse that a vanilla GAN presents, I will use the Wasserstein loss with a gradient penalty (WGAN-GP).\n",
    "\n",
    "> **Tips:** Typically, the discriminator (critic) loss is expected to have negative values and fall very quickly at the beginning of the training, then rise again to near 0, that is the expected behavior of a stable training.\n",
    "\n",
    "| *Discriminator loss.* |\n",
    "![epoch_d_loss](https://github.com/RGivisiez/WcGAN-GP-MNIST/blob/main/img/epoch_d_loss.svg?raw=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHr6fnk6hyi3"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zeJy4ohuaN26",
    "outputId": "961c51b9-6364-4bcb-95f3-168ba6719dab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 17:33:16.431954: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-24 17:33:17.027498: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0DJ2cp_8aeFc"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPIm-RHcCdo5"
   },
   "source": [
    "# Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "2BVluXbyared"
   },
   "outputs": [],
   "source": [
    "#@title Downlad and normalize imagens\n",
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "norm_image = 255 / 2.0\n",
    "\n",
    "train_images = (train_images - norm_image) / norm_image  # Normalize the images to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFL_YqdR_LDO",
    "outputId": "1302a2f3-841e-4365-e329-0ff4a8e247a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 512 \n",
      "Classes: [0, 2]\n"
     ]
    }
   ],
   "source": [
    "#@title Set the train size and select the classes to consider (Default is 0 and 2).\n",
    "\n",
    "train_size = 512 #@param {type:\"integer\"}\n",
    "class_to_consider = [0, 2] #@param {type:\"raw\"}\n",
    "num_class = len(class_to_consider)\n",
    "\n",
    "print('Train size: {0} \\nClasses: {1}'.format(train_size, class_to_consider))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "id": "xSpsvTAQjtm7"
   },
   "outputs": [],
   "source": [
    "#@title Restrict the train size and select the classes labels\n",
    "\n",
    "mask = train_labels == class_to_consider[0]\n",
    "\n",
    "for c in class_to_consider[1:]:\n",
    "  mask = mask + (train_labels == c)\n",
    "\n",
    "train_images = train_images[mask]\n",
    "train_labels = train_labels[mask]\n",
    "\n",
    "train_images = train_images[:train_size]\n",
    "train_labels = train_labels[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SemxzkS1bOro"
   },
   "outputs": [],
   "source": [
    "# Buffer size must be big. \n",
    "# A rule of thumbs is to choose it equal\n",
    "# to the dataset size.\n",
    "\n",
    "BUFFER_SIZE = train_images.shape[0]\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "form",
    "id": "WBAgb3uvbiVO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 17:33:17.981770: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 17:33:17.996430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 17:33:17.996616: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 17:33:17.997823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 17:33:17.997969: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 17:33:17.998395: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 17:33:18.055366: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 17:33:18.055532: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 17:33:18.055656: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 17:33:18.055751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "#@title Make the dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kghQIj3FChRc"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jB8Tu32CzIGo"
   },
   "outputs": [],
   "source": [
    "noise_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jkfGbg0Cwb7A"
   },
   "outputs": [],
   "source": [
    "gen_input_shape = (noise_dim + num_class, )\n",
    "disc_input_shape = (train_images.shape[1],\n",
    "                    train_images.shape[2],\n",
    "                    1 + num_class,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qP2n6BudbsWv"
   },
   "outputs": [],
   "source": [
    "def make_generator1():\n",
    "\n",
    "  model = tf.keras.Sequential(name='generator1')\n",
    "\n",
    "  model.add(layers.Dense(7*7*256, input_shape=gen_input_shape))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  model.add(layers.Reshape([7, 7, 256]))\n",
    "  model.add(layers.Conv2DTranspose(128, 5, 1, 'same'))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  model.add(layers.Conv2DTranspose(64, 5, 2, 'same'))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  model.add(layers.Conv2DTranspose(1, 5, 2, 'same', activation='tanh'))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xLkWmyqDhsbT"
   },
   "outputs": [],
   "source": [
    "def make_discriminator1():\n",
    "\n",
    "  model = tf.keras.Sequential(name='discriminator1')\n",
    "\n",
    "  model.add(layers.Conv2D(64, 5, 2, 'same', input_shape=disc_input_shape))\n",
    "  model.add(layers.LeakyReLU())\n",
    "  model.add(layers.Dropout(0.3))\n",
    "\n",
    "  model.add(layers.Conv2D(128, 5, 2, 'same'))\n",
    "  model.add(layers.LeakyReLU())\n",
    "  model.add(layers.Dropout(0.3))\n",
    "  \n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(1))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12544)             1643264   \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 12544)             50176     \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 12544)             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTr  (None, 7, 7, 128)         819328    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 7, 7, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2D  (None, 14, 14, 64)        204864    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 14, 14, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2D  (None, 28, 28, 1)         1601      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2720001 (10.38 MB)\n",
      "Trainable params: 2694529 (10.28 MB)\n",
      "Non-trainable params: 25472 (99.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "make_generator1().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6xtzj9FuWLMW"
   },
   "outputs": [],
   "source": [
    "def upsample_block(\n",
    "    x,\n",
    "    filters,\n",
    "    activation,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    up_size=(2, 2),\n",
    "    padding=\"same\",\n",
    "    use_bn=False,\n",
    "    use_bias=True,\n",
    "    use_dropout=False,\n",
    "    drop_value=0.3,\n",
    "):\n",
    "    x = layers.UpSampling2D(up_size)(x)\n",
    "    x = layers.Conv2D(\n",
    "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
    "    )(x)\n",
    "\n",
    "    if use_bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "    if use_dropout:\n",
    "        x = layers.Dropout(drop_value)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_generator2():\n",
    "    noise = layers.Input(shape=gen_input_shape)\n",
    "    x = layers.Dense(4 * 4 * 256, use_bias=False)(noise)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Reshape((4, 4, 256))(x)\n",
    "    x = upsample_block(\n",
    "        x,\n",
    "        128,\n",
    "        layers.LeakyReLU(0.2),\n",
    "        strides=(1, 1),\n",
    "        use_bias=False,\n",
    "        use_bn=True,\n",
    "        padding=\"same\",\n",
    "        use_dropout=False,\n",
    "    )\n",
    "    x = upsample_block(\n",
    "        x,\n",
    "        64,\n",
    "        layers.LeakyReLU(0.2),\n",
    "        strides=(1, 1),\n",
    "        use_bias=False,\n",
    "        use_bn=True,\n",
    "        padding=\"same\",\n",
    "        use_dropout=False,\n",
    "    )\n",
    "    x = upsample_block(\n",
    "        x, 1, layers.Activation(\"tanh\"), strides=(1, 1), use_bias=False, use_bn=True\n",
    "    )\n",
    "    # At this point, we have an output which has the same shape as the input, (32, 32, 1).\n",
    "    # We will use a Cropping2D layer to make it (28, 28, 1).\n",
    "    x = layers.Cropping2D((2, 2))(x)\n",
    "    \n",
    "    g_model = keras.models.Model(noise, x, name=\"generator2\")\n",
    "    return g_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ciYOhNdWVo-a"
   },
   "outputs": [],
   "source": [
    "def conv_block(\n",
    "    x,\n",
    "    filters,\n",
    "    activation,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding=\"same\",\n",
    "    use_bias=True,\n",
    "    use_bn=False,\n",
    "    use_dropout=False,\n",
    "    drop_value=0.5,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
    "    )(x)\n",
    "    if use_bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = activation(x)\n",
    "    if use_dropout:\n",
    "        x = layers.Dropout(drop_value)(x)\n",
    "    return x\n",
    "\n",
    "def make_discriminator2():\n",
    "    img_input = layers.Input(shape=disc_input_shape)\n",
    "    # Zero pad the input to make the input images size to (32, 32, 1).\n",
    "    x = layers.ZeroPadding2D((2, 2))(img_input)\n",
    "    x = conv_block(\n",
    "        x,\n",
    "        64,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(2, 2),\n",
    "        use_bn=False,\n",
    "        use_bias=True,\n",
    "        activation=layers.LeakyReLU(0.2),\n",
    "        use_dropout=False,\n",
    "        drop_value=0.3,\n",
    "    )\n",
    "    x = conv_block(\n",
    "        x,\n",
    "        128,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(2, 2),\n",
    "        use_bn=False,\n",
    "        activation=layers.LeakyReLU(0.2),\n",
    "        use_bias=True,\n",
    "        use_dropout=True,\n",
    "        drop_value=0.3,\n",
    "    )\n",
    "    x = conv_block(\n",
    "        x,\n",
    "        256,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(2, 2),\n",
    "        use_bn=False,\n",
    "        activation=layers.LeakyReLU(0.2),\n",
    "        use_bias=True,\n",
    "        use_dropout=True,\n",
    "        drop_value=0.3,\n",
    "    )\n",
    "    x = conv_block(\n",
    "        x,\n",
    "        512,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(2, 2),\n",
    "        use_bn=False,\n",
    "        activation=layers.LeakyReLU(0.2),\n",
    "        use_bias=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.3,\n",
    "    )\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    \n",
    "    d_model = keras.models.Model(img_input, x, name=\"discriminator2\")\n",
    "    return d_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGDnrZ8GExVt"
   },
   "source": [
    "# WcGAN-GP class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "p5yjSb7XsVm7"
   },
   "outputs": [],
   "source": [
    "class WGAN(Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim,\n",
    "                 d_extra_steps=3, gp_weight=10.0,):\n",
    "        super(WGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_extra_steps = d_extra_steps\n",
    "        self.gp_weight = gp_weight\n",
    "\n",
    "    def compile(self, disc_opt, gen_opt, d_loss_fn, g_loss_fn):\n",
    "        super(WGAN, self).compile()\n",
    "        self.disc_opt = disc_opt\n",
    "        self.gen_opt = gen_opt\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "\n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
    "        \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "            This loss is calculated on an interpolated image\n",
    "            and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1])\n",
    "        interpolated = real_images * alpha + fake_images * (1 - alpha)\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = self.discriminator(interpolated, training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        \n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        \n",
    "        return gp\n",
    "\n",
    "    # Override the training step function of the Model class\n",
    "    def train_step(self, data):\n",
    "\n",
    "      images, labels = data\n",
    "\n",
    "      batch_size = tf.shape(images)[0]\n",
    "\n",
    "      one_hot_labels = tf.one_hot(labels, depth=num_class)\n",
    "\n",
    "      image_one_hot_labels = tf.repeat(one_hot_labels,\n",
    "                                 repeats=[disc_input_shape[0] * disc_input_shape[1]])\n",
    "\n",
    "      image_one_hot_labels = tf.reshape(image_one_hot_labels,\n",
    "                                        (-1, disc_input_shape[0], disc_input_shape[1], num_class))\n",
    "\n",
    "      #---------Discriminator loop--------------\n",
    "\n",
    "      for i in range(self.d_extra_steps):\n",
    "\n",
    "        noise = tf.random.normal([batch_size, self.latent_dim])\n",
    "\n",
    "        noise_labels = tf.concat([noise, one_hot_labels], axis=1)\n",
    "\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "          \n",
    "          G_output = self.generator(noise_labels, training=True)\n",
    "          G_output = tf.concat([G_output, image_one_hot_labels], -1)\n",
    "          images_and_labels = tf.concat([images, image_one_hot_labels], -1)\n",
    "  \n",
    "          D_fake_pred = self.discriminator(G_output, training=True)\n",
    "\n",
    "          D_real_pred = self.discriminator(images_and_labels, training=True)\n",
    "\n",
    "          gp = self.gradient_penalty(batch_size, images_and_labels, G_output)\n",
    "          D_loss = self.d_loss_fn(D_real_pred, D_fake_pred, self.gp_weight, gp)\n",
    "\n",
    "        D_grad = disc_tape.gradient(D_loss, self.discriminator.trainable_variables)\n",
    "        disc_opt.apply_gradients(zip(D_grad, self.discriminator.trainable_variables))\n",
    "      \n",
    "      #------Generator loop-------------\n",
    "\n",
    "      noise = tf.random.normal([batch_size, self.latent_dim])\n",
    "\n",
    "      noise_labels = tf.concat([noise, one_hot_labels], axis=1)\n",
    "\n",
    "      with tf.GradientTape() as gen_tape:\n",
    "\n",
    "        G_output = self.generator(noise_labels, training=True)\n",
    "        G_output = tf.concat([G_output, image_one_hot_labels], -1)\n",
    "\n",
    "        D_fake_pred = self.discriminator(G_output, training=True)\n",
    "\n",
    "        G_loss = self.g_loss_fn(D_fake_pred)\n",
    "\n",
    "      G_grad = gen_tape.gradient(G_loss, self.generator.trainable_variables)\n",
    "      gen_opt.apply_gradients(zip(G_grad, self.generator.trainable_variables))\n",
    "\n",
    "      return {'d_loss': D_loss, \"g_loss\": G_loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xA9WbvFpF64H"
   },
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j4gev3GopsAM",
    "outputId": "a1c993ce-1114-48a8-932c-3d5ad0619b3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path logs: logs/Model-2\n"
     ]
    }
   ],
   "source": [
    "#@title Path to save the callbacks\n",
    "logdir = \"logs/Model-2\"#os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
    "\n",
    "image_writer = tf.summary.create_file_writer(logdir + '/img')\n",
    "\n",
    "print('Path logs: {0}'.format(logdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TrrAT4p3LD1R"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 17:33:18.294345: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2023-07-24 17:33:18.294360: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2023-07-24 17:33:18.294391: I tensorflow/compiler/xla/backends/profiler/gpu/cupti_tracer.cc:1671] Profiler found 1 GPUs\n",
      "2023-07-24 17:33:18.302165: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2023-07-24 17:33:18.302273: I tensorflow/compiler/xla/backends/profiler/gpu/cupti_tracer.cc:1805] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir,\n",
    "                                                      histogram_freq=5,\n",
    "                                                      profile_batch = '2,3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6RCaCLGF-Px"
   },
   "source": [
    "### Help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "nnmBlcC_qc8J"
   },
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "\n",
    "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "  \n",
    "  # Save the plot to a PNG in memory.\n",
    "  buf = io.BytesIO()\n",
    "  plt.savefig(buf, format='png')\n",
    "\n",
    "  # Closing the figure prevents it from being displayed directly inside\n",
    "  # the notebook.\n",
    "  plt.close(figure)\n",
    "  buf.seek(0)\n",
    "\n",
    "  # Convert PNG buffer to TF image\n",
    "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "  \n",
    "  # Add the batch dimension\n",
    "  image = tf.expand_dims(image, 0)\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zH07XncpGDsS"
   },
   "source": [
    "### **GeneratorImages**: callback to save images for TensorBoard\n",
    "\n",
    "> **Warning**: This function use matplotlib and will slowdown the code, consider exclude GeneratorImages from the callback calls in model.fit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "lxO-WW1910Ko"
   },
   "outputs": [],
   "source": [
    "class GeneratorImages(keras.callbacks.Callback):\n",
    "  def __init__(self, fixed_seed, save_step=10):\n",
    "    self.fixed_seed = fixed_seed\n",
    "    self.save_step = save_step\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "\n",
    "    if epoch % self.save_step == 0:\n",
    "\n",
    "      display.clear_output(wait=True)\n",
    "      print('Epoch {0}'.format(epoch + 1))\n",
    "\n",
    "      labels = tf.range(0, num_class)\n",
    "      one_hot_labels = tf.one_hot(labels, num_class)\n",
    "      noise_labels = tf.concat([self.fixed_seed, one_hot_labels], axis=1)\n",
    "      predictions = self.model.generator(noise_labels, training=False)\n",
    "\n",
    "      predictions_img = predictions[:, :, :, :] * 255\n",
    "      \n",
    "      fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "      for i in range(predictions_img.shape[0]):\n",
    "        plt.imshow(predictions_img[i, :, :], cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "        with image_writer.as_default():\n",
    "          tf.summary.image(\"Generator Images - {}\".format(i), plot_to_image(fig), step=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeM9gJ08HfrM"
   },
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "fhbYOIyS_cz7"
   },
   "outputs": [],
   "source": [
    "def W_gen_loss(fake_pred):\n",
    "  return -tf.reduce_mean(fake_pred)\n",
    "\n",
    "def W_disc_loss(real_pred, fake_pred, eps, grad_pen):\n",
    "  return -tf.reduce_mean(real_pred) + tf.reduce_mean(fake_pred) + eps * grad_pen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiHEQRTRHlvf"
   },
   "source": [
    "# Model build and compile\n",
    "\n",
    "There are two models that can be used:\n",
    "\n",
    "  1. `make_generator1()` or `make_discriminator1()`\n",
    "  2. `make_generator2()` or `make_discriminator2()`\n",
    "\n",
    "> By default `make_discriminator2()` and `make_generator2()` are used because they give better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "DeBung0fy7I_"
   },
   "outputs": [],
   "source": [
    "Generator = make_generator2()\n",
    "Discriminator = make_discriminator2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "yNdX8bMTRBRm"
   },
   "outputs": [],
   "source": [
    "disc_opt = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n",
    "gen_opt = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "em1OC_WTsVkp"
   },
   "outputs": [],
   "source": [
    "model = WGAN(Discriminator, Generator, noise_dim, d_extra_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "fcKSMU0XsVij"
   },
   "outputs": [],
   "source": [
    "model.compile(disc_opt, gen_opt, W_disc_loss, W_gen_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDHWOUfLI9Ym"
   },
   "source": [
    "# Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cellView": "form",
    "id": "auBcxksOJmWf"
   },
   "outputs": [],
   "source": [
    "#@title \n",
    "EPOCH =  700#@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "-6d16pXHmSth"
   },
   "outputs": [],
   "source": [
    "# Seed used to creat new images at every epoch using the Generator.\n",
    "# With a fixed seed, it is possible to see how the generator improves\n",
    "# at every epoch.\n",
    "fixed_seed = tf.random.normal([num_class, noise_dim], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZISf4b8sVgT",
    "outputId": "a74d86a0-e8b4-4537-80a2-ab1e4077494e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "4/4 [==============================] - 8s 466ms/step - d_loss: -7.7614 - g_loss: -1.8203\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 1s 193ms/step - d_loss: -24.9589 - g_loss: -10.9971\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 1s 191ms/step - d_loss: -20.4475 - g_loss: -19.9918\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = model.fit(train_dataset,\n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 epochs=3,\n",
    "                 callbacks=[GeneratorImages(fixed_seed),\n",
    "                            tensorboard_callback,\n",
    "                            ]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lHcdW-tPXBq"
   },
   "source": [
    "# Generate new images using the Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "C1G-eV4nCvHk",
    "outputId": "57b8cac6-1659-42db-81c3-26a578582949"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 300x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 300x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 300x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 300x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Number o images\n",
    "n_images = 4 #@param {type:\"integer\"}\n",
    "\n",
    "plt.close()\n",
    "\n",
    "for _ in range(n_images):\n",
    "  \n",
    "  fixed_seed = tf.random.normal([num_class, noise_dim])\n",
    "\n",
    "  labels = tf.range(0, num_class)\n",
    "  one_hot_labels = tf.one_hot(labels, num_class)\n",
    "  noise_labels = tf.concat([fixed_seed, one_hot_labels], axis=1)\n",
    "  predictions = Generator(noise_labels, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(num_class+1, 2))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(1, num_class, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "hHr6fnk6hyi3",
    "EPIm-RHcCdo5",
    "kghQIj3FChRc",
    "dGDnrZ8GExVt",
    "xA9WbvFpF64H",
    "v6RCaCLGF-Px",
    "zH07XncpGDsS",
    "YeM9gJ08HfrM",
    "RiHEQRTRHlvf",
    "fDHWOUfLI9Ym"
   ],
   "include_colab_link": true,
   "name": "WcGAN-GP (MNIST).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
