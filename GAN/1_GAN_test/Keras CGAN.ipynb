{
 "cells": [
  {
   "cell_type": "raw",
   "id": "fc8cc834",
   "metadata": {},
   "source": [
    "!pip install tensorflow\n",
    "!pip install -q git+https://github.com/tensorflow/docs\n",
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4727fe0",
   "metadata": {},
   "source": [
    "https://keras.io/examples/generative/conditional_gan/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15277642",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de75ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 10:42:15.727329: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-24 10:42:16.328788: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow_docs.vis import embed\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "436c4326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c756a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_channels = 1\n",
    "num_classes = 10\n",
    "image_size = 28\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa590d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (70000, 28, 28, 1)\n",
      "Shape of training labels: (70000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 10:42:17.667618: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 10:42:17.688112: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 10:42:17.688303: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 10:42:17.689889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 10:42:17.690034: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 10:42:17.690158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 10:42:17.742899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 10:42:17.743040: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 10:42:17.743144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 10:42:17.743262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9548 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# We'll use all the available examples from both the training and test\n",
    "# sets.\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "all_digits = np.concatenate([x_train, x_test])\n",
    "all_labels = np.concatenate([y_train, y_test])\n",
    "\n",
    "# Scale the pixel values to [0, 1] range, add a channel dimension to\n",
    "# the images, and one-hot encode the labels.\n",
    "all_digits = all_digits.astype(\"float32\") / 255.0\n",
    "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "all_labels = keras.utils.to_categorical(all_labels, 10)\n",
    "\n",
    "# Create tf.data.Dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_digits, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "print(f\"Shape of training images: {all_digits.shape}\")\n",
    "print(f\"Shape of training labels: {all_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68da70c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 11\n"
     ]
    }
   ],
   "source": [
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06260b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((28, 28, discriminator_in_channels)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        # We want to generate 128 + num_classes coefficients to reshape into a\n",
    "        # 7x7x(128 + num_classes) map.\n",
    "        layers.Dense(7 * 7 * generator_in_channels),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((7, 7, generator_in_channels)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "786ace78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[image_size * image_size]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8ed6ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 10:42:19.273111: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-07-24 10:42:19.294711: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-24 10:42:19.614718: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f71ba6e0770 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-24 10:42:19.614742: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2023-07-24 10:42:19.618806: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-24 10:42:19.673645: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-24 10:42:19.717674: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094/1094 [==============================] - 22s 18ms/step - g_loss: 1.5364 - d_loss: 0.4186\n",
      "Epoch 2/100\n",
      "1094/1094 [==============================] - 18s 17ms/step - g_loss: 1.5177 - d_loss: 0.4440\n",
      "Epoch 3/100\n",
      "1094/1094 [==============================] - 18s 17ms/step - g_loss: 1.6436 - d_loss: 0.3846\n",
      "Epoch 4/100\n",
      "1094/1094 [==============================] - 21s 19ms/step - g_loss: 2.1431 - d_loss: 0.2331\n",
      "Epoch 5/100\n",
      "1094/1094 [==============================] - 20s 18ms/step - g_loss: 1.0498 - d_loss: 0.6084\n",
      "Epoch 6/100\n",
      "1094/1094 [==============================] - 20s 18ms/step - g_loss: 0.9092 - d_loss: 0.6396\n",
      "Epoch 7/100\n",
      "1094/1094 [==============================] - 21s 19ms/step - g_loss: 0.8553 - d_loss: 0.6611\n",
      "Epoch 8/100\n",
      "1094/1094 [==============================] - 22s 20ms/step - g_loss: 0.8156 - d_loss: 0.6659\n",
      "Epoch 9/100\n",
      "1094/1094 [==============================] - 21s 19ms/step - g_loss: 0.7864 - d_loss: 0.6755\n",
      "Epoch 10/100\n",
      "1094/1094 [==============================] - 21s 19ms/step - g_loss: 0.7780 - d_loss: 0.6751\n",
      "Epoch 11/100\n",
      "1094/1094 [==============================] - 19s 18ms/step - g_loss: 0.7693 - d_loss: 0.6825\n",
      "Epoch 12/100\n",
      "1094/1094 [==============================] - 17s 16ms/step - g_loss: 0.7680 - d_loss: 0.6779\n",
      "Epoch 13/100\n",
      "1094/1094 [==============================] - 20s 19ms/step - g_loss: 0.7592 - d_loss: 0.6795\n",
      "Epoch 14/100\n",
      "1094/1094 [==============================] - 21s 19ms/step - g_loss: 0.7889 - d_loss: 0.6685\n",
      "Epoch 15/100\n",
      "1094/1094 [==============================] - 20s 18ms/step - g_loss: 0.7573 - d_loss: 0.6779\n",
      "Epoch 16/100\n",
      "1094/1094 [==============================] - 20s 19ms/step - g_loss: 0.7775 - d_loss: 0.6658\n"
     ]
    }
   ],
   "source": [
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='g_loss', patience=3)\n",
    "\n",
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "history = cond_gan.fit(dataset, epochs=100, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a7af782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.    1.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.875 0.    0.    0.    0.125 0.    0.    0.    0.   ]\n",
      " [0.    0.75  0.    0.    0.    0.25  0.    0.    0.    0.   ]\n",
      " [0.    0.625 0.    0.    0.    0.375 0.    0.    0.    0.   ]\n",
      " [0.    0.5   0.    0.    0.    0.5   0.    0.    0.    0.   ]\n",
      " [0.    0.375 0.    0.    0.    0.625 0.    0.    0.    0.   ]\n",
      " [0.    0.25  0.    0.    0.    0.75  0.    0.    0.    0.   ]\n",
      " [0.    0.125 0.    0.    0.    0.875 0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]], shape=(9, 10), dtype=float32)\n",
      "(9, 138)\n",
      "1/1 [==============================] - 0s 144ms/step\n"
     ]
    }
   ],
   "source": [
    "# We first extract the trained generator from our Conditional GAN.\n",
    "trained_gen = cond_gan.generator\n",
    "\n",
    "# Choose the number of intermediate images that would be generated in\n",
    "# between the interpolation + 2 (start and last images).\n",
    "num_interpolation = 9  # @param {type:\"integer\"}\n",
    "\n",
    "# Sample noise for the interpolation.\n",
    "interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n",
    "interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)\n",
    "interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))\n",
    "\n",
    "\n",
    "def interpolate_class(first_number, second_number):\n",
    "    # Convert the start and end labels to one-hot encoded vectors.\n",
    "    first_label = keras.utils.to_categorical([first_number], num_classes)\n",
    "    second_label = keras.utils.to_categorical([second_number], num_classes)\n",
    "    first_label = tf.cast(first_label, tf.float32)\n",
    "    second_label = tf.cast(second_label, tf.float32)\n",
    "\n",
    "    # Calculate the interpolation vector between the two labels.\n",
    "    percent_second_label = tf.linspace(0, 1, num_interpolation)[:, None]\n",
    "    percent_second_label = tf.cast(percent_second_label, tf.float32)\n",
    "    interpolation_labels = (\n",
    "        first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
    "    )\n",
    "    print(interpolation_labels)\n",
    "\n",
    "    # Combine the noise and the labels and run inference with the generator.\n",
    "    noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)\n",
    "    print(noise_and_labels.shape)\n",
    "    fake = trained_gen.predict(noise_and_labels)\n",
    "    return fake\n",
    "\n",
    "\n",
    "start_class = 1  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "end_class = 5  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "\n",
    "fake_images = interpolate_class(start_class, end_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bcd3803",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images *= 255.0\n",
    "converted_images = fake_images.astype(np.uint8)\n",
    "converted_images = tf.image.resize(converted_images, (28, 28)).numpy().astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3c70ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7646c4aad0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(converted_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8734f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
