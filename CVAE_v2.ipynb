{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b38409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 04:50:49.633143: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.vae import create_VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a72c9ce",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f2a7570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión de imágenes: (2937, 128, 128, 1)\n",
      "Dimensión de labels: (2937, 4)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"data/processed_data_128_20230726.h5\", \"r\") as f:\n",
    "    imgs_train, labels_train = np.array(f[\"X_train\"]), np.array(f[\"y_train\"])\n",
    "    imgs_test, labels_test = np.array(f[\"X_test\"]), np.array(f[\"y_test\"])\n",
    "\n",
    "print(\"Dimensión de imágenes:\", imgs_train.shape)\n",
    "print(\"Dimensión de labels:\", labels_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a705df48",
   "metadata": {},
   "source": [
    "# Modelo\n",
    "\n",
    "Se entrenará un modelo similar a lo expuesto en transfer-learning y pretrained models. La diferencia es que este modelo se entrenará desde cero, a diferencia de los expuestos en transfer-learning que partimos de un modelo preentrenado. Como vimo en los modelos preentrenados, la arquitectura más grande es la que mejor da. Se entrenarán 4 modelos. 2 chiquitos (256 y 512) (ver notebook de preentrenados para entender) y 2 grandes(256 y 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b1a2c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_shape = imgs_train.shape[1:]\n",
    "n_cat = labels_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cde00d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cvae_small_256 = create_VAE(input_img_shape, latent_dim = 256,  n_blocks=13, n_cat=n_cat, \n",
    "                            conditional=True)\n",
    "cvae_small_512 = create_VAE(input_img_shape, latent_dim = 512,  n_blocks=13, n_cat=n_cat, \n",
    "                            conditional=True)\n",
    "\n",
    "cvae_big_256 = create_VAE(input_img_shape, latent_dim = 256,  n_blocks=19, n_cat=n_cat, \n",
    "                            conditional=True)\n",
    "cvae_big_512 = create_VAE(input_img_shape, latent_dim = 512,  n_blocks=19, n_cat=n_cat, \n",
    "                            conditional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cbd4cf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 05:01:45.970148: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-07-27 05:01:46.504597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-07-27 05:01:48.094892: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f783198ac50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-27 05:01:48.094915: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-07-27 05:01:48.097621: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-27 05:01:48.168514: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 19s 189ms/step - loss: 10217.0039 - reconstruction_loss: 9049.3691 - kl_loss: 4.4445\n",
      "Epoch 2/300\n",
      "46/46 [==============================] - 5s 112ms/step - loss: 7222.9651 - reconstruction_loss: 7107.3130 - kl_loss: 13.3481\n",
      "Epoch 3/300\n",
      "46/46 [==============================] - 5s 111ms/step - loss: 6919.6210 - reconstruction_loss: 6862.7725 - kl_loss: 17.1813\n",
      "Epoch 4/300\n",
      "46/46 [==============================] - 5s 112ms/step - loss: 6889.7325 - reconstruction_loss: 6844.8667 - kl_loss: 13.8742\n",
      "Epoch 5/300\n",
      "46/46 [==============================] - 5s 112ms/step - loss: 6883.3387 - reconstruction_loss: 6844.2583 - kl_loss: 13.7006\n",
      "Epoch 6/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6851.6692 - reconstruction_loss: 6828.8062 - kl_loss: 12.8956\n",
      "Epoch 7/300\n",
      "46/46 [==============================] - 5s 112ms/step - loss: 6857.6578 - reconstruction_loss: 6814.2988 - kl_loss: 14.9339\n",
      "Epoch 8/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6835.2342 - reconstruction_loss: 6787.8989 - kl_loss: 18.0115\n",
      "Epoch 9/300\n",
      "46/46 [==============================] - 5s 112ms/step - loss: 6773.3615 - reconstruction_loss: 6763.3755 - kl_loss: 19.7010\n",
      "Epoch 10/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6748.3119 - reconstruction_loss: 6752.6626 - kl_loss: 19.7480\n",
      "Epoch 11/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6776.5236 - reconstruction_loss: 6735.1577 - kl_loss: 19.8163\n",
      "Epoch 12/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6727.3168 - reconstruction_loss: 6724.7168 - kl_loss: 19.9136\n",
      "Epoch 13/300\n",
      "46/46 [==============================] - 5s 112ms/step - loss: 6726.0928 - reconstruction_loss: 6717.7656 - kl_loss: 20.4910\n",
      "Epoch 14/300\n",
      "46/46 [==============================] - 5s 112ms/step - loss: 6760.7405 - reconstruction_loss: 6713.7847 - kl_loss: 20.4846\n",
      "Epoch 15/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6719.0478 - reconstruction_loss: 6698.2759 - kl_loss: 21.5923\n",
      "Epoch 16/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6643.9863 - reconstruction_loss: 6674.0864 - kl_loss: 24.4408\n",
      "Epoch 17/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6683.1759 - reconstruction_loss: 6655.4707 - kl_loss: 26.1958\n",
      "Epoch 18/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6678.1879 - reconstruction_loss: 6649.9536 - kl_loss: 26.7521\n",
      "Epoch 19/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6683.4732 - reconstruction_loss: 6633.0498 - kl_loss: 27.7319\n",
      "Epoch 20/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6629.6827 - reconstruction_loss: 6621.1426 - kl_loss: 28.9326\n",
      "Epoch 21/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6651.3745 - reconstruction_loss: 6597.1406 - kl_loss: 30.4437\n",
      "Epoch 22/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6660.2724 - reconstruction_loss: 6589.2690 - kl_loss: 32.5970\n",
      "Epoch 23/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6590.6976 - reconstruction_loss: 6565.6509 - kl_loss: 34.3870\n",
      "Epoch 24/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6633.8370 - reconstruction_loss: 6555.1494 - kl_loss: 34.9617\n",
      "Epoch 25/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6594.6779 - reconstruction_loss: 6542.4756 - kl_loss: 35.4269\n",
      "Epoch 26/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6553.8556 - reconstruction_loss: 6558.7881 - kl_loss: 37.6702\n",
      "Epoch 27/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6614.1879 - reconstruction_loss: 6526.3350 - kl_loss: 36.9949\n",
      "Epoch 28/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6585.7430 - reconstruction_loss: 6520.4233 - kl_loss: 37.0903\n",
      "Epoch 29/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6548.3364 - reconstruction_loss: 6508.3501 - kl_loss: 37.8787\n",
      "Epoch 30/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6605.3420 - reconstruction_loss: 6507.4414 - kl_loss: 37.8840\n",
      "Epoch 31/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6595.5036 - reconstruction_loss: 6506.4268 - kl_loss: 37.9666\n",
      "Epoch 32/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6523.3634 - reconstruction_loss: 6492.6235 - kl_loss: 38.3990\n",
      "Epoch 33/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6548.3330 - reconstruction_loss: 6494.8804 - kl_loss: 38.9068\n",
      "Epoch 34/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6514.1116 - reconstruction_loss: 6482.6704 - kl_loss: 40.0357\n",
      "Epoch 35/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6533.1522 - reconstruction_loss: 6474.8872 - kl_loss: 40.0016\n",
      "Epoch 36/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6461.9052 - reconstruction_loss: 6466.8037 - kl_loss: 41.0235\n",
      "Epoch 37/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6512.3398 - reconstruction_loss: 6459.0190 - kl_loss: 41.5159\n",
      "Epoch 38/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6467.2822 - reconstruction_loss: 6452.5205 - kl_loss: 42.4866\n",
      "Epoch 39/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6505.5194 - reconstruction_loss: 6455.5229 - kl_loss: 42.2743\n",
      "Epoch 40/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6506.9472 - reconstruction_loss: 6442.2432 - kl_loss: 42.4683\n",
      "Epoch 41/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6502.2633 - reconstruction_loss: 6427.2349 - kl_loss: 43.3069\n",
      "Epoch 42/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6442.3446 - reconstruction_loss: 6427.4912 - kl_loss: 42.8295\n",
      "Epoch 43/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6461.5715 - reconstruction_loss: 6423.1597 - kl_loss: 43.0540\n",
      "Epoch 44/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6448.8639 - reconstruction_loss: 6433.3247 - kl_loss: 43.6471\n",
      "Epoch 45/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6491.5008 - reconstruction_loss: 6411.9995 - kl_loss: 43.2795\n",
      "Epoch 46/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6447.1803 - reconstruction_loss: 6415.8613 - kl_loss: 43.5862\n",
      "Epoch 47/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6471.6335 - reconstruction_loss: 6404.8042 - kl_loss: 43.9527\n",
      "Epoch 48/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6450.9352 - reconstruction_loss: 6400.3457 - kl_loss: 43.7425\n",
      "Epoch 49/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6437.7338 - reconstruction_loss: 6396.8623 - kl_loss: 43.9753\n",
      "Epoch 50/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6407.6454 - reconstruction_loss: 6400.0562 - kl_loss: 43.2339\n",
      "Epoch 51/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6457.1437 - reconstruction_loss: 6394.4561 - kl_loss: 43.4344\n",
      "Epoch 52/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6425.1542 - reconstruction_loss: 6382.3877 - kl_loss: 44.7430\n",
      "Epoch 53/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6421.0315 - reconstruction_loss: 6380.1108 - kl_loss: 43.7562\n",
      "Epoch 54/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6439.3356 - reconstruction_loss: 6387.1177 - kl_loss: 44.1089\n",
      "Epoch 55/300\n",
      "46/46 [==============================] - 6s 125ms/step - loss: 6453.9942 - reconstruction_loss: 6381.4424 - kl_loss: 43.9228\n",
      "Epoch 56/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6413.8330 - reconstruction_loss: 6366.5073 - kl_loss: 44.5482\n",
      "Epoch 57/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6413.2598 - reconstruction_loss: 6364.4639 - kl_loss: 44.5129\n",
      "Epoch 58/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6406.4293 - reconstruction_loss: 6358.2876 - kl_loss: 44.8072\n",
      "Epoch 59/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6418.6347 - reconstruction_loss: 6358.8804 - kl_loss: 45.8119\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 5s 118ms/step - loss: 6392.3708 - reconstruction_loss: 6352.3960 - kl_loss: 45.0741\n",
      "Epoch 61/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6382.8683 - reconstruction_loss: 6352.7012 - kl_loss: 44.7228\n",
      "Epoch 62/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6385.6198 - reconstruction_loss: 6337.1157 - kl_loss: 45.7390\n",
      "Epoch 63/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6371.6351 - reconstruction_loss: 6338.1748 - kl_loss: 44.7990\n",
      "Epoch 64/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6367.5058 - reconstruction_loss: 6342.0591 - kl_loss: 44.9532\n",
      "Epoch 65/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6395.5433 - reconstruction_loss: 6333.2061 - kl_loss: 45.1426\n",
      "Epoch 66/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6336.9754 - reconstruction_loss: 6333.5483 - kl_loss: 45.0050\n",
      "Epoch 67/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6355.9759 - reconstruction_loss: 6326.4341 - kl_loss: 45.3104\n",
      "Epoch 68/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6390.1648 - reconstruction_loss: 6317.5225 - kl_loss: 45.5222\n",
      "Epoch 69/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6319.1105 - reconstruction_loss: 6314.9790 - kl_loss: 45.1813\n",
      "Epoch 70/300\n",
      "46/46 [==============================] - 6s 130ms/step - loss: 6385.4116 - reconstruction_loss: 6315.0439 - kl_loss: 45.4390\n",
      "Epoch 71/300\n",
      "46/46 [==============================] - 6s 128ms/step - loss: 6339.5821 - reconstruction_loss: 6311.3110 - kl_loss: 45.2490\n",
      "Epoch 72/300\n",
      "46/46 [==============================] - 6s 127ms/step - loss: 6297.5549 - reconstruction_loss: 6310.8384 - kl_loss: 44.3219\n",
      "Epoch 73/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6283.5887 - reconstruction_loss: 6302.9717 - kl_loss: 45.2594\n",
      "Epoch 74/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6425.1635 - reconstruction_loss: 6311.4077 - kl_loss: 44.8948\n",
      "Epoch 75/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6341.9444 - reconstruction_loss: 6303.1724 - kl_loss: 44.8025\n",
      "Epoch 76/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6321.1210 - reconstruction_loss: 6298.0640 - kl_loss: 45.2060\n",
      "Epoch 77/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6363.3746 - reconstruction_loss: 6307.8008 - kl_loss: 44.4095\n",
      "Epoch 78/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6367.9119 - reconstruction_loss: 6291.6040 - kl_loss: 45.5188\n",
      "Epoch 79/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6327.2082 - reconstruction_loss: 6291.1860 - kl_loss: 46.0289\n",
      "Epoch 80/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6356.3446 - reconstruction_loss: 6286.4873 - kl_loss: 45.4803\n",
      "Epoch 81/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6325.9441 - reconstruction_loss: 6280.0889 - kl_loss: 45.6197\n",
      "Epoch 82/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6297.0578 - reconstruction_loss: 6275.7998 - kl_loss: 46.0206\n",
      "Epoch 83/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6342.4690 - reconstruction_loss: 6268.4336 - kl_loss: 46.1844\n",
      "Epoch 84/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6335.0922 - reconstruction_loss: 6271.8633 - kl_loss: 46.2521\n",
      "Epoch 85/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6302.7931 - reconstruction_loss: 6272.6938 - kl_loss: 45.2489\n",
      "Epoch 86/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6332.1859 - reconstruction_loss: 6266.9849 - kl_loss: 45.9082\n",
      "Epoch 87/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6299.8395 - reconstruction_loss: 6263.4102 - kl_loss: 46.5321\n",
      "Epoch 88/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6309.6288 - reconstruction_loss: 6260.0298 - kl_loss: 45.9573\n",
      "Epoch 89/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6310.3208 - reconstruction_loss: 6253.2778 - kl_loss: 46.2280\n",
      "Epoch 90/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6270.3708 - reconstruction_loss: 6249.0942 - kl_loss: 46.2568\n",
      "Epoch 91/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6374.5069 - reconstruction_loss: 6243.8999 - kl_loss: 46.7650\n",
      "Epoch 92/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6289.6368 - reconstruction_loss: 6248.6724 - kl_loss: 46.4439\n",
      "Epoch 93/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6256.0089 - reconstruction_loss: 6240.8789 - kl_loss: 46.2346\n",
      "Epoch 94/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6305.0958 - reconstruction_loss: 6237.7534 - kl_loss: 46.5666\n",
      "Epoch 95/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6284.8289 - reconstruction_loss: 6238.6914 - kl_loss: 46.2173\n",
      "Epoch 96/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6258.0556 - reconstruction_loss: 6234.5312 - kl_loss: 47.0129\n",
      "Epoch 97/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6315.2266 - reconstruction_loss: 6238.0605 - kl_loss: 46.1467\n",
      "Epoch 98/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6233.4494 - reconstruction_loss: 6224.6421 - kl_loss: 46.1397\n",
      "Epoch 99/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6227.8412 - reconstruction_loss: 6224.8096 - kl_loss: 46.2842\n",
      "Epoch 100/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6286.1707 - reconstruction_loss: 6222.2158 - kl_loss: 46.1032\n",
      "Epoch 101/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6257.1513 - reconstruction_loss: 6217.2261 - kl_loss: 46.2878\n",
      "Epoch 102/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6251.6659 - reconstruction_loss: 6216.9585 - kl_loss: 46.3355\n",
      "Epoch 103/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6275.1332 - reconstruction_loss: 6220.2568 - kl_loss: 46.5835\n",
      "Epoch 104/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6299.5098 - reconstruction_loss: 6215.6768 - kl_loss: 46.3032\n",
      "Epoch 105/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6266.9521 - reconstruction_loss: 6205.5039 - kl_loss: 46.6030\n",
      "Epoch 106/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6297.0175 - reconstruction_loss: 6206.1963 - kl_loss: 46.1931\n",
      "Epoch 107/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6271.1580 - reconstruction_loss: 6205.9912 - kl_loss: 46.2208\n",
      "Epoch 108/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6219.3628 - reconstruction_loss: 6205.8765 - kl_loss: 46.0944\n",
      "Epoch 109/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6177.3321 - reconstruction_loss: 6197.3140 - kl_loss: 45.8945\n",
      "Epoch 110/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6255.8870 - reconstruction_loss: 6200.1323 - kl_loss: 45.4687\n",
      "Epoch 111/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6226.8904 - reconstruction_loss: 6190.1890 - kl_loss: 45.9973\n",
      "Epoch 112/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6226.7455 - reconstruction_loss: 6189.1562 - kl_loss: 46.1175\n",
      "Epoch 113/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6230.3403 - reconstruction_loss: 6186.8086 - kl_loss: 46.0395\n",
      "Epoch 114/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6255.1818 - reconstruction_loss: 6187.7168 - kl_loss: 45.3604\n",
      "Epoch 115/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6249.8687 - reconstruction_loss: 6186.3296 - kl_loss: 45.6745\n",
      "Epoch 116/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6291.0814 - reconstruction_loss: 6191.6875 - kl_loss: 45.6797\n",
      "Epoch 117/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6250.4504 - reconstruction_loss: 6179.9380 - kl_loss: 45.7486\n",
      "Epoch 118/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6222.0053 - reconstruction_loss: 6180.4199 - kl_loss: 45.2636\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 5s 115ms/step - loss: 6243.1232 - reconstruction_loss: 6177.5591 - kl_loss: 46.6918\n",
      "Epoch 120/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6200.8216 - reconstruction_loss: 6168.4893 - kl_loss: 45.8290\n",
      "Epoch 121/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6230.6791 - reconstruction_loss: 6169.6714 - kl_loss: 45.5488\n",
      "Epoch 122/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6246.9381 - reconstruction_loss: 6172.5293 - kl_loss: 45.6152\n",
      "Epoch 123/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6183.5595 - reconstruction_loss: 6166.2324 - kl_loss: 45.4022\n",
      "Epoch 124/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6236.9134 - reconstruction_loss: 6161.6841 - kl_loss: 45.2315\n",
      "Epoch 125/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6214.4389 - reconstruction_loss: 6160.8989 - kl_loss: 45.2145\n",
      "Epoch 126/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6170.9549 - reconstruction_loss: 6157.7798 - kl_loss: 45.1498\n",
      "Epoch 127/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6209.4861 - reconstruction_loss: 6160.5415 - kl_loss: 45.4606\n",
      "Epoch 128/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6215.9746 - reconstruction_loss: 6160.0068 - kl_loss: 45.3557\n",
      "Epoch 129/300\n",
      "46/46 [==============================] - 5s 120ms/step - loss: 6215.1708 - reconstruction_loss: 6156.6021 - kl_loss: 44.9379\n",
      "Epoch 130/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6212.8762 - reconstruction_loss: 6154.5073 - kl_loss: 45.5319\n",
      "Epoch 131/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6198.9951 - reconstruction_loss: 6153.2920 - kl_loss: 45.2132\n",
      "Epoch 132/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6209.6563 - reconstruction_loss: 6151.8779 - kl_loss: 45.1380\n",
      "Epoch 133/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6191.0245 - reconstruction_loss: 6152.4980 - kl_loss: 45.0254\n",
      "Epoch 134/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6226.5696 - reconstruction_loss: 6149.2324 - kl_loss: 44.7113\n",
      "Epoch 135/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6199.8093 - reconstruction_loss: 6139.1753 - kl_loss: 44.8704\n",
      "Epoch 136/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6189.5773 - reconstruction_loss: 6143.4688 - kl_loss: 45.0418\n",
      "Epoch 137/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6205.3558 - reconstruction_loss: 6141.3838 - kl_loss: 44.6668\n",
      "Epoch 138/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6184.3529 - reconstruction_loss: 6136.3062 - kl_loss: 44.9082\n",
      "Epoch 139/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6155.4399 - reconstruction_loss: 6134.9692 - kl_loss: 44.8218\n",
      "Epoch 140/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6185.8626 - reconstruction_loss: 6134.9614 - kl_loss: 44.6422\n",
      "Epoch 141/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6172.7635 - reconstruction_loss: 6126.3320 - kl_loss: 44.8142\n",
      "Epoch 142/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6202.6110 - reconstruction_loss: 6136.9180 - kl_loss: 44.5273\n",
      "Epoch 143/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6169.7279 - reconstruction_loss: 6127.3921 - kl_loss: 44.7609\n",
      "Epoch 144/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6153.8247 - reconstruction_loss: 6124.3296 - kl_loss: 44.2121\n",
      "Epoch 145/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6208.0575 - reconstruction_loss: 6123.0889 - kl_loss: 44.6065\n",
      "Epoch 146/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6151.4755 - reconstruction_loss: 6121.0220 - kl_loss: 44.3654\n",
      "Epoch 147/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6118.7729 - reconstruction_loss: 6122.1201 - kl_loss: 44.2508\n",
      "Epoch 148/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6148.2626 - reconstruction_loss: 6120.1108 - kl_loss: 44.3428\n",
      "Epoch 149/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6201.2593 - reconstruction_loss: 6109.8994 - kl_loss: 44.0369\n",
      "Epoch 150/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6143.7152 - reconstruction_loss: 6108.6440 - kl_loss: 43.9782\n",
      "Epoch 151/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6176.2538 - reconstruction_loss: 6114.4775 - kl_loss: 44.2512\n",
      "Epoch 152/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6194.2574 - reconstruction_loss: 6117.4604 - kl_loss: 43.8144\n",
      "Epoch 153/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6160.3404 - reconstruction_loss: 6116.3164 - kl_loss: 43.4834\n",
      "Epoch 154/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6140.4717 - reconstruction_loss: 6103.7817 - kl_loss: 43.7254\n",
      "Epoch 155/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6153.9580 - reconstruction_loss: 6104.7983 - kl_loss: 43.6213\n",
      "Epoch 156/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6106.4507 - reconstruction_loss: 6100.3281 - kl_loss: 43.3417\n",
      "Epoch 157/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6148.7626 - reconstruction_loss: 6096.6113 - kl_loss: 43.8764\n",
      "Epoch 158/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6165.1537 - reconstruction_loss: 6099.1177 - kl_loss: 43.3759\n",
      "Epoch 159/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6120.0685 - reconstruction_loss: 6099.1133 - kl_loss: 43.3078\n",
      "Epoch 160/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6192.2234 - reconstruction_loss: 6101.5918 - kl_loss: 43.5060\n",
      "Epoch 161/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6085.0065 - reconstruction_loss: 6092.5728 - kl_loss: 42.9364\n",
      "Epoch 162/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6131.1785 - reconstruction_loss: 6090.6768 - kl_loss: 43.0750\n",
      "Epoch 163/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6128.8570 - reconstruction_loss: 6089.7036 - kl_loss: 43.0211\n",
      "Epoch 164/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6117.0965 - reconstruction_loss: 6092.7573 - kl_loss: 42.9733\n",
      "Epoch 165/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6143.9342 - reconstruction_loss: 6088.1123 - kl_loss: 42.7514\n",
      "Epoch 166/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6089.6167 - reconstruction_loss: 6088.9648 - kl_loss: 42.6319\n",
      "Epoch 167/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6146.5581 - reconstruction_loss: 6085.9995 - kl_loss: 42.6876\n",
      "Epoch 168/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6108.6416 - reconstruction_loss: 6086.0117 - kl_loss: 42.6132\n",
      "Epoch 169/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6147.1876 - reconstruction_loss: 6085.0151 - kl_loss: 42.3528\n",
      "Epoch 170/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6093.5840 - reconstruction_loss: 6085.1343 - kl_loss: 42.2746\n",
      "Epoch 171/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6148.7928 - reconstruction_loss: 6081.5073 - kl_loss: 42.2039\n",
      "Epoch 172/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6143.9172 - reconstruction_loss: 6079.7974 - kl_loss: 42.0753\n",
      "Epoch 173/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6144.3563 - reconstruction_loss: 6075.5093 - kl_loss: 42.1093\n",
      "Epoch 174/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6105.0220 - reconstruction_loss: 6075.2783 - kl_loss: 41.6591\n",
      "Epoch 175/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6110.0694 - reconstruction_loss: 6070.4180 - kl_loss: 42.1429\n",
      "Epoch 176/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6101.9704 - reconstruction_loss: 6067.9702 - kl_loss: 42.1974\n",
      "Epoch 177/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6040.5925 - reconstruction_loss: 6063.7549 - kl_loss: 41.9309\n",
      "Epoch 178/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 5s 113ms/step - loss: 6088.6158 - reconstruction_loss: 6067.9189 - kl_loss: 41.6123\n",
      "Epoch 179/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6091.0330 - reconstruction_loss: 6064.0586 - kl_loss: 41.6536\n",
      "Epoch 180/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6070.7852 - reconstruction_loss: 6061.1025 - kl_loss: 41.1899\n",
      "Epoch 181/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6132.3556 - reconstruction_loss: 6063.0918 - kl_loss: 41.6456\n",
      "Epoch 182/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6111.6833 - reconstruction_loss: 6068.7861 - kl_loss: 41.1848\n",
      "Epoch 183/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6093.9011 - reconstruction_loss: 6069.6338 - kl_loss: 41.2088\n",
      "Epoch 184/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6111.8670 - reconstruction_loss: 6065.9033 - kl_loss: 41.6500\n",
      "Epoch 185/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6096.9408 - reconstruction_loss: 6061.1875 - kl_loss: 41.3974\n",
      "Epoch 186/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6105.9499 - reconstruction_loss: 6053.5835 - kl_loss: 41.0991\n",
      "Epoch 187/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6088.4164 - reconstruction_loss: 6055.9619 - kl_loss: 41.1895\n",
      "Epoch 188/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6149.7744 - reconstruction_loss: 6064.6582 - kl_loss: 41.0763\n",
      "Epoch 189/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6103.5539 - reconstruction_loss: 6054.1821 - kl_loss: 41.2248\n",
      "Epoch 190/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6099.8380 - reconstruction_loss: 6050.4907 - kl_loss: 40.8955\n",
      "Epoch 191/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6077.8770 - reconstruction_loss: 6048.4355 - kl_loss: 40.7439\n",
      "Epoch 192/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6085.1758 - reconstruction_loss: 6049.3105 - kl_loss: 41.0534\n",
      "Epoch 193/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6131.3615 - reconstruction_loss: 6047.2095 - kl_loss: 41.1077\n",
      "Epoch 194/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6119.1481 - reconstruction_loss: 6048.2554 - kl_loss: 40.4931\n",
      "Epoch 195/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6097.9717 - reconstruction_loss: 6048.6514 - kl_loss: 40.8118\n",
      "Epoch 196/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6084.4737 - reconstruction_loss: 6046.8408 - kl_loss: 40.9810\n",
      "Epoch 197/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6103.5975 - reconstruction_loss: 6041.9375 - kl_loss: 40.6668\n",
      "Epoch 198/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6059.9735 - reconstruction_loss: 6042.5942 - kl_loss: 40.1952\n",
      "Epoch 199/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6092.9219 - reconstruction_loss: 6045.3545 - kl_loss: 40.5568\n",
      "Epoch 200/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6081.5827 - reconstruction_loss: 6042.0938 - kl_loss: 40.6095\n",
      "Epoch 201/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6061.6821 - reconstruction_loss: 6037.7695 - kl_loss: 40.2362\n",
      "Epoch 202/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6105.3688 - reconstruction_loss: 6040.1602 - kl_loss: 40.4859\n",
      "Epoch 203/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6091.3193 - reconstruction_loss: 6038.2964 - kl_loss: 40.4673\n",
      "Epoch 204/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6121.8487 - reconstruction_loss: 6039.8677 - kl_loss: 40.1890\n",
      "Epoch 205/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6072.4843 - reconstruction_loss: 6031.9893 - kl_loss: 40.0459\n",
      "Epoch 206/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6039.3582 - reconstruction_loss: 6033.2881 - kl_loss: 40.0171\n",
      "Epoch 207/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6056.1805 - reconstruction_loss: 6032.9658 - kl_loss: 40.2958\n",
      "Epoch 208/300\n",
      "46/46 [==============================] - 6s 122ms/step - loss: 6074.9433 - reconstruction_loss: 6034.0977 - kl_loss: 40.0578\n",
      "Epoch 209/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6054.5663 - reconstruction_loss: 6033.9185 - kl_loss: 39.5682\n",
      "Epoch 210/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6082.7552 - reconstruction_loss: 6029.4683 - kl_loss: 39.8215\n",
      "Epoch 211/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6068.4735 - reconstruction_loss: 6024.5122 - kl_loss: 39.4969\n",
      "Epoch 212/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6066.3677 - reconstruction_loss: 6026.6318 - kl_loss: 39.9811\n",
      "Epoch 213/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6087.9413 - reconstruction_loss: 6025.8750 - kl_loss: 40.0382\n",
      "Epoch 214/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6084.3417 - reconstruction_loss: 6026.4116 - kl_loss: 39.7556\n",
      "Epoch 215/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6060.3622 - reconstruction_loss: 6021.7935 - kl_loss: 39.8882\n",
      "Epoch 216/300\n",
      "46/46 [==============================] - 6s 124ms/step - loss: 6067.0576 - reconstruction_loss: 6030.4287 - kl_loss: 39.5339\n",
      "Epoch 217/300\n",
      "46/46 [==============================] - 6s 122ms/step - loss: 6057.1091 - reconstruction_loss: 6023.1338 - kl_loss: 39.5694\n",
      "Epoch 218/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6065.9219 - reconstruction_loss: 6020.3276 - kl_loss: 39.5242\n",
      "Epoch 219/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6068.3425 - reconstruction_loss: 6018.0000 - kl_loss: 39.3556\n",
      "Epoch 220/300\n",
      "46/46 [==============================] - 6s 130ms/step - loss: 6026.5923 - reconstruction_loss: 6017.6401 - kl_loss: 39.1676\n",
      "Epoch 221/300\n",
      "46/46 [==============================] - 6s 125ms/step - loss: 6029.0572 - reconstruction_loss: 6019.5273 - kl_loss: 39.3116\n",
      "Epoch 222/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6090.6433 - reconstruction_loss: 6028.0898 - kl_loss: 39.1701\n",
      "Epoch 223/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6072.6608 - reconstruction_loss: 6021.2192 - kl_loss: 39.1003\n",
      "Epoch 224/300\n",
      "46/46 [==============================] - 6s 122ms/step - loss: 6095.7891 - reconstruction_loss: 6016.8657 - kl_loss: 39.5164\n",
      "Epoch 225/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6055.6239 - reconstruction_loss: 6016.1929 - kl_loss: 39.1508\n",
      "Epoch 226/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6027.4164 - reconstruction_loss: 6013.5137 - kl_loss: 39.1581\n",
      "Epoch 227/300\n",
      "46/46 [==============================] - 6s 124ms/step - loss: 6102.1003 - reconstruction_loss: 6010.4741 - kl_loss: 39.1067\n",
      "Epoch 228/300\n",
      "46/46 [==============================] - 6s 124ms/step - loss: 6025.9247 - reconstruction_loss: 6011.7866 - kl_loss: 38.9339\n",
      "Epoch 229/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6018.7479 - reconstruction_loss: 6013.0137 - kl_loss: 38.9868\n",
      "Epoch 230/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6047.4272 - reconstruction_loss: 6008.9390 - kl_loss: 38.9785\n",
      "Epoch 231/300\n",
      "46/46 [==============================] - 6s 122ms/step - loss: 6057.8481 - reconstruction_loss: 6012.0742 - kl_loss: 39.0868\n",
      "Epoch 232/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6064.9426 - reconstruction_loss: 6009.8208 - kl_loss: 38.4996\n",
      "Epoch 233/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6036.1739 - reconstruction_loss: 6004.1357 - kl_loss: 38.5151\n",
      "Epoch 234/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6045.5369 - reconstruction_loss: 6006.4912 - kl_loss: 38.6293\n",
      "Epoch 235/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6049.3955 - reconstruction_loss: 6004.8608 - kl_loss: 38.5906\n",
      "Epoch 236/300\n",
      "46/46 [==============================] - 6s 122ms/step - loss: 6067.6025 - reconstruction_loss: 6006.0225 - kl_loss: 38.5488\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 6s 120ms/step - loss: 5988.5223 - reconstruction_loss: 6003.6646 - kl_loss: 39.0240\n",
      "Epoch 238/300\n",
      "46/46 [==============================] - 6s 122ms/step - loss: 6035.8152 - reconstruction_loss: 6002.9131 - kl_loss: 38.2805\n",
      "Epoch 239/300\n",
      "46/46 [==============================] - 6s 124ms/step - loss: 6084.9366 - reconstruction_loss: 6001.7861 - kl_loss: 38.3050\n",
      "Epoch 240/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6003.0317 - reconstruction_loss: 5999.5283 - kl_loss: 38.1069\n",
      "Epoch 241/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6037.0030 - reconstruction_loss: 5999.0972 - kl_loss: 38.0841\n",
      "Epoch 242/300\n",
      "46/46 [==============================] - 6s 122ms/step - loss: 6028.9560 - reconstruction_loss: 5997.1577 - kl_loss: 38.0391\n",
      "Epoch 243/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6048.0934 - reconstruction_loss: 5998.3838 - kl_loss: 38.3386\n",
      "Epoch 244/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6035.8323 - reconstruction_loss: 6000.5249 - kl_loss: 38.1261\n",
      "Epoch 245/300\n",
      "46/46 [==============================] - 6s 124ms/step - loss: 5999.7468 - reconstruction_loss: 6001.5918 - kl_loss: 38.0398\n",
      "Epoch 246/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6027.3669 - reconstruction_loss: 5996.9253 - kl_loss: 37.8975\n",
      "Epoch 247/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6050.3675 - reconstruction_loss: 5999.3545 - kl_loss: 37.9885\n",
      "Epoch 248/300\n",
      "46/46 [==============================] - 6s 124ms/step - loss: 6055.3593 - reconstruction_loss: 5998.5591 - kl_loss: 38.0621\n",
      "Epoch 249/300\n",
      "46/46 [==============================] - 6s 124ms/step - loss: 6019.7324 - reconstruction_loss: 5991.7485 - kl_loss: 37.7947\n",
      "Epoch 250/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6063.9108 - reconstruction_loss: 5994.4097 - kl_loss: 37.6943\n",
      "Epoch 251/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6043.9138 - reconstruction_loss: 5991.7827 - kl_loss: 37.7877\n",
      "Epoch 252/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6046.6161 - reconstruction_loss: 5991.5835 - kl_loss: 37.5548\n",
      "Epoch 253/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6003.4329 - reconstruction_loss: 5991.6440 - kl_loss: 37.8573\n",
      "Epoch 254/300\n",
      "46/46 [==============================] - 6s 122ms/step - loss: 6070.5627 - reconstruction_loss: 5990.2207 - kl_loss: 37.6245\n",
      "Epoch 255/300\n",
      "46/46 [==============================] - 6s 124ms/step - loss: 6010.9672 - reconstruction_loss: 5990.5405 - kl_loss: 37.4874\n",
      "Epoch 256/300\n",
      "46/46 [==============================] - 6s 129ms/step - loss: 5968.0587 - reconstruction_loss: 5986.4233 - kl_loss: 37.3814\n",
      "Epoch 257/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6001.7668 - reconstruction_loss: 5986.8525 - kl_loss: 37.5162\n",
      "Epoch 258/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 5959.2895 - reconstruction_loss: 5989.1255 - kl_loss: 37.2970\n",
      "Epoch 259/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6012.2826 - reconstruction_loss: 5988.5278 - kl_loss: 37.3844\n",
      "Epoch 260/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6034.4005 - reconstruction_loss: 5986.0205 - kl_loss: 37.1535\n",
      "Epoch 261/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6024.7493 - reconstruction_loss: 5984.6870 - kl_loss: 37.1771\n",
      "Epoch 262/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6039.4263 - reconstruction_loss: 5982.8975 - kl_loss: 37.1351\n",
      "Epoch 263/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6010.8463 - reconstruction_loss: 5985.4775 - kl_loss: 37.0946\n",
      "Epoch 264/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6013.3639 - reconstruction_loss: 5983.0039 - kl_loss: 36.8476\n",
      "Epoch 265/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6044.3513 - reconstruction_loss: 5980.0073 - kl_loss: 36.7723\n",
      "Epoch 266/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6017.7803 - reconstruction_loss: 5979.9375 - kl_loss: 37.1513\n",
      "Epoch 267/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 5995.4141 - reconstruction_loss: 5982.3999 - kl_loss: 37.0221\n",
      "Epoch 268/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6004.6994 - reconstruction_loss: 5978.6270 - kl_loss: 36.8248\n",
      "Epoch 269/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6012.8396 - reconstruction_loss: 5978.6792 - kl_loss: 36.6556\n",
      "Epoch 270/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6026.2992 - reconstruction_loss: 5976.5640 - kl_loss: 36.7198\n",
      "Epoch 271/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 5990.1386 - reconstruction_loss: 5978.3511 - kl_loss: 36.3311\n",
      "Epoch 272/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 5992.5134 - reconstruction_loss: 5978.5005 - kl_loss: 36.4815\n",
      "Epoch 273/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 5947.6331 - reconstruction_loss: 5976.9600 - kl_loss: 36.5651\n",
      "Epoch 274/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6054.6994 - reconstruction_loss: 5977.7783 - kl_loss: 36.3999\n",
      "Epoch 275/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6051.2017 - reconstruction_loss: 5983.0845 - kl_loss: 36.5197\n",
      "Epoch 276/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6009.5392 - reconstruction_loss: 5976.6655 - kl_loss: 36.5722\n",
      "Epoch 277/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 5959.3874 - reconstruction_loss: 5978.7080 - kl_loss: 36.4679\n",
      "Epoch 278/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6004.3779 - reconstruction_loss: 5975.4653 - kl_loss: 36.2575\n",
      "Epoch 279/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6029.4696 - reconstruction_loss: 5972.2100 - kl_loss: 36.3841\n",
      "Epoch 280/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6029.1139 - reconstruction_loss: 5972.9312 - kl_loss: 36.4007\n",
      "Epoch 281/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6015.4551 - reconstruction_loss: 5967.6943 - kl_loss: 36.3365\n",
      "Epoch 282/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6056.2993 - reconstruction_loss: 5968.9653 - kl_loss: 36.0184\n",
      "Epoch 283/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 5997.7964 - reconstruction_loss: 5966.3677 - kl_loss: 35.8802\n",
      "Epoch 284/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6020.5117 - reconstruction_loss: 5967.2417 - kl_loss: 35.9061\n",
      "Epoch 285/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6004.0359 - reconstruction_loss: 5968.7998 - kl_loss: 35.8211\n",
      "Epoch 286/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6005.4511 - reconstruction_loss: 5969.5835 - kl_loss: 35.9479\n",
      "Epoch 287/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6009.5522 - reconstruction_loss: 5965.5488 - kl_loss: 35.7554\n",
      "Epoch 288/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 5972.7908 - reconstruction_loss: 5964.6230 - kl_loss: 35.6650\n",
      "Epoch 289/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6037.5950 - reconstruction_loss: 5965.5625 - kl_loss: 35.6862\n",
      "Epoch 290/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 5995.2877 - reconstruction_loss: 5963.9058 - kl_loss: 35.7737\n",
      "Epoch 291/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 5981.9930 - reconstruction_loss: 5961.5195 - kl_loss: 35.9905\n",
      "Epoch 292/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6000.1045 - reconstruction_loss: 5962.4155 - kl_loss: 35.6590\n",
      "Epoch 293/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6011.8879 - reconstruction_loss: 5968.0137 - kl_loss: 35.7705\n",
      "Epoch 294/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 5956.3979 - reconstruction_loss: 5969.4248 - kl_loss: 35.8532\n",
      "Epoch 295/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 5982.5618 - reconstruction_loss: 5964.3442 - kl_loss: 35.3773\n",
      "Epoch 296/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 5s 116ms/step - loss: 6016.4934 - reconstruction_loss: 5962.2920 - kl_loss: 35.5392\n",
      "Epoch 297/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 5977.7235 - reconstruction_loss: 5965.9517 - kl_loss: 35.4712\n",
      "Epoch 298/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6034.4339 - reconstruction_loss: 5969.2930 - kl_loss: 35.4831\n",
      "Epoch 299/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6051.6777 - reconstruction_loss: 5963.2749 - kl_loss: 35.5262\n",
      "Epoch 300/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 5997.7243 - reconstruction_loss: 5959.5630 - kl_loss: 35.4079\n",
      "Epoch 1/300\n",
      "46/46 [==============================] - 11s 117ms/step - loss: 10183.3937 - reconstruction_loss: 9070.9160 - kl_loss: 0.6639\n",
      "Epoch 2/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 7177.7640 - reconstruction_loss: 7014.9165 - kl_loss: 25.0943\n",
      "Epoch 3/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6826.9568 - reconstruction_loss: 6853.9097 - kl_loss: 19.0869\n",
      "Epoch 4/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6789.7711 - reconstruction_loss: 6843.0796 - kl_loss: 15.6456\n",
      "Epoch 5/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6832.1503 - reconstruction_loss: 6835.9810 - kl_loss: 14.0824\n",
      "Epoch 6/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6817.3646 - reconstruction_loss: 6822.2183 - kl_loss: 14.4926\n",
      "Epoch 7/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6872.5985 - reconstruction_loss: 6791.8701 - kl_loss: 18.4885\n",
      "Epoch 8/300\n",
      "46/46 [==============================] - 6s 125ms/step - loss: 6804.2529 - reconstruction_loss: 6761.2954 - kl_loss: 21.4628\n",
      "Epoch 9/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6807.1339 - reconstruction_loss: 6744.7866 - kl_loss: 21.1602\n",
      "Epoch 10/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6754.3535 - reconstruction_loss: 6740.6455 - kl_loss: 21.1641\n",
      "Epoch 11/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6742.0142 - reconstruction_loss: 6724.9189 - kl_loss: 20.9127\n",
      "Epoch 12/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6695.6227 - reconstruction_loss: 6735.7397 - kl_loss: 20.9657\n",
      "Epoch 13/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6753.5759 - reconstruction_loss: 6714.4565 - kl_loss: 21.5846\n",
      "Epoch 14/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6754.7193 - reconstruction_loss: 6707.1411 - kl_loss: 21.8290\n",
      "Epoch 15/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6690.7932 - reconstruction_loss: 6688.1177 - kl_loss: 23.8706\n",
      "Epoch 16/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6715.2315 - reconstruction_loss: 6664.7031 - kl_loss: 27.0825\n",
      "Epoch 17/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6727.2571 - reconstruction_loss: 6657.7310 - kl_loss: 27.8114\n",
      "Epoch 18/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6671.5306 - reconstruction_loss: 6642.3989 - kl_loss: 27.7512\n",
      "Epoch 19/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6657.7039 - reconstruction_loss: 6633.8022 - kl_loss: 28.8290\n",
      "Epoch 20/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6635.7779 - reconstruction_loss: 6622.0142 - kl_loss: 29.5015\n",
      "Epoch 21/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6650.9320 - reconstruction_loss: 6610.1772 - kl_loss: 31.4143\n",
      "Epoch 22/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6630.6521 - reconstruction_loss: 6592.5889 - kl_loss: 32.4040\n",
      "Epoch 23/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6594.1881 - reconstruction_loss: 6581.6011 - kl_loss: 34.7505\n",
      "Epoch 24/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6656.3483 - reconstruction_loss: 6574.9526 - kl_loss: 35.9521\n",
      "Epoch 25/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6618.8842 - reconstruction_loss: 6566.1187 - kl_loss: 37.4875\n",
      "Epoch 26/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6561.1954 - reconstruction_loss: 6543.9761 - kl_loss: 38.0468\n",
      "Epoch 27/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6577.4946 - reconstruction_loss: 6546.8623 - kl_loss: 38.4986\n",
      "Epoch 28/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6617.6763 - reconstruction_loss: 6525.9707 - kl_loss: 39.5673\n",
      "Epoch 29/300\n",
      "46/46 [==============================] - 5s 120ms/step - loss: 6543.5454 - reconstruction_loss: 6530.4536 - kl_loss: 40.3048\n",
      "Epoch 30/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6556.6783 - reconstruction_loss: 6517.6338 - kl_loss: 40.9867\n",
      "Epoch 31/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6531.5409 - reconstruction_loss: 6516.1187 - kl_loss: 41.8858\n",
      "Epoch 32/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6514.1435 - reconstruction_loss: 6512.1670 - kl_loss: 41.3577\n",
      "Epoch 33/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6585.3399 - reconstruction_loss: 6510.4048 - kl_loss: 42.2765\n",
      "Epoch 34/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6511.8571 - reconstruction_loss: 6495.7202 - kl_loss: 43.1876\n",
      "Epoch 35/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6545.0225 - reconstruction_loss: 6497.5317 - kl_loss: 42.9885\n",
      "Epoch 36/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6529.7066 - reconstruction_loss: 6494.3042 - kl_loss: 43.8025\n",
      "Epoch 37/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6515.4680 - reconstruction_loss: 6488.2759 - kl_loss: 44.2730\n",
      "Epoch 38/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6583.7397 - reconstruction_loss: 6498.2974 - kl_loss: 43.9468\n",
      "Epoch 39/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6517.4429 - reconstruction_loss: 6478.0537 - kl_loss: 44.7380\n",
      "Epoch 40/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6480.2718 - reconstruction_loss: 6463.8540 - kl_loss: 46.4374\n",
      "Epoch 41/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6513.2467 - reconstruction_loss: 6457.1748 - kl_loss: 47.0314\n",
      "Epoch 42/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6473.4498 - reconstruction_loss: 6446.8281 - kl_loss: 48.9529\n",
      "Epoch 43/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6449.1130 - reconstruction_loss: 6444.7529 - kl_loss: 49.2989\n",
      "Epoch 44/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6472.8289 - reconstruction_loss: 6454.5522 - kl_loss: 49.3216\n",
      "Epoch 45/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6530.1636 - reconstruction_loss: 6443.3125 - kl_loss: 50.2185\n",
      "Epoch 46/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6506.6331 - reconstruction_loss: 6432.1455 - kl_loss: 49.1181\n",
      "Epoch 47/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6471.1602 - reconstruction_loss: 6432.0688 - kl_loss: 50.1052\n",
      "Epoch 48/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6503.5315 - reconstruction_loss: 6437.6768 - kl_loss: 49.4959\n",
      "Epoch 49/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6456.7423 - reconstruction_loss: 6420.7183 - kl_loss: 50.7218\n",
      "Epoch 50/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6447.4147 - reconstruction_loss: 6416.6162 - kl_loss: 49.4677\n",
      "Epoch 51/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6461.6069 - reconstruction_loss: 6421.6616 - kl_loss: 51.2523\n",
      "Epoch 52/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6408.3193 - reconstruction_loss: 6419.5332 - kl_loss: 49.8872\n",
      "Epoch 53/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6489.0049 - reconstruction_loss: 6403.5420 - kl_loss: 51.8589\n",
      "Epoch 54/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6457.0547 - reconstruction_loss: 6399.3281 - kl_loss: 51.8865\n",
      "Epoch 55/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 5s 115ms/step - loss: 6431.3556 - reconstruction_loss: 6400.9409 - kl_loss: 50.4263\n",
      "Epoch 56/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6409.9866 - reconstruction_loss: 6390.6807 - kl_loss: 52.5519\n",
      "Epoch 57/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6452.8135 - reconstruction_loss: 6391.2661 - kl_loss: 52.9434\n",
      "Epoch 58/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6469.9215 - reconstruction_loss: 6404.4780 - kl_loss: 51.7089\n",
      "Epoch 59/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6458.5796 - reconstruction_loss: 6393.2495 - kl_loss: 52.3874\n",
      "Epoch 60/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6456.5623 - reconstruction_loss: 6383.4097 - kl_loss: 51.8736\n",
      "Epoch 61/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6458.4811 - reconstruction_loss: 6377.7705 - kl_loss: 53.6876\n",
      "Epoch 62/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6418.0823 - reconstruction_loss: 6378.5029 - kl_loss: 53.5951\n",
      "Epoch 63/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6430.6963 - reconstruction_loss: 6366.3926 - kl_loss: 53.9638\n",
      "Epoch 64/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6472.3668 - reconstruction_loss: 6362.3452 - kl_loss: 54.3225\n",
      "Epoch 65/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6429.6086 - reconstruction_loss: 6365.2764 - kl_loss: 53.6629\n",
      "Epoch 66/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6404.5982 - reconstruction_loss: 6361.2412 - kl_loss: 54.7058\n",
      "Epoch 67/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6384.4148 - reconstruction_loss: 6352.7949 - kl_loss: 54.6726\n",
      "Epoch 68/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6406.5952 - reconstruction_loss: 6353.5244 - kl_loss: 53.6215\n",
      "Epoch 69/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6444.0365 - reconstruction_loss: 6348.9937 - kl_loss: 54.8565\n",
      "Epoch 70/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6398.4381 - reconstruction_loss: 6351.8188 - kl_loss: 54.4942\n",
      "Epoch 71/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6343.5343 - reconstruction_loss: 6339.5874 - kl_loss: 55.6734\n",
      "Epoch 72/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6404.1007 - reconstruction_loss: 6339.9062 - kl_loss: 54.4978\n",
      "Epoch 73/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6378.9277 - reconstruction_loss: 6333.6367 - kl_loss: 54.7736\n",
      "Epoch 74/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6415.4492 - reconstruction_loss: 6330.5591 - kl_loss: 55.4600\n",
      "Epoch 75/300\n",
      "46/46 [==============================] - 5s 120ms/step - loss: 6371.3184 - reconstruction_loss: 6327.8911 - kl_loss: 55.7516\n",
      "Epoch 76/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6406.3559 - reconstruction_loss: 6326.7705 - kl_loss: 55.0913\n",
      "Epoch 77/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6356.8916 - reconstruction_loss: 6324.3071 - kl_loss: 55.8738\n",
      "Epoch 78/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6364.2672 - reconstruction_loss: 6318.1982 - kl_loss: 55.4717\n",
      "Epoch 79/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6339.7992 - reconstruction_loss: 6317.6323 - kl_loss: 55.1975\n",
      "Epoch 80/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6380.3541 - reconstruction_loss: 6320.6313 - kl_loss: 55.2111\n",
      "Epoch 81/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6417.9384 - reconstruction_loss: 6313.3784 - kl_loss: 55.1530\n",
      "Epoch 82/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6350.0390 - reconstruction_loss: 6309.8647 - kl_loss: 55.4385\n",
      "Epoch 83/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6380.5322 - reconstruction_loss: 6308.0942 - kl_loss: 54.5325\n",
      "Epoch 84/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6359.2677 - reconstruction_loss: 6306.0972 - kl_loss: 55.4773\n",
      "Epoch 85/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6336.3354 - reconstruction_loss: 6299.2534 - kl_loss: 54.9911\n",
      "Epoch 86/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6342.1527 - reconstruction_loss: 6299.5332 - kl_loss: 55.0831\n",
      "Epoch 87/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6343.2075 - reconstruction_loss: 6290.4482 - kl_loss: 55.2540\n",
      "Epoch 88/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6355.4141 - reconstruction_loss: 6282.9497 - kl_loss: 55.3040\n",
      "Epoch 89/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6344.3646 - reconstruction_loss: 6283.2896 - kl_loss: 55.7214\n",
      "Epoch 90/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6302.6026 - reconstruction_loss: 6277.6494 - kl_loss: 55.4558\n",
      "Epoch 91/300\n",
      "46/46 [==============================] - 6s 119ms/step - loss: 6308.3631 - reconstruction_loss: 6274.9844 - kl_loss: 56.3949\n",
      "Epoch 92/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6333.2836 - reconstruction_loss: 6281.3408 - kl_loss: 55.5576\n",
      "Epoch 93/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6312.1318 - reconstruction_loss: 6272.6929 - kl_loss: 55.2542\n",
      "Epoch 94/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6339.7210 - reconstruction_loss: 6270.4463 - kl_loss: 56.1214\n",
      "Epoch 95/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6310.6085 - reconstruction_loss: 6278.1113 - kl_loss: 54.9166\n",
      "Epoch 96/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6339.4746 - reconstruction_loss: 6265.7095 - kl_loss: 56.4994\n",
      "Epoch 97/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6284.4194 - reconstruction_loss: 6256.1470 - kl_loss: 55.5538\n",
      "Epoch 98/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6304.3889 - reconstruction_loss: 6258.0117 - kl_loss: 55.8306\n",
      "Epoch 99/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6327.3479 - reconstruction_loss: 6253.8369 - kl_loss: 55.3714\n",
      "Epoch 100/300\n",
      "46/46 [==============================] - 6s 119ms/step - loss: 6296.3961 - reconstruction_loss: 6252.3267 - kl_loss: 55.6555\n",
      "Epoch 101/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6375.7231 - reconstruction_loss: 6252.4531 - kl_loss: 55.3832\n",
      "Epoch 102/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6285.5786 - reconstruction_loss: 6240.1787 - kl_loss: 55.7742\n",
      "Epoch 103/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6247.0201 - reconstruction_loss: 6236.6313 - kl_loss: 55.6520\n",
      "Epoch 104/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6266.2712 - reconstruction_loss: 6240.7339 - kl_loss: 55.5189\n",
      "Epoch 105/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6263.2647 - reconstruction_loss: 6231.7012 - kl_loss: 54.4819\n",
      "Epoch 106/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6290.6791 - reconstruction_loss: 6239.7290 - kl_loss: 54.5378\n",
      "Epoch 107/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6281.3818 - reconstruction_loss: 6228.2505 - kl_loss: 55.0459\n",
      "Epoch 108/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6261.6900 - reconstruction_loss: 6230.3843 - kl_loss: 55.2001\n",
      "Epoch 109/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6277.5485 - reconstruction_loss: 6222.7241 - kl_loss: 55.1959\n",
      "Epoch 110/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6266.3028 - reconstruction_loss: 6218.8403 - kl_loss: 54.4005\n",
      "Epoch 111/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6266.8146 - reconstruction_loss: 6232.5054 - kl_loss: 54.8082\n",
      "Epoch 112/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6274.6188 - reconstruction_loss: 6214.7783 - kl_loss: 54.5716\n",
      "Epoch 113/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6299.0351 - reconstruction_loss: 6220.1802 - kl_loss: 54.4812\n",
      "Epoch 114/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 5s 118ms/step - loss: 6236.8687 - reconstruction_loss: 6211.9824 - kl_loss: 54.8240\n",
      "Epoch 115/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6257.3781 - reconstruction_loss: 6214.2085 - kl_loss: 54.7636\n",
      "Epoch 116/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6236.5181 - reconstruction_loss: 6210.2988 - kl_loss: 53.6079\n",
      "Epoch 117/300\n",
      "46/46 [==============================] - 6s 127ms/step - loss: 6286.7113 - reconstruction_loss: 6207.0107 - kl_loss: 54.2921\n",
      "Epoch 118/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6237.6620 - reconstruction_loss: 6201.3599 - kl_loss: 53.9011\n",
      "Epoch 119/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6272.3587 - reconstruction_loss: 6203.8281 - kl_loss: 54.2881\n",
      "Epoch 120/300\n",
      "46/46 [==============================] - 6s 122ms/step - loss: 6245.7861 - reconstruction_loss: 6201.5376 - kl_loss: 53.7348\n",
      "Epoch 121/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6213.5026 - reconstruction_loss: 6196.4526 - kl_loss: 54.1699\n",
      "Epoch 122/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6255.3707 - reconstruction_loss: 6189.8398 - kl_loss: 54.3406\n",
      "Epoch 123/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6229.6776 - reconstruction_loss: 6193.8076 - kl_loss: 53.7357\n",
      "Epoch 124/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6262.2438 - reconstruction_loss: 6194.9219 - kl_loss: 53.2934\n",
      "Epoch 125/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6228.1180 - reconstruction_loss: 6183.2046 - kl_loss: 53.4337\n",
      "Epoch 126/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6267.5669 - reconstruction_loss: 6180.7983 - kl_loss: 53.3138\n",
      "Epoch 127/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6205.1210 - reconstruction_loss: 6184.8188 - kl_loss: 53.1370\n",
      "Epoch 128/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6228.2213 - reconstruction_loss: 6183.3491 - kl_loss: 53.7920\n",
      "Epoch 129/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6214.9972 - reconstruction_loss: 6176.4375 - kl_loss: 52.8761\n",
      "Epoch 130/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6232.6889 - reconstruction_loss: 6173.1489 - kl_loss: 52.8415\n",
      "Epoch 131/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6241.0800 - reconstruction_loss: 6172.3247 - kl_loss: 53.3230\n",
      "Epoch 132/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6247.4391 - reconstruction_loss: 6169.7690 - kl_loss: 52.0175\n",
      "Epoch 133/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6272.1943 - reconstruction_loss: 6168.5693 - kl_loss: 53.3126\n",
      "Epoch 134/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6284.6488 - reconstruction_loss: 6166.9355 - kl_loss: 52.8958\n",
      "Epoch 135/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6196.2183 - reconstruction_loss: 6160.3486 - kl_loss: 52.6584\n",
      "Epoch 136/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6187.4841 - reconstruction_loss: 6162.6201 - kl_loss: 52.7920\n",
      "Epoch 137/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6207.5585 - reconstruction_loss: 6155.9995 - kl_loss: 52.6275\n",
      "Epoch 138/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6225.8139 - reconstruction_loss: 6155.6333 - kl_loss: 51.9690\n",
      "Epoch 139/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6206.9429 - reconstruction_loss: 6155.0264 - kl_loss: 51.7723\n",
      "Epoch 140/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6225.5390 - reconstruction_loss: 6154.2461 - kl_loss: 52.6221\n",
      "Epoch 141/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6219.9519 - reconstruction_loss: 6153.1333 - kl_loss: 52.1773\n",
      "Epoch 142/300\n",
      "46/46 [==============================] - 6s 124ms/step - loss: 6166.9411 - reconstruction_loss: 6147.3423 - kl_loss: 51.8139\n",
      "Epoch 143/300\n",
      "46/46 [==============================] - 6s 124ms/step - loss: 6174.0334 - reconstruction_loss: 6142.9082 - kl_loss: 51.7500\n",
      "Epoch 144/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6255.6053 - reconstruction_loss: 6143.1235 - kl_loss: 51.5027\n",
      "Epoch 145/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6186.1590 - reconstruction_loss: 6144.1250 - kl_loss: 51.7198\n",
      "Epoch 146/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6183.0428 - reconstruction_loss: 6136.6030 - kl_loss: 51.6661\n",
      "Epoch 147/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6145.1279 - reconstruction_loss: 6139.7690 - kl_loss: 51.6793\n",
      "Epoch 148/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6161.4495 - reconstruction_loss: 6133.6772 - kl_loss: 51.1180\n",
      "Epoch 149/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6190.7081 - reconstruction_loss: 6136.8154 - kl_loss: 51.0655\n",
      "Epoch 150/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6171.3999 - reconstruction_loss: 6128.2383 - kl_loss: 51.8172\n",
      "Epoch 151/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6148.1107 - reconstruction_loss: 6123.7158 - kl_loss: 50.9002\n",
      "Epoch 152/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6209.6023 - reconstruction_loss: 6126.2222 - kl_loss: 51.0495\n",
      "Epoch 153/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6227.1787 - reconstruction_loss: 6129.7827 - kl_loss: 51.1472\n",
      "Epoch 154/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6172.7954 - reconstruction_loss: 6130.6421 - kl_loss: 51.4420\n",
      "Epoch 155/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6160.2906 - reconstruction_loss: 6124.7710 - kl_loss: 51.6871\n",
      "Epoch 156/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6167.9523 - reconstruction_loss: 6115.1807 - kl_loss: 50.9949\n",
      "Epoch 157/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6131.6426 - reconstruction_loss: 6118.7817 - kl_loss: 50.1228\n",
      "Epoch 158/300\n",
      "46/46 [==============================] - 6s 122ms/step - loss: 6210.7142 - reconstruction_loss: 6118.5586 - kl_loss: 50.6698\n",
      "Epoch 159/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6142.0635 - reconstruction_loss: 6116.9248 - kl_loss: 50.2555\n",
      "Epoch 160/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6151.8859 - reconstruction_loss: 6114.8037 - kl_loss: 50.3784\n",
      "Epoch 161/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6196.1484 - reconstruction_loss: 6115.3955 - kl_loss: 49.9925\n",
      "Epoch 162/300\n",
      "46/46 [==============================] - 5s 120ms/step - loss: 6204.1370 - reconstruction_loss: 6115.9131 - kl_loss: 50.2108\n",
      "Epoch 163/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6208.8988 - reconstruction_loss: 6119.0801 - kl_loss: 50.2964\n",
      "Epoch 164/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6164.7439 - reconstruction_loss: 6105.0776 - kl_loss: 50.4297\n",
      "Epoch 165/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6143.7210 - reconstruction_loss: 6100.8330 - kl_loss: 49.7922\n",
      "Epoch 166/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6148.9129 - reconstruction_loss: 6098.2183 - kl_loss: 49.3201\n",
      "Epoch 167/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6101.5542 - reconstruction_loss: 6096.7793 - kl_loss: 50.2044\n",
      "Epoch 168/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6136.0877 - reconstruction_loss: 6095.6782 - kl_loss: 49.5896\n",
      "Epoch 169/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6126.0553 - reconstruction_loss: 6096.1387 - kl_loss: 49.5420\n",
      "Epoch 170/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6157.8427 - reconstruction_loss: 6092.9653 - kl_loss: 49.4470\n",
      "Epoch 171/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6145.8557 - reconstruction_loss: 6093.0518 - kl_loss: 49.0766\n",
      "Epoch 172/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6143.4428 - reconstruction_loss: 6093.0352 - kl_loss: 49.8431\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 5s 113ms/step - loss: 6162.2097 - reconstruction_loss: 6092.7783 - kl_loss: 48.9286\n",
      "Epoch 174/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6111.5519 - reconstruction_loss: 6086.9775 - kl_loss: 49.5184\n",
      "Epoch 175/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6177.4797 - reconstruction_loss: 6082.6270 - kl_loss: 49.2932\n",
      "Epoch 176/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6156.0527 - reconstruction_loss: 6092.0952 - kl_loss: 49.2273\n",
      "Epoch 177/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6141.9100 - reconstruction_loss: 6089.6333 - kl_loss: 48.6141\n",
      "Epoch 178/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6134.1070 - reconstruction_loss: 6086.5576 - kl_loss: 48.7344\n",
      "Epoch 179/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6189.6386 - reconstruction_loss: 6084.3091 - kl_loss: 48.8576\n",
      "Epoch 180/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6119.5644 - reconstruction_loss: 6082.6201 - kl_loss: 48.3499\n",
      "Epoch 181/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6155.6201 - reconstruction_loss: 6080.3633 - kl_loss: 49.0676\n",
      "Epoch 182/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6080.2274 - reconstruction_loss: 6076.6299 - kl_loss: 48.1136\n",
      "Epoch 183/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6153.7567 - reconstruction_loss: 6081.6558 - kl_loss: 48.0736\n",
      "Epoch 184/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6111.7857 - reconstruction_loss: 6082.1289 - kl_loss: 47.9029\n",
      "Epoch 185/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6125.6431 - reconstruction_loss: 6071.0972 - kl_loss: 48.0377\n",
      "Epoch 186/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6097.5339 - reconstruction_loss: 6071.6099 - kl_loss: 47.9222\n",
      "Epoch 187/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6121.6579 - reconstruction_loss: 6069.7920 - kl_loss: 48.0640\n",
      "Epoch 188/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6142.4057 - reconstruction_loss: 6063.2451 - kl_loss: 47.9148\n",
      "Epoch 189/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6113.7856 - reconstruction_loss: 6061.9526 - kl_loss: 47.5458\n",
      "Epoch 190/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6077.9243 - reconstruction_loss: 6068.0674 - kl_loss: 47.4051\n",
      "Epoch 191/300\n",
      "46/46 [==============================] - 6s 122ms/step - loss: 6121.3473 - reconstruction_loss: 6060.8320 - kl_loss: 47.6096\n",
      "Epoch 192/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6115.1149 - reconstruction_loss: 6057.1489 - kl_loss: 47.2010\n",
      "Epoch 193/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6103.2881 - reconstruction_loss: 6054.0435 - kl_loss: 47.4644\n",
      "Epoch 194/300\n",
      "46/46 [==============================] - 6s 130ms/step - loss: 6115.9773 - reconstruction_loss: 6054.5186 - kl_loss: 47.1451\n",
      "Epoch 195/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6087.1169 - reconstruction_loss: 6061.0029 - kl_loss: 47.0171\n",
      "Epoch 196/300\n",
      "46/46 [==============================] - 6s 122ms/step - loss: 6103.8916 - reconstruction_loss: 6054.7432 - kl_loss: 46.8881\n",
      "Epoch 197/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6060.2801 - reconstruction_loss: 6053.5640 - kl_loss: 47.2636\n",
      "Epoch 198/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6117.0038 - reconstruction_loss: 6055.1689 - kl_loss: 46.8218\n",
      "Epoch 199/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6060.5224 - reconstruction_loss: 6053.8091 - kl_loss: 46.7117\n",
      "Epoch 200/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6142.4301 - reconstruction_loss: 6053.8687 - kl_loss: 46.7642\n",
      "Epoch 201/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6079.0289 - reconstruction_loss: 6056.7915 - kl_loss: 46.2381\n",
      "Epoch 202/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6098.9192 - reconstruction_loss: 6046.0884 - kl_loss: 46.4285\n",
      "Epoch 203/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6109.8678 - reconstruction_loss: 6043.2935 - kl_loss: 46.2901\n",
      "Epoch 204/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6081.6639 - reconstruction_loss: 6044.0889 - kl_loss: 46.2489\n",
      "Epoch 205/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6085.1208 - reconstruction_loss: 6042.3784 - kl_loss: 45.8510\n",
      "Epoch 206/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6110.2300 - reconstruction_loss: 6041.5625 - kl_loss: 46.1896\n",
      "Epoch 207/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6052.9962 - reconstruction_loss: 6041.9380 - kl_loss: 45.1434\n",
      "Epoch 208/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6084.3349 - reconstruction_loss: 6047.8574 - kl_loss: 45.7615\n",
      "Epoch 209/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6114.2189 - reconstruction_loss: 6041.6045 - kl_loss: 45.9896\n",
      "Epoch 210/300\n",
      "46/46 [==============================] - 6s 124ms/step - loss: 6080.3967 - reconstruction_loss: 6040.3716 - kl_loss: 45.6374\n",
      "Epoch 211/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6094.8091 - reconstruction_loss: 6034.7471 - kl_loss: 45.9029\n",
      "Epoch 212/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6049.3701 - reconstruction_loss: 6034.0596 - kl_loss: 45.4246\n",
      "Epoch 213/300\n",
      "46/46 [==============================] - 6s 122ms/step - loss: 6070.5910 - reconstruction_loss: 6032.8911 - kl_loss: 45.1443\n",
      "Epoch 214/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6082.7412 - reconstruction_loss: 6031.3086 - kl_loss: 45.1072\n",
      "Epoch 215/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6064.8982 - reconstruction_loss: 6034.8130 - kl_loss: 45.4699\n",
      "Epoch 216/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6065.4664 - reconstruction_loss: 6029.9468 - kl_loss: 45.4100\n",
      "Epoch 217/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6037.5324 - reconstruction_loss: 6028.4424 - kl_loss: 44.7315\n",
      "Epoch 218/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6121.9337 - reconstruction_loss: 6024.7729 - kl_loss: 44.5636\n",
      "Epoch 219/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6079.9868 - reconstruction_loss: 6026.0522 - kl_loss: 44.5944\n",
      "Epoch 220/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6044.5607 - reconstruction_loss: 6030.2827 - kl_loss: 44.4679\n",
      "Epoch 221/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6049.9267 - reconstruction_loss: 6024.0728 - kl_loss: 44.3474\n",
      "Epoch 222/300\n",
      "46/46 [==============================] - 6s 122ms/step - loss: 6049.9373 - reconstruction_loss: 6025.3262 - kl_loss: 44.3039\n",
      "Epoch 223/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6039.3892 - reconstruction_loss: 6022.5122 - kl_loss: 44.2044\n",
      "Epoch 224/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6065.1507 - reconstruction_loss: 6023.0278 - kl_loss: 44.2369\n",
      "Epoch 225/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6071.1764 - reconstruction_loss: 6019.6968 - kl_loss: 44.1877\n",
      "Epoch 226/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6023.3806 - reconstruction_loss: 6017.3525 - kl_loss: 43.6309\n",
      "Epoch 227/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6057.1812 - reconstruction_loss: 6017.0156 - kl_loss: 43.4543\n",
      "Epoch 228/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6045.6488 - reconstruction_loss: 6013.8423 - kl_loss: 43.8307\n",
      "Epoch 229/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6087.9757 - reconstruction_loss: 6015.8467 - kl_loss: 43.6565\n",
      "Epoch 230/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6058.0573 - reconstruction_loss: 6012.6948 - kl_loss: 43.8383\n",
      "Epoch 231/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6041.3086 - reconstruction_loss: 6011.6826 - kl_loss: 43.4371\n",
      "Epoch 232/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 6s 121ms/step - loss: 6073.7183 - reconstruction_loss: 6012.9292 - kl_loss: 43.6777\n",
      "Epoch 233/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6031.6108 - reconstruction_loss: 6011.7642 - kl_loss: 43.3543\n",
      "Epoch 234/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6035.9980 - reconstruction_loss: 6013.3687 - kl_loss: 43.3616\n",
      "Epoch 235/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6020.3916 - reconstruction_loss: 6008.2515 - kl_loss: 42.8665\n",
      "Epoch 236/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6055.3469 - reconstruction_loss: 6008.9062 - kl_loss: 43.1831\n",
      "Epoch 237/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6028.8437 - reconstruction_loss: 6007.5190 - kl_loss: 43.2120\n",
      "Epoch 238/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6066.0918 - reconstruction_loss: 6007.5347 - kl_loss: 42.8725\n",
      "Epoch 239/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6029.5957 - reconstruction_loss: 6005.4033 - kl_loss: 43.0659\n",
      "Epoch 240/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6049.3945 - reconstruction_loss: 6006.4897 - kl_loss: 42.4102\n",
      "Epoch 241/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6061.6715 - reconstruction_loss: 6002.7427 - kl_loss: 42.5441\n",
      "Epoch 242/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6039.0181 - reconstruction_loss: 6003.0708 - kl_loss: 42.5593\n",
      "Epoch 243/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6070.6381 - reconstruction_loss: 6001.5864 - kl_loss: 42.2570\n",
      "Epoch 244/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6034.1165 - reconstruction_loss: 6004.2881 - kl_loss: 42.4644\n",
      "Epoch 245/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6040.0844 - reconstruction_loss: 6005.3838 - kl_loss: 42.4424\n",
      "Epoch 246/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6042.7972 - reconstruction_loss: 5998.3477 - kl_loss: 42.6134\n",
      "Epoch 247/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6026.5054 - reconstruction_loss: 5998.8662 - kl_loss: 42.2911\n",
      "Epoch 248/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6040.2759 - reconstruction_loss: 5993.1646 - kl_loss: 42.0560\n",
      "Epoch 249/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6025.2980 - reconstruction_loss: 5997.5781 - kl_loss: 42.2915\n",
      "Epoch 250/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 5976.3822 - reconstruction_loss: 5995.7759 - kl_loss: 42.3090\n",
      "Epoch 251/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6020.5098 - reconstruction_loss: 5990.8716 - kl_loss: 41.8920\n",
      "Epoch 252/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6032.4426 - reconstruction_loss: 5993.0449 - kl_loss: 41.6649\n",
      "Epoch 253/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6027.9315 - reconstruction_loss: 6000.9429 - kl_loss: 41.2553\n",
      "Epoch 254/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 5999.0025 - reconstruction_loss: 5994.8369 - kl_loss: 41.5192\n",
      "Epoch 255/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6024.7322 - reconstruction_loss: 5991.9966 - kl_loss: 41.6888\n",
      "Epoch 256/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6014.7572 - reconstruction_loss: 5990.5835 - kl_loss: 41.5100\n",
      "Epoch 257/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6013.3716 - reconstruction_loss: 5987.8789 - kl_loss: 41.6789\n",
      "Epoch 258/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6009.4119 - reconstruction_loss: 5983.9370 - kl_loss: 41.6051\n",
      "Epoch 259/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6020.0828 - reconstruction_loss: 5988.6011 - kl_loss: 41.6489\n",
      "Epoch 260/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6042.9688 - reconstruction_loss: 5987.8052 - kl_loss: 41.3294\n",
      "Epoch 261/300\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 6059.9920 - reconstruction_loss: 5989.4951 - kl_loss: 41.3794\n",
      "Epoch 262/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6030.1061 - reconstruction_loss: 5986.4058 - kl_loss: 41.1877\n",
      "Epoch 263/300\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 6030.2404 - reconstruction_loss: 5982.6406 - kl_loss: 41.0422\n",
      "Epoch 264/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6018.3476 - reconstruction_loss: 5982.4438 - kl_loss: 41.1678\n",
      "Epoch 265/300\n",
      "46/46 [==============================] - 6s 126ms/step - loss: 6023.3076 - reconstruction_loss: 5982.6758 - kl_loss: 41.0022\n",
      "Epoch 266/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 5990.6755 - reconstruction_loss: 5982.6460 - kl_loss: 41.0383\n",
      "Epoch 267/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 5999.4162 - reconstruction_loss: 5979.3511 - kl_loss: 40.9902\n",
      "Epoch 268/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6008.0524 - reconstruction_loss: 5978.2002 - kl_loss: 40.7333\n",
      "Epoch 269/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 6056.0910 - reconstruction_loss: 5978.5967 - kl_loss: 40.7784\n",
      "Epoch 270/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 5991.1665 - reconstruction_loss: 5981.2534 - kl_loss: 40.7061\n",
      "Epoch 271/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6030.7762 - reconstruction_loss: 5978.0029 - kl_loss: 40.7949\n",
      "Epoch 272/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6011.4582 - reconstruction_loss: 5975.2798 - kl_loss: 40.5591\n",
      "Epoch 273/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6033.7638 - reconstruction_loss: 5974.8032 - kl_loss: 40.5943\n",
      "Epoch 274/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 5976.7773 - reconstruction_loss: 5976.7217 - kl_loss: 40.3001\n",
      "Epoch 275/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6006.0268 - reconstruction_loss: 5974.2256 - kl_loss: 40.2729\n",
      "Epoch 276/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6003.5614 - reconstruction_loss: 5979.7778 - kl_loss: 40.3062\n",
      "Epoch 277/300\n",
      "46/46 [==============================] - 6s 121ms/step - loss: 6008.9111 - reconstruction_loss: 5975.8921 - kl_loss: 40.2465\n",
      "Epoch 278/300\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 6015.5038 - reconstruction_loss: 5971.7749 - kl_loss: 40.0332\n",
      "Epoch 279/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 5993.3385 - reconstruction_loss: 5969.5073 - kl_loss: 40.1810\n",
      "Epoch 280/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 5994.3478 - reconstruction_loss: 5970.6748 - kl_loss: 39.5995\n",
      "Epoch 281/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6010.2978 - reconstruction_loss: 5971.4185 - kl_loss: 39.8397\n",
      "Epoch 282/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 5986.6627 - reconstruction_loss: 5971.1313 - kl_loss: 39.6981\n",
      "Epoch 283/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 5990.9797 - reconstruction_loss: 5968.5205 - kl_loss: 39.8756\n",
      "Epoch 284/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6043.4466 - reconstruction_loss: 5965.8179 - kl_loss: 39.4770\n",
      "Epoch 285/300\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 5969.2021 - reconstruction_loss: 5967.5986 - kl_loss: 39.6264\n",
      "Epoch 286/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 5980.6428 - reconstruction_loss: 5968.8433 - kl_loss: 39.7531\n",
      "Epoch 287/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6011.7974 - reconstruction_loss: 5966.3062 - kl_loss: 39.9293\n",
      "Epoch 288/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 5984.4719 - reconstruction_loss: 5967.5625 - kl_loss: 39.8331\n",
      "Epoch 289/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6035.4374 - reconstruction_loss: 5967.2407 - kl_loss: 39.3175\n",
      "Epoch 290/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6008.6301 - reconstruction_loss: 5964.9321 - kl_loss: 39.7224\n",
      "Epoch 291/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 5s 116ms/step - loss: 6024.2338 - reconstruction_loss: 5963.6064 - kl_loss: 39.6592\n",
      "Epoch 292/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 5991.0565 - reconstruction_loss: 5963.2202 - kl_loss: 39.4053\n",
      "Epoch 293/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 5994.0823 - reconstruction_loss: 5961.7817 - kl_loss: 39.5189\n",
      "Epoch 294/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 6015.7800 - reconstruction_loss: 5964.1719 - kl_loss: 39.4378\n",
      "Epoch 295/300\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 6010.0438 - reconstruction_loss: 5962.0518 - kl_loss: 39.5647\n",
      "Epoch 296/300\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 5995.8950 - reconstruction_loss: 5963.2104 - kl_loss: 39.3425\n",
      "Epoch 297/300\n",
      "46/46 [==============================] - 5s 114ms/step - loss: 6007.9036 - reconstruction_loss: 5960.4907 - kl_loss: 39.1231\n",
      "Epoch 298/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 6029.0734 - reconstruction_loss: 5961.4624 - kl_loss: 38.9350\n",
      "Epoch 299/300\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 5997.7541 - reconstruction_loss: 5959.6494 - kl_loss: 39.0992\n",
      "Epoch 300/300\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 6017.2914 - reconstruction_loss: 5963.2119 - kl_loss: 38.7417\n",
      "Epoch 1/300\n",
      "46/46 [==============================] - 24s 236ms/step - loss: 11037.8811 - reconstruction_loss: 10667.8223 - kl_loss: 0.3404\n",
      "Epoch 2/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 8800.0939 - reconstruction_loss: 8243.9268 - kl_loss: 3.4030\n",
      "Epoch 3/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 7317.4501 - reconstruction_loss: 7109.9346 - kl_loss: 22.1236\n",
      "Epoch 4/300\n",
      "46/46 [==============================] - 8s 180ms/step - loss: 6912.7396 - reconstruction_loss: 6878.0171 - kl_loss: 16.8527\n",
      "Epoch 5/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6877.9532 - reconstruction_loss: 6862.6636 - kl_loss: 14.6810\n",
      "Epoch 6/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6885.8055 - reconstruction_loss: 6848.9497 - kl_loss: 13.4512\n",
      "Epoch 7/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6862.1934 - reconstruction_loss: 6834.2393 - kl_loss: 13.8442\n",
      "Epoch 8/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6875.4289 - reconstruction_loss: 6827.9468 - kl_loss: 13.4312\n",
      "Epoch 9/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6783.7459 - reconstruction_loss: 6820.5708 - kl_loss: 13.4880\n",
      "Epoch 10/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6850.6152 - reconstruction_loss: 6809.8906 - kl_loss: 15.1102\n",
      "Epoch 11/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6872.1718 - reconstruction_loss: 6801.3979 - kl_loss: 16.7480\n",
      "Epoch 12/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6766.7408 - reconstruction_loss: 6776.0742 - kl_loss: 18.4565\n",
      "Epoch 13/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6783.4781 - reconstruction_loss: 6749.6807 - kl_loss: 18.9375\n",
      "Epoch 14/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6695.9599 - reconstruction_loss: 6740.7686 - kl_loss: 19.2007\n",
      "Epoch 15/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6768.3146 - reconstruction_loss: 6732.4526 - kl_loss: 19.7643\n",
      "Epoch 16/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6783.9861 - reconstruction_loss: 6708.9375 - kl_loss: 21.3336\n",
      "Epoch 17/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6655.3588 - reconstruction_loss: 6687.3521 - kl_loss: 23.2571\n",
      "Epoch 18/300\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 6708.2523 - reconstruction_loss: 6666.1392 - kl_loss: 23.5636\n",
      "Epoch 19/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6640.4762 - reconstruction_loss: 6643.5620 - kl_loss: 25.2069\n",
      "Epoch 20/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6647.1035 - reconstruction_loss: 6629.9116 - kl_loss: 26.4373\n",
      "Epoch 21/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6639.2659 - reconstruction_loss: 6611.9653 - kl_loss: 26.6862\n",
      "Epoch 22/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6651.9563 - reconstruction_loss: 6604.3154 - kl_loss: 27.2668\n",
      "Epoch 23/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6644.5912 - reconstruction_loss: 6580.5503 - kl_loss: 27.4925\n",
      "Epoch 24/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6575.7960 - reconstruction_loss: 6586.3301 - kl_loss: 27.7278\n",
      "Epoch 25/300\n",
      "46/46 [==============================] - 8s 179ms/step - loss: 6643.1671 - reconstruction_loss: 6578.4907 - kl_loss: 28.6502\n",
      "Epoch 26/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6654.7082 - reconstruction_loss: 6576.9360 - kl_loss: 27.9286\n",
      "Epoch 27/300\n",
      "46/46 [==============================] - 8s 180ms/step - loss: 6596.8481 - reconstruction_loss: 6565.1440 - kl_loss: 28.0409\n",
      "Epoch 28/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6581.7150 - reconstruction_loss: 6558.5762 - kl_loss: 28.3078\n",
      "Epoch 29/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6601.6156 - reconstruction_loss: 6547.8228 - kl_loss: 27.5248\n",
      "Epoch 30/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6604.5586 - reconstruction_loss: 6541.4565 - kl_loss: 28.3264\n",
      "Epoch 31/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6570.9454 - reconstruction_loss: 6540.5967 - kl_loss: 27.9111\n",
      "Epoch 32/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6517.6402 - reconstruction_loss: 6539.2808 - kl_loss: 27.9679\n",
      "Epoch 33/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6586.8960 - reconstruction_loss: 6543.6719 - kl_loss: 27.2542\n",
      "Epoch 34/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6564.2454 - reconstruction_loss: 6528.6499 - kl_loss: 28.1544\n",
      "Epoch 35/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6579.9434 - reconstruction_loss: 6532.3608 - kl_loss: 28.2625\n",
      "Epoch 36/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6548.0515 - reconstruction_loss: 6517.5537 - kl_loss: 28.5783\n",
      "Epoch 37/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6520.2515 - reconstruction_loss: 6513.9111 - kl_loss: 28.8181\n",
      "Epoch 38/300\n",
      "46/46 [==============================] - 8s 180ms/step - loss: 6515.2075 - reconstruction_loss: 6506.6279 - kl_loss: 28.8176\n",
      "Epoch 39/300\n",
      "46/46 [==============================] - 8s 182ms/step - loss: 6551.2849 - reconstruction_loss: 6492.3276 - kl_loss: 30.3810\n",
      "Epoch 40/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6467.2746 - reconstruction_loss: 6485.1733 - kl_loss: 30.1111\n",
      "Epoch 41/300\n",
      "46/46 [==============================] - 8s 181ms/step - loss: 6511.8044 - reconstruction_loss: 6488.0298 - kl_loss: 30.7654\n",
      "Epoch 42/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6452.3896 - reconstruction_loss: 6472.9443 - kl_loss: 30.0213\n",
      "Epoch 43/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6511.6304 - reconstruction_loss: 6457.6855 - kl_loss: 30.8691\n",
      "Epoch 44/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6504.9762 - reconstruction_loss: 6463.5571 - kl_loss: 30.9304\n",
      "Epoch 45/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6495.2459 - reconstruction_loss: 6465.7876 - kl_loss: 31.0868\n",
      "Epoch 46/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6479.1694 - reconstruction_loss: 6455.8042 - kl_loss: 31.9106\n",
      "Epoch 47/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6488.6143 - reconstruction_loss: 6441.8711 - kl_loss: 32.5548\n",
      "Epoch 48/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6486.7759 - reconstruction_loss: 6439.4048 - kl_loss: 32.6617\n",
      "Epoch 49/300\n",
      "46/46 [==============================] - 9s 200ms/step - loss: 6487.2570 - reconstruction_loss: 6440.7773 - kl_loss: 32.8606\n",
      "Epoch 50/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 9s 199ms/step - loss: 6486.5425 - reconstruction_loss: 6420.9600 - kl_loss: 33.1516\n",
      "Epoch 51/300\n",
      "46/46 [==============================] - 9s 197ms/step - loss: 6382.9305 - reconstruction_loss: 6419.0469 - kl_loss: 33.3107\n",
      "Epoch 52/300\n",
      "46/46 [==============================] - 9s 193ms/step - loss: 6396.1244 - reconstruction_loss: 6419.2280 - kl_loss: 33.0147\n",
      "Epoch 53/300\n",
      "46/46 [==============================] - 9s 204ms/step - loss: 6413.9517 - reconstruction_loss: 6415.6187 - kl_loss: 33.8435\n",
      "Epoch 54/300\n",
      "46/46 [==============================] - 9s 199ms/step - loss: 6438.2873 - reconstruction_loss: 6399.9673 - kl_loss: 33.6030\n",
      "Epoch 55/300\n",
      "46/46 [==============================] - 9s 193ms/step - loss: 6455.3618 - reconstruction_loss: 6398.2983 - kl_loss: 34.3051\n",
      "Epoch 56/300\n",
      "46/46 [==============================] - 9s 190ms/step - loss: 6455.1076 - reconstruction_loss: 6412.6636 - kl_loss: 34.0867\n",
      "Epoch 57/300\n",
      "46/46 [==============================] - 9s 192ms/step - loss: 6456.6994 - reconstruction_loss: 6396.2529 - kl_loss: 33.7071\n",
      "Epoch 58/300\n",
      "46/46 [==============================] - 9s 193ms/step - loss: 6414.1004 - reconstruction_loss: 6388.4077 - kl_loss: 34.1304\n",
      "Epoch 59/300\n",
      "46/46 [==============================] - 9s 192ms/step - loss: 6411.0260 - reconstruction_loss: 6389.2148 - kl_loss: 33.9877\n",
      "Epoch 60/300\n",
      "46/46 [==============================] - 9s 190ms/step - loss: 6438.6345 - reconstruction_loss: 6373.8408 - kl_loss: 34.2201\n",
      "Epoch 61/300\n",
      "46/46 [==============================] - 9s 197ms/step - loss: 6426.1028 - reconstruction_loss: 6367.5381 - kl_loss: 33.8504\n",
      "Epoch 62/300\n",
      "46/46 [==============================] - 9s 198ms/step - loss: 6419.3890 - reconstruction_loss: 6366.6372 - kl_loss: 34.2294\n",
      "Epoch 63/300\n",
      "46/46 [==============================] - 9s 188ms/step - loss: 6397.5320 - reconstruction_loss: 6373.9946 - kl_loss: 33.6075\n",
      "Epoch 64/300\n",
      "46/46 [==============================] - 9s 192ms/step - loss: 6360.8043 - reconstruction_loss: 6362.9639 - kl_loss: 33.6915\n",
      "Epoch 65/300\n",
      "46/46 [==============================] - 9s 185ms/step - loss: 6403.8759 - reconstruction_loss: 6357.3252 - kl_loss: 33.3005\n",
      "Epoch 66/300\n",
      "46/46 [==============================] - 9s 192ms/step - loss: 6452.3310 - reconstruction_loss: 6367.2534 - kl_loss: 33.1608\n",
      "Epoch 67/300\n",
      "46/46 [==============================] - 9s 196ms/step - loss: 6317.8481 - reconstruction_loss: 6348.0776 - kl_loss: 33.8950\n",
      "Epoch 68/300\n",
      "46/46 [==============================] - 9s 205ms/step - loss: 6395.0467 - reconstruction_loss: 6354.3887 - kl_loss: 33.4398\n",
      "Epoch 69/300\n",
      "46/46 [==============================] - 9s 201ms/step - loss: 6424.8726 - reconstruction_loss: 6349.9189 - kl_loss: 33.4258\n",
      "Epoch 70/300\n",
      "46/46 [==============================] - 9s 188ms/step - loss: 6345.5157 - reconstruction_loss: 6344.5752 - kl_loss: 33.5058\n",
      "Epoch 71/300\n",
      "46/46 [==============================] - 9s 194ms/step - loss: 6404.6393 - reconstruction_loss: 6336.4707 - kl_loss: 34.0332\n",
      "Epoch 72/300\n",
      "46/46 [==============================] - 9s 200ms/step - loss: 6362.5196 - reconstruction_loss: 6333.7104 - kl_loss: 34.4827\n",
      "Epoch 73/300\n",
      "46/46 [==============================] - 9s 192ms/step - loss: 6363.7052 - reconstruction_loss: 6329.3140 - kl_loss: 34.4910\n",
      "Epoch 74/300\n",
      "46/46 [==============================] - 9s 203ms/step - loss: 6367.0491 - reconstruction_loss: 6327.3872 - kl_loss: 34.7717\n",
      "Epoch 75/300\n",
      "46/46 [==============================] - 9s 191ms/step - loss: 6347.9446 - reconstruction_loss: 6321.2427 - kl_loss: 35.2464\n",
      "Epoch 76/300\n",
      "46/46 [==============================] - 9s 185ms/step - loss: 6328.7121 - reconstruction_loss: 6319.2881 - kl_loss: 34.8680\n",
      "Epoch 77/300\n",
      "46/46 [==============================] - 9s 187ms/step - loss: 6369.9006 - reconstruction_loss: 6318.0654 - kl_loss: 35.2997\n",
      "Epoch 78/300\n",
      "46/46 [==============================] - 9s 187ms/step - loss: 6299.6232 - reconstruction_loss: 6313.8657 - kl_loss: 35.1455\n",
      "Epoch 79/300\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 6336.3719 - reconstruction_loss: 6310.7842 - kl_loss: 35.6699\n",
      "Epoch 80/300\n",
      "46/46 [==============================] - 8s 185ms/step - loss: 6395.9806 - reconstruction_loss: 6331.2061 - kl_loss: 34.8336\n",
      "Epoch 81/300\n",
      "46/46 [==============================] - 9s 187ms/step - loss: 6344.9406 - reconstruction_loss: 6308.3623 - kl_loss: 35.3042\n",
      "Epoch 82/300\n",
      "46/46 [==============================] - 9s 188ms/step - loss: 6339.4544 - reconstruction_loss: 6296.1680 - kl_loss: 35.5539\n",
      "Epoch 83/300\n",
      "46/46 [==============================] - 9s 185ms/step - loss: 6368.3589 - reconstruction_loss: 6290.1958 - kl_loss: 35.8598\n",
      "Epoch 84/300\n",
      "46/46 [==============================] - 9s 185ms/step - loss: 6291.1884 - reconstruction_loss: 6290.0820 - kl_loss: 35.8569\n",
      "Epoch 85/300\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 6304.1492 - reconstruction_loss: 6302.3320 - kl_loss: 35.5527\n",
      "Epoch 86/300\n",
      "46/46 [==============================] - 8s 182ms/step - loss: 6342.4534 - reconstruction_loss: 6287.6387 - kl_loss: 35.4210\n",
      "Epoch 87/300\n",
      "46/46 [==============================] - 9s 187ms/step - loss: 6346.3977 - reconstruction_loss: 6284.1011 - kl_loss: 35.7055\n",
      "Epoch 88/300\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 6326.1377 - reconstruction_loss: 6284.0938 - kl_loss: 35.5435\n",
      "Epoch 89/300\n",
      "46/46 [==============================] - 8s 180ms/step - loss: 6318.5422 - reconstruction_loss: 6304.1475 - kl_loss: 35.3018\n",
      "Epoch 90/300\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 6284.7933 - reconstruction_loss: 6276.0557 - kl_loss: 36.1818\n",
      "Epoch 91/300\n",
      "46/46 [==============================] - 9s 189ms/step - loss: 6295.9550 - reconstruction_loss: 6268.8755 - kl_loss: 35.9109\n",
      "Epoch 92/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6332.3891 - reconstruction_loss: 6271.2100 - kl_loss: 35.6065\n",
      "Epoch 93/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6269.3831 - reconstruction_loss: 6265.8999 - kl_loss: 35.8111\n",
      "Epoch 94/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6306.7097 - reconstruction_loss: 6261.0342 - kl_loss: 35.9709\n",
      "Epoch 95/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6279.1104 - reconstruction_loss: 6261.3003 - kl_loss: 35.4693\n",
      "Epoch 96/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6274.2504 - reconstruction_loss: 6259.2271 - kl_loss: 35.3158\n",
      "Epoch 97/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6299.8255 - reconstruction_loss: 6257.6650 - kl_loss: 35.7490\n",
      "Epoch 98/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6310.0640 - reconstruction_loss: 6251.8198 - kl_loss: 35.6573\n",
      "Epoch 99/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6316.6985 - reconstruction_loss: 6247.2563 - kl_loss: 35.8208\n",
      "Epoch 100/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6298.3580 - reconstruction_loss: 6252.1230 - kl_loss: 35.3290\n",
      "Epoch 101/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6290.7329 - reconstruction_loss: 6238.1836 - kl_loss: 35.6800\n",
      "Epoch 102/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6267.7455 - reconstruction_loss: 6242.2974 - kl_loss: 35.4130\n",
      "Epoch 103/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6291.9747 - reconstruction_loss: 6245.9512 - kl_loss: 35.4714\n",
      "Epoch 104/300\n",
      "46/46 [==============================] - 8s 181ms/step - loss: 6276.6229 - reconstruction_loss: 6236.1558 - kl_loss: 35.5007\n",
      "Epoch 105/300\n",
      "46/46 [==============================] - 8s 179ms/step - loss: 6251.7906 - reconstruction_loss: 6233.3179 - kl_loss: 35.3267\n",
      "Epoch 106/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6264.3100 - reconstruction_loss: 6226.5488 - kl_loss: 35.9327\n",
      "Epoch 107/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6219.8091 - reconstruction_loss: 6215.8086 - kl_loss: 35.8501\n",
      "Epoch 108/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6261.3860 - reconstruction_loss: 6223.8418 - kl_loss: 35.7333\n",
      "Epoch 109/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 8s 178ms/step - loss: 6232.0494 - reconstruction_loss: 6218.5210 - kl_loss: 35.8195\n",
      "Epoch 110/300\n",
      "46/46 [==============================] - 8s 181ms/step - loss: 6258.4732 - reconstruction_loss: 6230.6162 - kl_loss: 35.7121\n",
      "Epoch 111/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6254.7580 - reconstruction_loss: 6210.6758 - kl_loss: 35.4066\n",
      "Epoch 112/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6216.2639 - reconstruction_loss: 6203.3125 - kl_loss: 35.5164\n",
      "Epoch 113/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6227.7050 - reconstruction_loss: 6200.3501 - kl_loss: 35.0908\n",
      "Epoch 114/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6215.1326 - reconstruction_loss: 6205.6558 - kl_loss: 35.0005\n",
      "Epoch 115/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6204.7358 - reconstruction_loss: 6198.0591 - kl_loss: 34.6972\n",
      "Epoch 116/300\n",
      "46/46 [==============================] - 8s 179ms/step - loss: 6247.6668 - reconstruction_loss: 6196.0005 - kl_loss: 35.0041\n",
      "Epoch 117/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6241.3322 - reconstruction_loss: 6197.6528 - kl_loss: 35.1124\n",
      "Epoch 118/300\n",
      "46/46 [==============================] - 8s 185ms/step - loss: 6197.1603 - reconstruction_loss: 6191.8076 - kl_loss: 35.1764\n",
      "Epoch 119/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6152.5771 - reconstruction_loss: 6181.3369 - kl_loss: 35.1216\n",
      "Epoch 120/300\n",
      "46/46 [==============================] - 8s 181ms/step - loss: 6233.5391 - reconstruction_loss: 6185.4849 - kl_loss: 34.4644\n",
      "Epoch 121/300\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 6242.9214 - reconstruction_loss: 6194.4077 - kl_loss: 34.3006\n",
      "Epoch 122/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6182.3718 - reconstruction_loss: 6190.8130 - kl_loss: 34.5751\n",
      "Epoch 123/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6230.2063 - reconstruction_loss: 6181.5918 - kl_loss: 34.8448\n",
      "Epoch 124/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6258.0010 - reconstruction_loss: 6175.7061 - kl_loss: 34.7688\n",
      "Epoch 125/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6191.3922 - reconstruction_loss: 6172.1265 - kl_loss: 34.0725\n",
      "Epoch 126/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6196.7172 - reconstruction_loss: 6177.0811 - kl_loss: 34.0343\n",
      "Epoch 127/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6177.3451 - reconstruction_loss: 6193.2046 - kl_loss: 34.0196\n",
      "Epoch 128/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6216.8931 - reconstruction_loss: 6178.4370 - kl_loss: 34.1065\n",
      "Epoch 129/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6190.1776 - reconstruction_loss: 6158.5625 - kl_loss: 34.3968\n",
      "Epoch 130/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6200.9539 - reconstruction_loss: 6161.2656 - kl_loss: 33.8753\n",
      "Epoch 131/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6171.2504 - reconstruction_loss: 6158.2749 - kl_loss: 33.4293\n",
      "Epoch 132/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6138.5501 - reconstruction_loss: 6157.2095 - kl_loss: 34.5233\n",
      "Epoch 133/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6219.2691 - reconstruction_loss: 6162.4336 - kl_loss: 33.6229\n",
      "Epoch 134/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6190.2705 - reconstruction_loss: 6160.8555 - kl_loss: 33.7202\n",
      "Epoch 135/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6129.1910 - reconstruction_loss: 6154.2725 - kl_loss: 33.6492\n",
      "Epoch 136/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6199.6083 - reconstruction_loss: 6154.7896 - kl_loss: 33.8169\n",
      "Epoch 137/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6179.2208 - reconstruction_loss: 6143.8208 - kl_loss: 33.7278\n",
      "Epoch 138/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6177.5867 - reconstruction_loss: 6139.1406 - kl_loss: 33.5883\n",
      "Epoch 139/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6123.6537 - reconstruction_loss: 6142.0488 - kl_loss: 33.3152\n",
      "Epoch 140/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6176.7620 - reconstruction_loss: 6134.3716 - kl_loss: 33.2085\n",
      "Epoch 141/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6163.9696 - reconstruction_loss: 6127.5454 - kl_loss: 33.4861\n",
      "Epoch 142/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6185.4990 - reconstruction_loss: 6124.7568 - kl_loss: 33.0993\n",
      "Epoch 143/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6148.9684 - reconstruction_loss: 6131.1821 - kl_loss: 33.0075\n",
      "Epoch 144/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6181.5667 - reconstruction_loss: 6131.6650 - kl_loss: 33.1544\n",
      "Epoch 145/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6217.5218 - reconstruction_loss: 6127.6221 - kl_loss: 33.2155\n",
      "Epoch 146/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6134.2045 - reconstruction_loss: 6121.5186 - kl_loss: 33.1760\n",
      "Epoch 147/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6137.3161 - reconstruction_loss: 6120.6880 - kl_loss: 32.7755\n",
      "Epoch 148/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6145.1315 - reconstruction_loss: 6118.5918 - kl_loss: 32.4135\n",
      "Epoch 149/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6136.1425 - reconstruction_loss: 6116.1548 - kl_loss: 32.7246\n",
      "Epoch 150/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6191.6977 - reconstruction_loss: 6124.2573 - kl_loss: 32.8933\n",
      "Epoch 151/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6178.2967 - reconstruction_loss: 6106.8345 - kl_loss: 32.5743\n",
      "Epoch 152/300\n",
      "46/46 [==============================] - 8s 182ms/step - loss: 6138.0694 - reconstruction_loss: 6104.0400 - kl_loss: 32.4057\n",
      "Epoch 153/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6144.1206 - reconstruction_loss: 6109.8384 - kl_loss: 32.8511\n",
      "Epoch 154/300\n",
      "46/46 [==============================] - 8s 180ms/step - loss: 6176.1427 - reconstruction_loss: 6107.1421 - kl_loss: 32.5303\n",
      "Epoch 155/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6137.2603 - reconstruction_loss: 6107.1772 - kl_loss: 32.7540\n",
      "Epoch 156/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6101.2217 - reconstruction_loss: 6103.3799 - kl_loss: 32.2126\n",
      "Epoch 157/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6193.8453 - reconstruction_loss: 6117.4077 - kl_loss: 32.3427\n",
      "Epoch 158/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6157.6883 - reconstruction_loss: 6114.0020 - kl_loss: 32.3499\n",
      "Epoch 159/300\n",
      "46/46 [==============================] - 8s 180ms/step - loss: 6156.7278 - reconstruction_loss: 6103.3633 - kl_loss: 32.4192\n",
      "Epoch 160/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6112.5674 - reconstruction_loss: 6100.9585 - kl_loss: 32.4056\n",
      "Epoch 161/300\n",
      "46/46 [==============================] - 8s 179ms/step - loss: 6131.8088 - reconstruction_loss: 6106.4688 - kl_loss: 32.4791\n",
      "Epoch 162/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6146.3948 - reconstruction_loss: 6093.0659 - kl_loss: 32.3104\n",
      "Epoch 163/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6120.9373 - reconstruction_loss: 6087.6182 - kl_loss: 31.8878\n",
      "Epoch 164/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6100.7842 - reconstruction_loss: 6084.6411 - kl_loss: 31.8042\n",
      "Epoch 165/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6100.5647 - reconstruction_loss: 6085.6860 - kl_loss: 31.3951\n",
      "Epoch 166/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6132.2832 - reconstruction_loss: 6082.0542 - kl_loss: 31.9267\n",
      "Epoch 167/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6083.4814 - reconstruction_loss: 6077.7725 - kl_loss: 31.5642\n",
      "Epoch 168/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 8s 175ms/step - loss: 6122.5892 - reconstruction_loss: 6071.8711 - kl_loss: 31.6164\n",
      "Epoch 169/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6096.0947 - reconstruction_loss: 6087.2192 - kl_loss: 31.5232\n",
      "Epoch 170/300\n",
      "46/46 [==============================] - 8s 181ms/step - loss: 6143.3511 - reconstruction_loss: 6075.0127 - kl_loss: 32.1137\n",
      "Epoch 171/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6099.4211 - reconstruction_loss: 6072.0039 - kl_loss: 31.5709\n",
      "Epoch 172/300\n",
      "46/46 [==============================] - 8s 183ms/step - loss: 6143.3019 - reconstruction_loss: 6081.1982 - kl_loss: 31.3628\n",
      "Epoch 173/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6056.9828 - reconstruction_loss: 6069.6157 - kl_loss: 31.4002\n",
      "Epoch 174/300\n",
      "46/46 [==============================] - 8s 182ms/step - loss: 6131.8892 - reconstruction_loss: 6069.3071 - kl_loss: 31.3256\n",
      "Epoch 175/300\n",
      "46/46 [==============================] - 8s 181ms/step - loss: 6118.6124 - reconstruction_loss: 6061.9702 - kl_loss: 31.0977\n",
      "Epoch 176/300\n",
      "46/46 [==============================] - 8s 182ms/step - loss: 6083.9204 - reconstruction_loss: 6064.8843 - kl_loss: 31.2764\n",
      "Epoch 177/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6102.1652 - reconstruction_loss: 6066.2407 - kl_loss: 31.3092\n",
      "Epoch 178/300\n",
      "46/46 [==============================] - 8s 183ms/step - loss: 6085.6000 - reconstruction_loss: 6063.4937 - kl_loss: 31.5827\n",
      "Epoch 179/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6101.4438 - reconstruction_loss: 6054.0908 - kl_loss: 31.1031\n",
      "Epoch 180/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6100.1275 - reconstruction_loss: 6050.3525 - kl_loss: 31.0371\n",
      "Epoch 181/300\n",
      "46/46 [==============================] - 8s 181ms/step - loss: 6064.8209 - reconstruction_loss: 6047.7554 - kl_loss: 31.1658\n",
      "Epoch 182/300\n",
      "46/46 [==============================] - 8s 179ms/step - loss: 6057.4550 - reconstruction_loss: 6049.7437 - kl_loss: 30.8895\n",
      "Epoch 183/300\n",
      "46/46 [==============================] - 8s 181ms/step - loss: 6051.1269 - reconstruction_loss: 6052.1685 - kl_loss: 31.2492\n",
      "Epoch 184/300\n",
      "46/46 [==============================] - 8s 185ms/step - loss: 6099.0074 - reconstruction_loss: 6063.4185 - kl_loss: 31.2871\n",
      "Epoch 185/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6058.8046 - reconstruction_loss: 6057.7236 - kl_loss: 31.3472\n",
      "Epoch 186/300\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 6071.7804 - reconstruction_loss: 6045.0278 - kl_loss: 30.9533\n",
      "Epoch 187/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6103.7836 - reconstruction_loss: 6042.2676 - kl_loss: 30.9051\n",
      "Epoch 188/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6082.7344 - reconstruction_loss: 6045.3628 - kl_loss: 31.3251\n",
      "Epoch 189/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6107.0111 - reconstruction_loss: 6043.3232 - kl_loss: 31.1545\n",
      "Epoch 190/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6117.7878 - reconstruction_loss: 6035.0542 - kl_loss: 30.8703\n",
      "Epoch 191/300\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 6079.4972 - reconstruction_loss: 6039.0117 - kl_loss: 30.9321\n",
      "Epoch 192/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6054.1501 - reconstruction_loss: 6036.5244 - kl_loss: 31.0573\n",
      "Epoch 193/300\n",
      "46/46 [==============================] - 8s 182ms/step - loss: 6065.3793 - reconstruction_loss: 6033.6235 - kl_loss: 30.7887\n",
      "Epoch 194/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6072.7707 - reconstruction_loss: 6030.5850 - kl_loss: 30.6909\n",
      "Epoch 195/300\n",
      "46/46 [==============================] - 8s 179ms/step - loss: 6120.1644 - reconstruction_loss: 6028.8643 - kl_loss: 30.8480\n",
      "Epoch 196/300\n",
      "46/46 [==============================] - 8s 179ms/step - loss: 6032.5070 - reconstruction_loss: 6027.4097 - kl_loss: 30.5750\n",
      "Epoch 197/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6055.9678 - reconstruction_loss: 6037.3921 - kl_loss: 30.6569\n",
      "Epoch 198/300\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 6078.1732 - reconstruction_loss: 6031.9438 - kl_loss: 30.8268\n",
      "Epoch 199/300\n",
      "46/46 [==============================] - 8s 180ms/step - loss: 6063.5290 - reconstruction_loss: 6034.2290 - kl_loss: 31.0448\n",
      "Epoch 200/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6062.7495 - reconstruction_loss: 6037.5688 - kl_loss: 30.9626\n",
      "Epoch 201/300\n",
      "46/46 [==============================] - 8s 180ms/step - loss: 6090.2946 - reconstruction_loss: 6031.1499 - kl_loss: 31.0382\n",
      "Epoch 202/300\n",
      "46/46 [==============================] - 8s 183ms/step - loss: 6026.7988 - reconstruction_loss: 6025.6626 - kl_loss: 30.6595\n",
      "Epoch 203/300\n",
      "46/46 [==============================] - 8s 183ms/step - loss: 6013.1358 - reconstruction_loss: 6019.7764 - kl_loss: 30.8945\n",
      "Epoch 204/300\n",
      "46/46 [==============================] - 9s 189ms/step - loss: 6013.4843 - reconstruction_loss: 6015.7930 - kl_loss: 30.4505\n",
      "Epoch 205/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6080.4811 - reconstruction_loss: 6018.7676 - kl_loss: 30.4927\n",
      "Epoch 206/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6028.2583 - reconstruction_loss: 6014.9907 - kl_loss: 30.6219\n",
      "Epoch 207/300\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 6072.1346 - reconstruction_loss: 6015.3228 - kl_loss: 30.0022\n",
      "Epoch 208/300\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 6034.7683 - reconstruction_loss: 6023.4062 - kl_loss: 30.4421\n",
      "Epoch 209/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6014.5663 - reconstruction_loss: 6011.2236 - kl_loss: 30.1915\n",
      "Epoch 210/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6012.3707 - reconstruction_loss: 6009.1006 - kl_loss: 30.3928\n",
      "Epoch 211/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6030.2436 - reconstruction_loss: 6006.1113 - kl_loss: 30.0528\n",
      "Epoch 212/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6025.6736 - reconstruction_loss: 6011.1099 - kl_loss: 29.9938\n",
      "Epoch 213/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6076.7424 - reconstruction_loss: 6011.0381 - kl_loss: 30.0509\n",
      "Epoch 214/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6054.5175 - reconstruction_loss: 6016.1836 - kl_loss: 30.3485\n",
      "Epoch 215/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6037.3463 - reconstruction_loss: 6010.9951 - kl_loss: 30.1042\n",
      "Epoch 216/300\n",
      "46/46 [==============================] - 8s 180ms/step - loss: 6011.1985 - reconstruction_loss: 6003.7188 - kl_loss: 30.1961\n",
      "Epoch 217/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6040.2406 - reconstruction_loss: 5999.3262 - kl_loss: 30.0753\n",
      "Epoch 218/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6029.8979 - reconstruction_loss: 6000.2373 - kl_loss: 30.1254\n",
      "Epoch 219/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6004.1552 - reconstruction_loss: 5996.6025 - kl_loss: 30.2845\n",
      "Epoch 220/300\n",
      "46/46 [==============================] - 8s 182ms/step - loss: 6046.6400 - reconstruction_loss: 5999.7798 - kl_loss: 30.1208\n",
      "Epoch 221/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 5990.2106 - reconstruction_loss: 5999.2339 - kl_loss: 29.9946\n",
      "Epoch 222/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6048.2811 - reconstruction_loss: 6002.2080 - kl_loss: 29.9651\n",
      "Epoch 223/300\n",
      "46/46 [==============================] - 8s 180ms/step - loss: 6016.5487 - reconstruction_loss: 5994.9863 - kl_loss: 29.9533\n",
      "Epoch 224/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6002.0489 - reconstruction_loss: 5997.4336 - kl_loss: 29.9945\n",
      "Epoch 225/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 5980.2713 - reconstruction_loss: 5990.8418 - kl_loss: 30.2359\n",
      "Epoch 226/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6024.1362 - reconstruction_loss: 5984.3628 - kl_loss: 29.6682\n",
      "Epoch 227/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 9s 185ms/step - loss: 6026.5095 - reconstruction_loss: 5986.7588 - kl_loss: 29.7198\n",
      "Epoch 228/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6013.1917 - reconstruction_loss: 5996.4937 - kl_loss: 29.8291\n",
      "Epoch 229/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6006.9945 - reconstruction_loss: 5989.0698 - kl_loss: 29.9082\n",
      "Epoch 230/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 5998.0463 - reconstruction_loss: 5987.1846 - kl_loss: 29.8432\n",
      "Epoch 231/300\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 6002.8485 - reconstruction_loss: 5996.4595 - kl_loss: 29.7433\n",
      "Epoch 232/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6042.5099 - reconstruction_loss: 5990.8970 - kl_loss: 30.0435\n",
      "Epoch 233/300\n",
      "46/46 [==============================] - 8s 179ms/step - loss: 6024.4915 - reconstruction_loss: 5986.8110 - kl_loss: 29.5331\n",
      "Epoch 234/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6001.6458 - reconstruction_loss: 5985.3267 - kl_loss: 29.7240\n",
      "Epoch 235/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6022.7397 - reconstruction_loss: 5978.4380 - kl_loss: 29.5994\n",
      "Epoch 236/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6001.8935 - reconstruction_loss: 5977.3442 - kl_loss: 29.5630\n",
      "Epoch 237/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6000.2457 - reconstruction_loss: 5978.5083 - kl_loss: 29.4230\n",
      "Epoch 238/300\n",
      "46/46 [==============================] - 8s 181ms/step - loss: 6078.6853 - reconstruction_loss: 5983.3389 - kl_loss: 29.7810\n",
      "Epoch 239/300\n",
      "46/46 [==============================] - 8s 180ms/step - loss: 6020.3577 - reconstruction_loss: 5978.5654 - kl_loss: 29.7155\n",
      "Epoch 240/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 5989.5365 - reconstruction_loss: 5975.6333 - kl_loss: 29.6468\n",
      "Epoch 241/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6007.6594 - reconstruction_loss: 5973.4204 - kl_loss: 29.3416\n",
      "Epoch 242/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6018.7749 - reconstruction_loss: 5968.8369 - kl_loss: 29.5295\n",
      "Epoch 243/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 5968.3951 - reconstruction_loss: 5973.1147 - kl_loss: 29.2883\n",
      "Epoch 244/300\n",
      "46/46 [==============================] - 8s 180ms/step - loss: 5984.8121 - reconstruction_loss: 5974.3315 - kl_loss: 29.1297\n",
      "Epoch 245/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6030.3039 - reconstruction_loss: 5984.3418 - kl_loss: 29.5609\n",
      "Epoch 246/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6013.8424 - reconstruction_loss: 5981.7690 - kl_loss: 29.4938\n",
      "Epoch 247/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 5997.7610 - reconstruction_loss: 5970.9722 - kl_loss: 29.5537\n",
      "Epoch 248/300\n",
      "46/46 [==============================] - 8s 179ms/step - loss: 6013.2272 - reconstruction_loss: 5979.2329 - kl_loss: 29.7732\n",
      "Epoch 249/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6032.3191 - reconstruction_loss: 5972.8682 - kl_loss: 29.0951\n",
      "Epoch 250/300\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 5980.2276 - reconstruction_loss: 5970.0161 - kl_loss: 29.1459\n",
      "Epoch 251/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 5999.9897 - reconstruction_loss: 5964.9795 - kl_loss: 29.3443\n",
      "Epoch 252/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6018.6245 - reconstruction_loss: 5965.9897 - kl_loss: 29.2218\n",
      "Epoch 253/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 5981.0969 - reconstruction_loss: 5959.6025 - kl_loss: 28.9513\n",
      "Epoch 254/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6009.3940 - reconstruction_loss: 5965.1528 - kl_loss: 29.0762\n",
      "Epoch 255/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6003.3547 - reconstruction_loss: 5959.0186 - kl_loss: 29.1376\n",
      "Epoch 256/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 5964.8933 - reconstruction_loss: 5958.5576 - kl_loss: 28.9560\n",
      "Epoch 257/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6011.6484 - reconstruction_loss: 5956.8003 - kl_loss: 28.7996\n",
      "Epoch 258/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6028.9559 - reconstruction_loss: 5959.9082 - kl_loss: 28.8963\n",
      "Epoch 259/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6052.3367 - reconstruction_loss: 5967.2817 - kl_loss: 29.1293\n",
      "Epoch 260/300\n",
      "46/46 [==============================] - 8s 180ms/step - loss: 5990.8210 - reconstruction_loss: 5959.9683 - kl_loss: 29.1345\n",
      "Epoch 261/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6049.4260 - reconstruction_loss: 5953.9751 - kl_loss: 29.0317\n",
      "Epoch 262/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6000.8311 - reconstruction_loss: 5954.7026 - kl_loss: 28.8943\n",
      "Epoch 263/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 5994.7162 - reconstruction_loss: 5957.5576 - kl_loss: 28.7828\n",
      "Epoch 264/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 5976.8214 - reconstruction_loss: 5955.3042 - kl_loss: 28.6509\n",
      "Epoch 265/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6036.8529 - reconstruction_loss: 5955.7085 - kl_loss: 28.7886\n",
      "Epoch 266/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 5999.5729 - reconstruction_loss: 5953.0562 - kl_loss: 28.6505\n",
      "Epoch 267/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 5975.4285 - reconstruction_loss: 5953.4458 - kl_loss: 28.8661\n",
      "Epoch 268/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 5995.6785 - reconstruction_loss: 5959.3408 - kl_loss: 29.1183\n",
      "Epoch 269/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 5944.7690 - reconstruction_loss: 5956.6470 - kl_loss: 28.7617\n",
      "Epoch 270/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 5950.6014 - reconstruction_loss: 5952.4497 - kl_loss: 28.8535\n",
      "Epoch 271/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 5968.2850 - reconstruction_loss: 5944.2939 - kl_loss: 28.8991\n",
      "Epoch 272/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 5984.9432 - reconstruction_loss: 5950.8579 - kl_loss: 28.7048\n",
      "Epoch 273/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 5926.4228 - reconstruction_loss: 5947.9907 - kl_loss: 28.8186\n",
      "Epoch 274/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 5940.6784 - reconstruction_loss: 5941.5063 - kl_loss: 28.4712\n",
      "Epoch 275/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 5958.0636 - reconstruction_loss: 5946.4424 - kl_loss: 28.7190\n",
      "Epoch 276/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 5963.9308 - reconstruction_loss: 5941.2012 - kl_loss: 28.2136\n",
      "Epoch 277/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 5963.7335 - reconstruction_loss: 5939.5664 - kl_loss: 28.2592\n",
      "Epoch 278/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 5963.8493 - reconstruction_loss: 5940.7842 - kl_loss: 28.4645\n",
      "Epoch 279/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 5953.5947 - reconstruction_loss: 5942.1021 - kl_loss: 28.1080\n",
      "Epoch 280/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 5988.9639 - reconstruction_loss: 5947.0029 - kl_loss: 28.5017\n",
      "Epoch 281/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 5956.7105 - reconstruction_loss: 5944.7866 - kl_loss: 28.5777\n",
      "Epoch 282/300\n",
      "46/46 [==============================] - 8s 181ms/step - loss: 5983.2030 - reconstruction_loss: 5938.4048 - kl_loss: 28.4728\n",
      "Epoch 283/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 5972.9838 - reconstruction_loss: 5936.1914 - kl_loss: 28.1560\n",
      "Epoch 284/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 5966.0225 - reconstruction_loss: 5935.8955 - kl_loss: 28.2277\n",
      "Epoch 285/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 5928.4098 - reconstruction_loss: 5933.3750 - kl_loss: 28.1501\n",
      "Epoch 286/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 8s 173ms/step - loss: 5935.4891 - reconstruction_loss: 5938.8643 - kl_loss: 28.4469\n",
      "Epoch 287/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 5954.3148 - reconstruction_loss: 5932.3545 - kl_loss: 28.3235\n",
      "Epoch 288/300\n",
      "46/46 [==============================] - 8s 182ms/step - loss: 5966.9329 - reconstruction_loss: 5933.1841 - kl_loss: 28.0797\n",
      "Epoch 289/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 5981.1561 - reconstruction_loss: 5930.0869 - kl_loss: 28.0591\n",
      "Epoch 290/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 5945.8413 - reconstruction_loss: 5935.9561 - kl_loss: 28.1981\n",
      "Epoch 291/300\n",
      "46/46 [==============================] - 8s 181ms/step - loss: 5963.7516 - reconstruction_loss: 5932.0542 - kl_loss: 28.2872\n",
      "Epoch 292/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 5954.8871 - reconstruction_loss: 5929.8525 - kl_loss: 27.9844\n",
      "Epoch 293/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 5927.7263 - reconstruction_loss: 5932.1445 - kl_loss: 27.9233\n",
      "Epoch 294/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 5945.6492 - reconstruction_loss: 5934.8110 - kl_loss: 28.0550\n",
      "Epoch 295/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 5968.6615 - reconstruction_loss: 5932.9302 - kl_loss: 28.2064\n",
      "Epoch 296/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 5988.7600 - reconstruction_loss: 5928.8472 - kl_loss: 27.8214\n",
      "Epoch 297/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 5943.1192 - reconstruction_loss: 5925.2969 - kl_loss: 27.7747\n",
      "Epoch 298/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 5980.7572 - reconstruction_loss: 5926.4546 - kl_loss: 27.9353\n",
      "Epoch 299/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 5971.8929 - reconstruction_loss: 5937.7749 - kl_loss: 27.8239\n",
      "Epoch 300/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6000.6418 - reconstruction_loss: 5938.0293 - kl_loss: 28.1385\n",
      "Epoch 1/300\n",
      "46/46 [==============================] - 18s 174ms/step - loss: 9844.1921 - reconstruction_loss: 8736.1719 - kl_loss: 2.3866\n",
      "Epoch 2/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 7143.4907 - reconstruction_loss: 7068.5127 - kl_loss: 21.5132\n",
      "Epoch 3/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6907.5109 - reconstruction_loss: 6870.2866 - kl_loss: 19.0451\n",
      "Epoch 4/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6813.2872 - reconstruction_loss: 6848.5630 - kl_loss: 14.9357\n",
      "Epoch 5/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6858.9329 - reconstruction_loss: 6850.1089 - kl_loss: 13.9988\n",
      "Epoch 6/300\n",
      "46/46 [==============================] - 8s 179ms/step - loss: 6889.8293 - reconstruction_loss: 6848.6670 - kl_loss: 13.5528\n",
      "Epoch 7/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6814.6893 - reconstruction_loss: 6834.2026 - kl_loss: 13.0721\n",
      "Epoch 8/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6874.3952 - reconstruction_loss: 6816.8315 - kl_loss: 15.5185\n",
      "Epoch 9/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6845.3020 - reconstruction_loss: 6786.3906 - kl_loss: 19.8953\n",
      "Epoch 10/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6727.5463 - reconstruction_loss: 6755.0083 - kl_loss: 20.7125\n",
      "Epoch 11/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6785.2372 - reconstruction_loss: 6742.9062 - kl_loss: 20.3166\n",
      "Epoch 12/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6727.7830 - reconstruction_loss: 6734.9355 - kl_loss: 20.5654\n",
      "Epoch 13/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6809.7267 - reconstruction_loss: 6735.7749 - kl_loss: 20.8792\n",
      "Epoch 14/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6741.0538 - reconstruction_loss: 6752.6123 - kl_loss: 20.6688\n",
      "Epoch 15/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6804.6495 - reconstruction_loss: 6736.1284 - kl_loss: 21.6409\n",
      "Epoch 16/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6737.2370 - reconstruction_loss: 6714.4448 - kl_loss: 21.6265\n",
      "Epoch 17/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6722.3191 - reconstruction_loss: 6704.0127 - kl_loss: 21.8402\n",
      "Epoch 18/300\n",
      "46/46 [==============================] - 8s 169ms/step - loss: 6727.8552 - reconstruction_loss: 6700.1074 - kl_loss: 22.7851\n",
      "Epoch 19/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6721.7415 - reconstruction_loss: 6680.7305 - kl_loss: 27.4672\n",
      "Epoch 20/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6624.6004 - reconstruction_loss: 6653.0903 - kl_loss: 28.4142\n",
      "Epoch 21/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6696.9692 - reconstruction_loss: 6645.3296 - kl_loss: 29.3693\n",
      "Epoch 22/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6664.6841 - reconstruction_loss: 6640.1436 - kl_loss: 29.5689\n",
      "Epoch 23/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6683.9628 - reconstruction_loss: 6634.2349 - kl_loss: 29.7093\n",
      "Epoch 24/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6639.4198 - reconstruction_loss: 6626.4565 - kl_loss: 31.3868\n",
      "Epoch 25/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6687.0737 - reconstruction_loss: 6623.9189 - kl_loss: 30.3988\n",
      "Epoch 26/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6592.6602 - reconstruction_loss: 6605.3911 - kl_loss: 31.8046\n",
      "Epoch 27/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6595.2157 - reconstruction_loss: 6596.5000 - kl_loss: 32.5263\n",
      "Epoch 28/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6653.2662 - reconstruction_loss: 6599.1099 - kl_loss: 33.3086\n",
      "Epoch 29/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6618.0615 - reconstruction_loss: 6579.0747 - kl_loss: 33.3969\n",
      "Epoch 30/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6605.6982 - reconstruction_loss: 6574.9253 - kl_loss: 33.7852\n",
      "Epoch 31/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6646.1364 - reconstruction_loss: 6564.4370 - kl_loss: 35.3975\n",
      "Epoch 32/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6615.7625 - reconstruction_loss: 6555.5107 - kl_loss: 36.0958\n",
      "Epoch 33/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6550.9373 - reconstruction_loss: 6559.5767 - kl_loss: 36.0760\n",
      "Epoch 34/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6554.5480 - reconstruction_loss: 6548.7134 - kl_loss: 36.5582\n",
      "Epoch 35/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6607.0555 - reconstruction_loss: 6544.1099 - kl_loss: 37.1468\n",
      "Epoch 36/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6606.5649 - reconstruction_loss: 6533.8423 - kl_loss: 37.5301\n",
      "Epoch 37/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6616.0255 - reconstruction_loss: 6530.4985 - kl_loss: 37.4667\n",
      "Epoch 38/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6613.9731 - reconstruction_loss: 6513.0640 - kl_loss: 38.2811\n",
      "Epoch 39/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6606.8973 - reconstruction_loss: 6513.6064 - kl_loss: 38.6374\n",
      "Epoch 40/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6582.6846 - reconstruction_loss: 6505.7344 - kl_loss: 38.5276\n",
      "Epoch 41/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6570.7681 - reconstruction_loss: 6506.9995 - kl_loss: 37.7895\n",
      "Epoch 42/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6517.8334 - reconstruction_loss: 6494.5244 - kl_loss: 38.8498\n",
      "Epoch 43/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6556.7129 - reconstruction_loss: 6505.0093 - kl_loss: 38.5265\n",
      "Epoch 44/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6554.9208 - reconstruction_loss: 6490.8354 - kl_loss: 38.8086\n",
      "Epoch 45/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 8s 170ms/step - loss: 6487.2635 - reconstruction_loss: 6479.3594 - kl_loss: 39.4509\n",
      "Epoch 46/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6524.4627 - reconstruction_loss: 6488.4253 - kl_loss: 39.0103\n",
      "Epoch 47/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6466.0535 - reconstruction_loss: 6468.9092 - kl_loss: 39.4856\n",
      "Epoch 48/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6510.4293 - reconstruction_loss: 6473.0762 - kl_loss: 38.0539\n",
      "Epoch 49/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6545.9794 - reconstruction_loss: 6477.1133 - kl_loss: 38.8340\n",
      "Epoch 50/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6497.7235 - reconstruction_loss: 6474.3960 - kl_loss: 39.0140\n",
      "Epoch 51/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6465.6247 - reconstruction_loss: 6452.9189 - kl_loss: 39.4639\n",
      "Epoch 52/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6464.9310 - reconstruction_loss: 6453.9624 - kl_loss: 39.1250\n",
      "Epoch 53/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6479.5620 - reconstruction_loss: 6445.5342 - kl_loss: 39.6960\n",
      "Epoch 54/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6482.2923 - reconstruction_loss: 6450.7383 - kl_loss: 39.2260\n",
      "Epoch 55/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6485.8562 - reconstruction_loss: 6454.2280 - kl_loss: 38.7914\n",
      "Epoch 56/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6486.5561 - reconstruction_loss: 6452.0698 - kl_loss: 39.1356\n",
      "Epoch 57/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6437.5804 - reconstruction_loss: 6441.2603 - kl_loss: 38.3471\n",
      "Epoch 58/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6505.2904 - reconstruction_loss: 6435.8970 - kl_loss: 37.9310\n",
      "Epoch 59/300\n",
      "46/46 [==============================] - 9s 189ms/step - loss: 6457.1086 - reconstruction_loss: 6432.9502 - kl_loss: 38.3108\n",
      "Epoch 60/300\n",
      "46/46 [==============================] - 9s 192ms/step - loss: 6447.4684 - reconstruction_loss: 6427.1060 - kl_loss: 38.5384\n",
      "Epoch 61/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6502.4110 - reconstruction_loss: 6426.4985 - kl_loss: 38.2766\n",
      "Epoch 62/300\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 6466.2593 - reconstruction_loss: 6420.5884 - kl_loss: 38.4544\n",
      "Epoch 63/300\n",
      "46/46 [==============================] - 8s 181ms/step - loss: 6418.5176 - reconstruction_loss: 6416.0884 - kl_loss: 38.1347\n",
      "Epoch 64/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6517.5378 - reconstruction_loss: 6425.7656 - kl_loss: 38.3804\n",
      "Epoch 65/300\n",
      "46/46 [==============================] - 8s 179ms/step - loss: 6469.5545 - reconstruction_loss: 6405.0918 - kl_loss: 38.0641\n",
      "Epoch 66/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6428.5176 - reconstruction_loss: 6406.4370 - kl_loss: 38.0634\n",
      "Epoch 67/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6414.8754 - reconstruction_loss: 6405.9722 - kl_loss: 37.9897\n",
      "Epoch 68/300\n",
      "46/46 [==============================] - 8s 181ms/step - loss: 6479.3108 - reconstruction_loss: 6403.9102 - kl_loss: 37.4500\n",
      "Epoch 69/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6412.6106 - reconstruction_loss: 6393.7964 - kl_loss: 37.9015\n",
      "Epoch 70/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6412.1789 - reconstruction_loss: 6394.3262 - kl_loss: 37.9982\n",
      "Epoch 71/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6409.5525 - reconstruction_loss: 6393.2168 - kl_loss: 38.3637\n",
      "Epoch 72/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6456.7609 - reconstruction_loss: 6388.2710 - kl_loss: 38.4678\n",
      "Epoch 73/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6423.0777 - reconstruction_loss: 6382.4302 - kl_loss: 38.4344\n",
      "Epoch 74/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6402.1610 - reconstruction_loss: 6375.8813 - kl_loss: 38.1831\n",
      "Epoch 75/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6428.0090 - reconstruction_loss: 6385.2915 - kl_loss: 37.9004\n",
      "Epoch 76/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6439.0954 - reconstruction_loss: 6396.1562 - kl_loss: 38.2245\n",
      "Epoch 77/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6453.0756 - reconstruction_loss: 6370.4214 - kl_loss: 38.8044\n",
      "Epoch 78/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6365.2762 - reconstruction_loss: 6371.0908 - kl_loss: 38.3338\n",
      "Epoch 79/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6372.0672 - reconstruction_loss: 6360.7656 - kl_loss: 38.3511\n",
      "Epoch 80/300\n",
      "46/46 [==============================] - 8s 180ms/step - loss: 6406.5298 - reconstruction_loss: 6359.5986 - kl_loss: 38.3607\n",
      "Epoch 81/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6370.0445 - reconstruction_loss: 6350.9463 - kl_loss: 39.4408\n",
      "Epoch 82/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6367.1586 - reconstruction_loss: 6349.0562 - kl_loss: 38.7935\n",
      "Epoch 83/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6386.8944 - reconstruction_loss: 6360.7842 - kl_loss: 39.3753\n",
      "Epoch 84/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6434.6306 - reconstruction_loss: 6357.1577 - kl_loss: 38.5224\n",
      "Epoch 85/300\n",
      "46/46 [==============================] - 8s 179ms/step - loss: 6371.9390 - reconstruction_loss: 6345.9131 - kl_loss: 38.9586\n",
      "Epoch 86/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6400.6430 - reconstruction_loss: 6342.9707 - kl_loss: 38.7456\n",
      "Epoch 87/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6362.5294 - reconstruction_loss: 6344.8525 - kl_loss: 39.0236\n",
      "Epoch 88/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6337.6377 - reconstruction_loss: 6333.2690 - kl_loss: 39.6910\n",
      "Epoch 89/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6336.4352 - reconstruction_loss: 6342.9185 - kl_loss: 38.9245\n",
      "Epoch 90/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6404.0271 - reconstruction_loss: 6328.9404 - kl_loss: 39.1735\n",
      "Epoch 91/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6346.2567 - reconstruction_loss: 6328.8296 - kl_loss: 38.9211\n",
      "Epoch 92/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6323.2618 - reconstruction_loss: 6314.5332 - kl_loss: 39.4936\n",
      "Epoch 93/300\n",
      "46/46 [==============================] - 8s 181ms/step - loss: 6378.3257 - reconstruction_loss: 6323.7627 - kl_loss: 39.2043\n",
      "Epoch 94/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6326.5237 - reconstruction_loss: 6311.7373 - kl_loss: 39.4756\n",
      "Epoch 95/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6327.8991 - reconstruction_loss: 6317.4604 - kl_loss: 39.8508\n",
      "Epoch 96/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6401.2278 - reconstruction_loss: 6311.7065 - kl_loss: 39.6732\n",
      "Epoch 97/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6337.2622 - reconstruction_loss: 6309.8721 - kl_loss: 39.3205\n",
      "Epoch 98/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6374.0062 - reconstruction_loss: 6309.3491 - kl_loss: 39.8266\n",
      "Epoch 99/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6331.3160 - reconstruction_loss: 6295.3130 - kl_loss: 39.2156\n",
      "Epoch 100/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6329.7149 - reconstruction_loss: 6291.3369 - kl_loss: 39.8319\n",
      "Epoch 101/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6288.8347 - reconstruction_loss: 6293.0610 - kl_loss: 39.1766\n",
      "Epoch 102/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6357.9506 - reconstruction_loss: 6298.4751 - kl_loss: 39.3718\n",
      "Epoch 103/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6309.4008 - reconstruction_loss: 6305.3345 - kl_loss: 39.1226\n",
      "Epoch 104/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 8s 175ms/step - loss: 6329.6249 - reconstruction_loss: 6294.9585 - kl_loss: 39.5376\n",
      "Epoch 105/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6386.4059 - reconstruction_loss: 6285.4492 - kl_loss: 39.2779\n",
      "Epoch 106/300\n",
      "46/46 [==============================] - 8s 180ms/step - loss: 6338.3715 - reconstruction_loss: 6286.6870 - kl_loss: 39.2019\n",
      "Epoch 107/300\n",
      "46/46 [==============================] - 8s 180ms/step - loss: 6358.1278 - reconstruction_loss: 6276.7705 - kl_loss: 39.2126\n",
      "Epoch 108/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6353.4779 - reconstruction_loss: 6271.3657 - kl_loss: 39.6253\n",
      "Epoch 109/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6330.5527 - reconstruction_loss: 6277.7852 - kl_loss: 39.4954\n",
      "Epoch 110/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6305.8604 - reconstruction_loss: 6292.6802 - kl_loss: 39.1644\n",
      "Epoch 111/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6314.9672 - reconstruction_loss: 6279.7173 - kl_loss: 38.9054\n",
      "Epoch 112/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6360.3578 - reconstruction_loss: 6266.3887 - kl_loss: 39.4719\n",
      "Epoch 113/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6279.4607 - reconstruction_loss: 6261.0522 - kl_loss: 38.7472\n",
      "Epoch 114/300\n",
      "46/46 [==============================] - 8s 182ms/step - loss: 6318.8545 - reconstruction_loss: 6255.7471 - kl_loss: 39.1392\n",
      "Epoch 115/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6252.7203 - reconstruction_loss: 6257.2827 - kl_loss: 39.4464\n",
      "Epoch 116/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6309.5563 - reconstruction_loss: 6256.9526 - kl_loss: 39.2047\n",
      "Epoch 117/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6243.7228 - reconstruction_loss: 6241.4771 - kl_loss: 39.1155\n",
      "Epoch 118/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6252.4762 - reconstruction_loss: 6248.3228 - kl_loss: 38.6020\n",
      "Epoch 119/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6321.0217 - reconstruction_loss: 6245.6284 - kl_loss: 39.4746\n",
      "Epoch 120/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6271.9103 - reconstruction_loss: 6241.8105 - kl_loss: 39.0125\n",
      "Epoch 121/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6308.8161 - reconstruction_loss: 6238.5088 - kl_loss: 39.4112\n",
      "Epoch 122/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6241.5968 - reconstruction_loss: 6228.9980 - kl_loss: 38.9043\n",
      "Epoch 123/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6257.1460 - reconstruction_loss: 6234.0801 - kl_loss: 39.0649\n",
      "Epoch 124/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6254.9301 - reconstruction_loss: 6223.8955 - kl_loss: 39.7093\n",
      "Epoch 125/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6259.9589 - reconstruction_loss: 6223.1123 - kl_loss: 39.4300\n",
      "Epoch 126/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6267.2113 - reconstruction_loss: 6233.0088 - kl_loss: 39.6119\n",
      "Epoch 127/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6290.6921 - reconstruction_loss: 6218.6567 - kl_loss: 39.9059\n",
      "Epoch 128/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6307.7627 - reconstruction_loss: 6220.6338 - kl_loss: 39.8334\n",
      "Epoch 129/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6284.8975 - reconstruction_loss: 6218.2070 - kl_loss: 39.9430\n",
      "Epoch 130/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6337.9311 - reconstruction_loss: 6221.8408 - kl_loss: 39.4997\n",
      "Epoch 131/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6309.9987 - reconstruction_loss: 6215.5435 - kl_loss: 39.4689\n",
      "Epoch 132/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6274.1296 - reconstruction_loss: 6219.1968 - kl_loss: 40.0707\n",
      "Epoch 133/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6240.9503 - reconstruction_loss: 6216.1611 - kl_loss: 40.0618\n",
      "Epoch 134/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6272.0582 - reconstruction_loss: 6209.6655 - kl_loss: 40.1329\n",
      "Epoch 135/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6265.6011 - reconstruction_loss: 6198.1514 - kl_loss: 40.0419\n",
      "Epoch 136/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6235.1485 - reconstruction_loss: 6190.7969 - kl_loss: 39.8875\n",
      "Epoch 137/300\n",
      "46/46 [==============================] - 8s 180ms/step - loss: 6240.8187 - reconstruction_loss: 6195.4233 - kl_loss: 40.0415\n",
      "Epoch 138/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6205.5152 - reconstruction_loss: 6185.4805 - kl_loss: 39.3172\n",
      "Epoch 139/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6273.6918 - reconstruction_loss: 6184.7842 - kl_loss: 39.8856\n",
      "Epoch 140/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6255.2035 - reconstruction_loss: 6188.8364 - kl_loss: 39.4415\n",
      "Epoch 141/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6237.9307 - reconstruction_loss: 6185.3647 - kl_loss: 40.0121\n",
      "Epoch 142/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6184.0246 - reconstruction_loss: 6184.1689 - kl_loss: 39.6070\n",
      "Epoch 143/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6205.7968 - reconstruction_loss: 6175.7314 - kl_loss: 40.2577\n",
      "Epoch 144/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6185.2341 - reconstruction_loss: 6165.3452 - kl_loss: 39.3233\n",
      "Epoch 145/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6233.9254 - reconstruction_loss: 6157.2480 - kl_loss: 39.2269\n",
      "Epoch 146/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6203.7640 - reconstruction_loss: 6173.5308 - kl_loss: 39.4676\n",
      "Epoch 147/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6242.8545 - reconstruction_loss: 6178.8159 - kl_loss: 39.1967\n",
      "Epoch 148/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6188.5940 - reconstruction_loss: 6172.9346 - kl_loss: 39.7863\n",
      "Epoch 149/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6186.7531 - reconstruction_loss: 6153.4448 - kl_loss: 39.4921\n",
      "Epoch 150/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6241.9062 - reconstruction_loss: 6158.3579 - kl_loss: 39.4606\n",
      "Epoch 151/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6173.4794 - reconstruction_loss: 6151.3267 - kl_loss: 39.3296\n",
      "Epoch 152/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6161.1799 - reconstruction_loss: 6155.2983 - kl_loss: 39.6022\n",
      "Epoch 153/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6175.0626 - reconstruction_loss: 6145.7852 - kl_loss: 39.3767\n",
      "Epoch 154/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6172.0984 - reconstruction_loss: 6147.7949 - kl_loss: 39.1454\n",
      "Epoch 155/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6213.5407 - reconstruction_loss: 6151.2661 - kl_loss: 38.6123\n",
      "Epoch 156/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6187.0508 - reconstruction_loss: 6140.7310 - kl_loss: 39.4459\n",
      "Epoch 157/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6233.3960 - reconstruction_loss: 6137.8682 - kl_loss: 38.9456\n",
      "Epoch 158/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6181.4583 - reconstruction_loss: 6136.3975 - kl_loss: 38.8918\n",
      "Epoch 159/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6165.8936 - reconstruction_loss: 6130.0693 - kl_loss: 38.7019\n",
      "Epoch 160/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6118.3432 - reconstruction_loss: 6126.7339 - kl_loss: 38.8410\n",
      "Epoch 161/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6116.2836 - reconstruction_loss: 6123.3320 - kl_loss: 38.5039\n",
      "Epoch 162/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6179.3233 - reconstruction_loss: 6131.1772 - kl_loss: 38.5065\n",
      "Epoch 163/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 8s 173ms/step - loss: 6153.1818 - reconstruction_loss: 6122.4238 - kl_loss: 38.8458\n",
      "Epoch 164/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6170.8476 - reconstruction_loss: 6122.6821 - kl_loss: 38.6682\n",
      "Epoch 165/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6171.3306 - reconstruction_loss: 6123.4717 - kl_loss: 38.4416\n",
      "Epoch 166/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6142.6132 - reconstruction_loss: 6112.9526 - kl_loss: 38.1019\n",
      "Epoch 167/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6140.3261 - reconstruction_loss: 6117.0186 - kl_loss: 38.6604\n",
      "Epoch 168/300\n",
      "46/46 [==============================] - 8s 177ms/step - loss: 6097.4982 - reconstruction_loss: 6121.5991 - kl_loss: 38.5580\n",
      "Epoch 169/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6212.4931 - reconstruction_loss: 6126.1479 - kl_loss: 38.5221\n",
      "Epoch 170/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6119.9986 - reconstruction_loss: 6115.6406 - kl_loss: 38.6098\n",
      "Epoch 171/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6160.2426 - reconstruction_loss: 6107.3125 - kl_loss: 38.5878\n",
      "Epoch 172/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6084.6011 - reconstruction_loss: 6097.4702 - kl_loss: 38.2606\n",
      "Epoch 173/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6177.0241 - reconstruction_loss: 6099.5537 - kl_loss: 38.4227\n",
      "Epoch 174/300\n",
      "46/46 [==============================] - 8s 181ms/step - loss: 6102.6715 - reconstruction_loss: 6095.5229 - kl_loss: 38.1676\n",
      "Epoch 175/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6156.6217 - reconstruction_loss: 6096.6440 - kl_loss: 38.1382\n",
      "Epoch 176/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6142.8404 - reconstruction_loss: 6100.0645 - kl_loss: 38.4754\n",
      "Epoch 177/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6161.4428 - reconstruction_loss: 6096.2202 - kl_loss: 38.3437\n",
      "Epoch 178/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6182.0165 - reconstruction_loss: 6128.5845 - kl_loss: 39.1409\n",
      "Epoch 179/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6163.0416 - reconstruction_loss: 6099.6182 - kl_loss: 38.8390\n",
      "Epoch 180/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6089.3304 - reconstruction_loss: 6081.4092 - kl_loss: 38.3139\n",
      "Epoch 181/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6103.6222 - reconstruction_loss: 6080.8921 - kl_loss: 38.3304\n",
      "Epoch 182/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6126.3535 - reconstruction_loss: 6079.4780 - kl_loss: 37.9985\n",
      "Epoch 183/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6094.2918 - reconstruction_loss: 6076.1665 - kl_loss: 37.6931\n",
      "Epoch 184/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6098.1732 - reconstruction_loss: 6076.1836 - kl_loss: 37.7759\n",
      "Epoch 185/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6108.3677 - reconstruction_loss: 6071.8838 - kl_loss: 38.0252\n",
      "Epoch 186/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6115.4241 - reconstruction_loss: 6074.3940 - kl_loss: 38.0029\n",
      "Epoch 187/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6094.8351 - reconstruction_loss: 6066.4653 - kl_loss: 37.7101\n",
      "Epoch 188/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6107.3904 - reconstruction_loss: 6070.3350 - kl_loss: 37.5533\n",
      "Epoch 189/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6119.5385 - reconstruction_loss: 6063.3564 - kl_loss: 37.6314\n",
      "Epoch 190/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 6100.3916 - reconstruction_loss: 6070.0815 - kl_loss: 37.9644\n",
      "Epoch 191/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6079.7304 - reconstruction_loss: 6063.2065 - kl_loss: 37.8532\n",
      "Epoch 192/300\n",
      "46/46 [==============================] - 8s 169ms/step - loss: 6102.7507 - reconstruction_loss: 6063.6475 - kl_loss: 38.1295\n",
      "Epoch 193/300\n",
      "46/46 [==============================] - 8s 169ms/step - loss: 6063.4983 - reconstruction_loss: 6061.2710 - kl_loss: 37.2634\n",
      "Epoch 194/300\n",
      "46/46 [==============================] - 8s 169ms/step - loss: 6108.4304 - reconstruction_loss: 6066.0752 - kl_loss: 38.2712\n",
      "Epoch 195/300\n",
      "46/46 [==============================] - 8s 169ms/step - loss: 6122.4353 - reconstruction_loss: 6061.8086 - kl_loss: 37.6467\n",
      "Epoch 196/300\n",
      "46/46 [==============================] - 8s 169ms/step - loss: 6057.3331 - reconstruction_loss: 6058.7305 - kl_loss: 38.1029\n",
      "Epoch 197/300\n",
      "46/46 [==============================] - 8s 169ms/step - loss: 6070.8077 - reconstruction_loss: 6050.4707 - kl_loss: 37.6989\n",
      "Epoch 198/300\n",
      "46/46 [==============================] - 8s 169ms/step - loss: 6077.0989 - reconstruction_loss: 6052.5039 - kl_loss: 37.5234\n",
      "Epoch 199/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6054.8378 - reconstruction_loss: 6053.0073 - kl_loss: 37.6511\n",
      "Epoch 200/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6039.6168 - reconstruction_loss: 6056.1011 - kl_loss: 37.5205\n",
      "Epoch 201/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6063.4061 - reconstruction_loss: 6049.1055 - kl_loss: 37.4712\n",
      "Epoch 202/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6089.8203 - reconstruction_loss: 6044.2461 - kl_loss: 37.4104\n",
      "Epoch 203/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6101.3788 - reconstruction_loss: 6044.7124 - kl_loss: 37.1725\n",
      "Epoch 204/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6084.1815 - reconstruction_loss: 6036.9033 - kl_loss: 36.8731\n",
      "Epoch 205/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6062.3232 - reconstruction_loss: 6040.4214 - kl_loss: 37.0400\n",
      "Epoch 206/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6118.5820 - reconstruction_loss: 6037.9565 - kl_loss: 37.2305\n",
      "Epoch 207/300\n",
      "46/46 [==============================] - 8s 169ms/step - loss: 6069.0568 - reconstruction_loss: 6041.6914 - kl_loss: 37.1456\n",
      "Epoch 208/300\n",
      "46/46 [==============================] - 8s 169ms/step - loss: 6075.9329 - reconstruction_loss: 6034.9614 - kl_loss: 36.8712\n",
      "Epoch 209/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6042.7929 - reconstruction_loss: 6034.5747 - kl_loss: 36.8082\n",
      "Epoch 210/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6098.1103 - reconstruction_loss: 6036.7002 - kl_loss: 36.8862\n",
      "Epoch 211/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6059.6022 - reconstruction_loss: 6030.5039 - kl_loss: 36.8242\n",
      "Epoch 212/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6080.5572 - reconstruction_loss: 6032.7847 - kl_loss: 37.0879\n",
      "Epoch 213/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6089.3508 - reconstruction_loss: 6030.6353 - kl_loss: 36.8525\n",
      "Epoch 214/300\n",
      "46/46 [==============================] - 8s 169ms/step - loss: 6101.6891 - reconstruction_loss: 6030.6265 - kl_loss: 36.5031\n",
      "Epoch 215/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6070.6274 - reconstruction_loss: 6025.4985 - kl_loss: 36.9193\n",
      "Epoch 216/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6051.1344 - reconstruction_loss: 6017.1494 - kl_loss: 36.3070\n",
      "Epoch 217/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6100.0955 - reconstruction_loss: 6021.7432 - kl_loss: 36.4021\n",
      "Epoch 218/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6046.9992 - reconstruction_loss: 6022.2568 - kl_loss: 36.7158\n",
      "Epoch 219/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 6039.8754 - reconstruction_loss: 6017.7002 - kl_loss: 36.5885\n",
      "Epoch 220/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6104.9231 - reconstruction_loss: 6018.7480 - kl_loss: 36.5215\n",
      "Epoch 221/300\n",
      "46/46 [==============================] - 8s 182ms/step - loss: 6053.4786 - reconstruction_loss: 6019.0225 - kl_loss: 36.5715\n",
      "Epoch 222/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 8s 179ms/step - loss: 6036.4445 - reconstruction_loss: 6014.7173 - kl_loss: 36.5860\n",
      "Epoch 223/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6081.6312 - reconstruction_loss: 6004.8501 - kl_loss: 36.1976\n",
      "Epoch 224/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6000.8773 - reconstruction_loss: 6008.4961 - kl_loss: 36.0562\n",
      "Epoch 225/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6044.1129 - reconstruction_loss: 6008.6597 - kl_loss: 36.3361\n",
      "Epoch 226/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6043.2357 - reconstruction_loss: 6002.4341 - kl_loss: 35.7094\n",
      "Epoch 227/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6059.6813 - reconstruction_loss: 6002.4761 - kl_loss: 36.3839\n",
      "Epoch 228/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6016.5081 - reconstruction_loss: 6002.7310 - kl_loss: 35.9017\n",
      "Epoch 229/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 6024.7406 - reconstruction_loss: 5999.5063 - kl_loss: 35.6865\n",
      "Epoch 230/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6040.1255 - reconstruction_loss: 6007.6733 - kl_loss: 36.1404\n",
      "Epoch 231/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6041.0571 - reconstruction_loss: 6004.3057 - kl_loss: 36.0862\n",
      "Epoch 232/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6037.8778 - reconstruction_loss: 6002.3853 - kl_loss: 36.4491\n",
      "Epoch 233/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6032.3959 - reconstruction_loss: 5997.0718 - kl_loss: 36.2583\n",
      "Epoch 234/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6033.4621 - reconstruction_loss: 6005.0610 - kl_loss: 35.8591\n",
      "Epoch 235/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 5990.7165 - reconstruction_loss: 6006.9839 - kl_loss: 35.9469\n",
      "Epoch 236/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6037.1210 - reconstruction_loss: 6002.3687 - kl_loss: 36.3640\n",
      "Epoch 237/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6014.0387 - reconstruction_loss: 6003.8525 - kl_loss: 36.6667\n",
      "Epoch 238/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6034.5281 - reconstruction_loss: 5999.4985 - kl_loss: 36.0975\n",
      "Epoch 239/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6025.6194 - reconstruction_loss: 5995.1143 - kl_loss: 35.8766\n",
      "Epoch 240/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6026.0069 - reconstruction_loss: 5992.1357 - kl_loss: 36.1814\n",
      "Epoch 241/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6018.8379 - reconstruction_loss: 5992.2417 - kl_loss: 35.6996\n",
      "Epoch 242/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6045.0886 - reconstruction_loss: 5990.1265 - kl_loss: 35.8713\n",
      "Epoch 243/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6008.4295 - reconstruction_loss: 5981.5439 - kl_loss: 35.4618\n",
      "Epoch 244/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6008.7497 - reconstruction_loss: 5983.5776 - kl_loss: 35.4607\n",
      "Epoch 245/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6046.0726 - reconstruction_loss: 5986.3179 - kl_loss: 35.8560\n",
      "Epoch 246/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6043.2669 - reconstruction_loss: 5986.2876 - kl_loss: 35.7780\n",
      "Epoch 247/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6025.9604 - reconstruction_loss: 5984.0029 - kl_loss: 35.6253\n",
      "Epoch 248/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6002.2009 - reconstruction_loss: 5980.2114 - kl_loss: 35.7636\n",
      "Epoch 249/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 5998.7223 - reconstruction_loss: 5977.0264 - kl_loss: 35.2610\n",
      "Epoch 250/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6020.0412 - reconstruction_loss: 5978.3037 - kl_loss: 35.0517\n",
      "Epoch 251/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6048.6366 - reconstruction_loss: 5976.7583 - kl_loss: 35.1592\n",
      "Epoch 252/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6051.1385 - reconstruction_loss: 5979.4634 - kl_loss: 35.4539\n",
      "Epoch 253/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6033.8718 - reconstruction_loss: 5973.4561 - kl_loss: 35.5705\n",
      "Epoch 254/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6014.7197 - reconstruction_loss: 5975.5820 - kl_loss: 35.1477\n",
      "Epoch 255/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6023.2250 - reconstruction_loss: 5972.6357 - kl_loss: 35.0205\n",
      "Epoch 256/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6021.7716 - reconstruction_loss: 5973.3228 - kl_loss: 35.1247\n",
      "Epoch 257/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 5995.4026 - reconstruction_loss: 5984.3765 - kl_loss: 35.3087\n",
      "Epoch 258/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6046.8671 - reconstruction_loss: 5983.8511 - kl_loss: 35.6016\n",
      "Epoch 259/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6015.9241 - reconstruction_loss: 5971.3467 - kl_loss: 35.4032\n",
      "Epoch 260/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 5985.6050 - reconstruction_loss: 5970.5952 - kl_loss: 35.0111\n",
      "Epoch 261/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6049.0953 - reconstruction_loss: 5964.2583 - kl_loss: 34.7722\n",
      "Epoch 262/300\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 6024.4375 - reconstruction_loss: 5967.7275 - kl_loss: 34.9976\n",
      "Epoch 263/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6002.8025 - reconstruction_loss: 5965.9033 - kl_loss: 35.1340\n",
      "Epoch 264/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 5979.0721 - reconstruction_loss: 5963.9448 - kl_loss: 34.8611\n",
      "Epoch 265/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6039.1089 - reconstruction_loss: 5974.7065 - kl_loss: 34.9097\n",
      "Epoch 266/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 5959.8131 - reconstruction_loss: 5964.3765 - kl_loss: 34.8720\n",
      "Epoch 267/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 5992.2072 - reconstruction_loss: 5964.4653 - kl_loss: 34.9496\n",
      "Epoch 268/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 5937.4667 - reconstruction_loss: 5960.5063 - kl_loss: 34.4873\n",
      "Epoch 269/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6001.7766 - reconstruction_loss: 5961.7886 - kl_loss: 34.7647\n",
      "Epoch 270/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 5984.0473 - reconstruction_loss: 5961.4639 - kl_loss: 34.9970\n",
      "Epoch 271/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 6015.8485 - reconstruction_loss: 5956.2227 - kl_loss: 34.7209\n",
      "Epoch 272/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 5950.2535 - reconstruction_loss: 5960.2969 - kl_loss: 34.6373\n",
      "Epoch 273/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 5993.3225 - reconstruction_loss: 5959.3076 - kl_loss: 34.4380\n",
      "Epoch 274/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 5996.4102 - reconstruction_loss: 5952.3940 - kl_loss: 34.7425\n",
      "Epoch 275/300\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 5995.4150 - reconstruction_loss: 5950.9126 - kl_loss: 34.2626\n",
      "Epoch 276/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 5954.3497 - reconstruction_loss: 5948.2383 - kl_loss: 34.2447\n",
      "Epoch 277/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 5969.2584 - reconstruction_loss: 5950.0405 - kl_loss: 34.2941\n",
      "Epoch 278/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 5994.7959 - reconstruction_loss: 5953.4795 - kl_loss: 34.3416\n",
      "Epoch 279/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 5995.5557 - reconstruction_loss: 5954.9980 - kl_loss: 34.6587\n",
      "Epoch 280/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 5972.9953 - reconstruction_loss: 5953.8994 - kl_loss: 34.4590\n",
      "Epoch 281/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 8s 171ms/step - loss: 5960.2258 - reconstruction_loss: 5952.0835 - kl_loss: 34.3900\n",
      "Epoch 282/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 5987.1643 - reconstruction_loss: 5947.4058 - kl_loss: 34.2771\n",
      "Epoch 283/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 5948.4893 - reconstruction_loss: 5945.3784 - kl_loss: 34.4970\n",
      "Epoch 284/300\n",
      "46/46 [==============================] - 8s 176ms/step - loss: 5956.4871 - reconstruction_loss: 5946.4761 - kl_loss: 33.9594\n",
      "Epoch 285/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 5988.3210 - reconstruction_loss: 5946.1670 - kl_loss: 34.0548\n",
      "Epoch 286/300\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 5943.6698 - reconstruction_loss: 5946.0225 - kl_loss: 33.9683\n",
      "Epoch 287/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 5987.7636 - reconstruction_loss: 5943.0396 - kl_loss: 34.0871\n",
      "Epoch 288/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 5973.2196 - reconstruction_loss: 5938.6460 - kl_loss: 34.0887\n",
      "Epoch 289/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 6011.3065 - reconstruction_loss: 5941.3657 - kl_loss: 33.9712\n",
      "Epoch 290/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 5990.7226 - reconstruction_loss: 5949.2515 - kl_loss: 34.4448\n",
      "Epoch 291/300\n",
      "46/46 [==============================] - 8s 170ms/step - loss: 5967.6956 - reconstruction_loss: 5948.8159 - kl_loss: 34.6048\n",
      "Epoch 292/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 6009.2279 - reconstruction_loss: 5945.9478 - kl_loss: 34.3305\n",
      "Epoch 293/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6020.1005 - reconstruction_loss: 5944.1646 - kl_loss: 34.3970\n",
      "Epoch 294/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 5993.4819 - reconstruction_loss: 5947.5317 - kl_loss: 34.1305\n",
      "Epoch 295/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 5933.6773 - reconstruction_loss: 5940.2983 - kl_loss: 34.0292\n",
      "Epoch 296/300\n",
      "46/46 [==============================] - 8s 172ms/step - loss: 5964.3658 - reconstruction_loss: 5943.2935 - kl_loss: 34.1479\n",
      "Epoch 297/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 5994.8629 - reconstruction_loss: 5940.6133 - kl_loss: 33.8363\n",
      "Epoch 298/300\n",
      "46/46 [==============================] - 8s 174ms/step - loss: 5963.9838 - reconstruction_loss: 5938.7061 - kl_loss: 33.6714\n",
      "Epoch 299/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 6002.0737 - reconstruction_loss: 5936.3408 - kl_loss: 34.0257\n",
      "Epoch 300/300\n",
      "46/46 [==============================] - 8s 173ms/step - loss: 5997.8355 - reconstruction_loss: 5934.2217 - kl_loss: 33.4106\n"
     ]
    }
   ],
   "source": [
    "names = [\"CVAE_small_256\", \"CVAE_small_512\",\"CVAE_big_256\", \"CVAE_big_512\"]\n",
    "models = [cvae_small_256, cvae_small_512, cvae_big_256, cvae_big_512]\n",
    "histories = {}\n",
    "for model,name in zip(models, names):\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4))\n",
    "    history = model.fit([imgs_train, labels_train], epochs=300, batch_size=64)\n",
    "    histories[name] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d33b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = 33\n",
    "\n",
    "for model, model_name in zip(models, names):\n",
    "    fake_data = np.split(np.zeros(shape=imgs_train.shape), batches)\n",
    "    for i,(chunk_imgs, chunk_labels) in enumerate(zip(np.split(imgs_train, batches), np.split(labels_train, batches))):\n",
    "        _, _, z = model.encoder([chunk_imgs, chunk_labels])\n",
    "        z+=np.random.normal(0,1, size=z.shape)\n",
    "        fake_data[i] = model.decoder([z, chunk_labels])\n",
    "\n",
    "    fake_data = np.concatenate(fake_data)\n",
    "\n",
    "    with h5py.File(f\"data/{model_name}.h5\", \"w\") as out: # guardar data\n",
    "        out.create_dataset(\"X_train\", fake_data.shape, dtype=\"float32\", data=fake_data)\n",
    "        out.create_dataset(\"y_train\", labels_train.shape, dtype=\"u1\", data=labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b932494",
   "metadata": {},
   "source": [
    "Ahora solo falta correr el modelo de clasificación con los distintos datos fake y concluir al respecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc7ba80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
