{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b184bba",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0114c44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T00:09:38.644352062Z",
     "start_time": "2023-07-25T00:09:37.335828084Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Concatenate, Conv2D, Conv2DTranspose, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2350570",
   "metadata": {},
   "source": [
    " # CVAE simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e778b296",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41b6e3bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T00:09:42.444430902Z",
     "start_time": "2023-07-25T00:09:42.289505399Z"
    }
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "n_pixels = np.prod(X_train.shape[1:])\n",
    "X_train = X_train.reshape((len(X_train), n_pixels))\n",
    "X_test = X_test.reshape((len(X_test), n_pixels))\n",
    "y_train = to_categorical(Y_train)\n",
    "y_test = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ade0a",
   "metadata": {},
   "source": [
    "## Modelamiento\n",
    "### Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f1a0ffb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T00:09:45.493402415Z",
     "start_time": "2023-07-25T00:09:45.490103935Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 250 # batch size\n",
    "latent_dim = 2 # latent space size\n",
    "optim = Adam(lr=0.001)\n",
    "n_x = X_train.shape[1]\n",
    "n_y = y_train.shape[1]\n",
    "n_epoch = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64eb223",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167bdde6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T00:09:47.671909557Z",
     "start_time": "2023-07-25T00:09:47.626988733Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_inp1 = Input(shape=(n_x,), name=\"input_image\")\n",
    "encoder_inp2 = Input(shape=(n_y,), name=\"input_label\")\n",
    "enc_concat = Concatenate(name=\"encoder_concatenate\")([encoder_inp1, encoder_inp2])\n",
    "encoder_hidden = Dense(512, name=\"hidden_layer\")(enc_concat)\n",
    "mu = Dense(latent_dim, activation='linear', name=\"mu\")(encoder_hidden)\n",
    "l_sigma = Dense(latent_dim, activation='linear', name=\"l_sigma\")(encoder_hidden)\n",
    "def sample_z(args):\n",
    "    mu, l_sigma = args\n",
    "    eps = K.random_normal(shape=(latent_dim, ), mean=0., stddev=1.) # shape antes => (batch_size, latent_dim)\n",
    "    return mu + K.exp(l_sigma / 2) * eps\n",
    "z = Lambda(sample_z, output_shape = (latent_dim, ), name=\"latent_vector\")([mu, l_sigma]) # output encoder\n",
    "\n",
    "encoder = Model([encoder_inp1, encoder_inp2], z, name=\"encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0071648e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T00:09:49.136442778Z",
     "start_time": "2023-07-25T00:09:49.090928599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_image (InputLayer)       [(None, 784)]        0           []                               \n",
      "                                                                                                  \n",
      " input_label (InputLayer)       [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " encoder_concatenate (Concatena  (None, 794)         0           ['input_image[0][0]',            \n",
      " te)                                                              'input_label[0][0]']            \n",
      "                                                                                                  \n",
      " hidden_layer (Dense)           (None, 512)          407040      ['encoder_concatenate[0][0]']    \n",
      "                                                                                                  \n",
      " mu (Dense)                     (None, 2)            1026        ['hidden_layer[0][0]']           \n",
      "                                                                                                  \n",
      " l_sigma (Dense)                (None, 2)            1026        ['hidden_layer[0][0]']           \n",
      "                                                                                                  \n",
      " latent_vector (Lambda)         (None, 2)            0           ['mu[0][0]',                     \n",
      "                                                                  'l_sigma[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 409,092\n",
      "Trainable params: 409,092\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7875777a",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "148b2dca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T00:10:05.854191122Z",
     "start_time": "2023-07-25T00:10:05.788221284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_latent_vector (InputLaye  [(None, 2)]         0           []                               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " input_label (InputLayer)       [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " decoder_concat (Concatenate)   (None, 12)           0           ['input_latent_vector[0][0]',    \n",
      "                                                                  'input_label[0][0]']            \n",
      "                                                                                                  \n",
      " hidden_layer (Dense)           (None, 512)          6656        ['decoder_concat[0][0]']         \n",
      "                                                                                                  \n",
      " output_img (Dense)             (None, 784)          402192      ['hidden_layer[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 408,848\n",
      "Trainable params: 408,848\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_inp1 = Input(shape=(latent_dim), name=\"input_latent_vector\")\n",
    "decoder_inp2 = Input(shape=(n_y), name = \"input_label\")\n",
    "dec_concat = Concatenate(name=\"decoder_concat\")([decoder_inp1, decoder_inp2]) \n",
    "decoder_hidden = Dense(512, activation=\"relu\", name=\"hidden_layer\")(dec_concat)\n",
    "output = Dense(n_x, activation=\"sigmoid\", name=\"output_img\")(decoder_hidden) # output img\n",
    "decoder = Model([decoder_inp1, decoder_inp2], output, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7e48ae",
   "metadata": {},
   "source": [
    "### Conditional variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5672485c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T00:10:07.960312089Z",
     "start_time": "2023-07-25T00:10:07.916017349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CVAE\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_image (InputLayer)       [(None, 784)]        0           []                               \n",
      "                                                                                                  \n",
      " input_label (InputLayer)       [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " encoder (Functional)           (None, 2)            409092      ['input_image[0][0]',            \n",
      "                                                                  'input_label[0][0]']            \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, 784)          408848      ['encoder[0][0]',                \n",
      "                                                                  'input_label[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 817,940\n",
      "Trainable params: 817,940\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_vector = encoder(inputs=[encoder_inp1, encoder_inp2]) # z\n",
    "output_img = decoder(inputs=[latent_vector, encoder_inp2])\n",
    "CVAE = Model(inputs=[encoder_inp1, encoder_inp2], outputs=output_img, name=\"CVAE\")\n",
    "CVAE.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ff524a",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce9d492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(y_true, y_pred):\n",
    "    recon = recon_loss(y_true, y_pred)\n",
    "    kl = KL_loss(y_true, y_pred)\n",
    "    return recon + kl\n",
    "\n",
    "def KL_loss(y_true, y_pred): # it doesnt use y_true and y_pred but the parameters are necessary for compiling\n",
    "     # importante se usan las capas de mu y sigma del encoder\n",
    "\treturn(0.5 * K.sum(K.exp(l_sigma) + K.square(mu) - 1. - l_sigma, axis=1))\n",
    "\n",
    "def recon_loss(y_true, y_pred):\n",
    "\treturn K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6dddcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CVAE.compile(optimizer=optim, loss=vae_loss, metrics = [KL_loss, recon_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10db0db9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 22:55:11.054031: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 22:55:11.067620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 22:55:11.067760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 22:55:11.068600: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 22:55:11.068712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 22:55:11.068809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 22:55:11.396696: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 22:55:11.396829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 22:55:11.396928: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 22:55:11.397009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21981 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:2b:00.0, compute capability: 8.6\n",
      "2023-07-24 22:55:11.406536: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
      "2023-07-24 22:55:11.581090: W tensorflow/c/c_api.cc:300] Operation '{name:'training/Adam/hidden_layer/kernel/v/Assign' id:582 op device:{requested: '', assigned: ''} def:{{{node training/Adam/hidden_layer/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/hidden_layer/kernel/v, training/Adam/hidden_layer/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15250/60000 [======>.......................] - ETA: 1s - loss: 287.8974 - KL_loss: 25.0297 - recon_loss: 262.8677"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 22:55:12.146116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 18us/sample - loss: 206.4400 - KL_loss: 11.4040 - recon_loss: 195.0359 - val_loss: 162.4436 - val_KL_loss: 5.4989 - val_recon_loss: 156.9447\n",
      "Epoch 2/50\n",
      "11750/60000 [====>.........................] - ETA: 0s - loss: 159.3685 - KL_loss: 4.3008 - recon_loss: 155.0678"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 22:55:12.658880: W tensorflow/c/c_api.cc:300] Operation '{name:'loss/mul' id:278 op device:{requested: '', assigned: ''} def:{{{node loss/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss/mul/x, loss/decoder_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 8us/sample - loss: 154.7117 - KL_loss: 4.1734 - recon_loss: 150.5383 - val_loss: 153.9076 - val_KL_loss: 4.8231 - val_recon_loss: 149.0845\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 149.0221 - KL_loss: 4.2507 - recon_loss: 144.7714 - val_loss: 147.5599 - val_KL_loss: 3.8465 - val_recon_loss: 143.7134\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 146.7611 - KL_loss: 4.3960 - recon_loss: 142.3651 - val_loss: 145.2047 - val_KL_loss: 4.3860 - val_recon_loss: 140.8187\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 145.0302 - KL_loss: 4.2019 - recon_loss: 140.8284 - val_loss: 143.9234 - val_KL_loss: 4.4337 - val_recon_loss: 139.4897\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 144.2513 - KL_loss: 4.3571 - recon_loss: 139.8942 - val_loss: 143.5651 - val_KL_loss: 4.4770 - val_recon_loss: 139.0881\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 143.5775 - KL_loss: 4.2432 - recon_loss: 139.3342 - val_loss: 143.3332 - val_KL_loss: 3.5734 - val_recon_loss: 139.7598\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 143.3556 - KL_loss: 4.5008 - recon_loss: 138.8548 - val_loss: 142.9193 - val_KL_loss: 4.0219 - val_recon_loss: 138.8974\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 142.9339 - KL_loss: 4.6290 - recon_loss: 138.3048 - val_loss: 142.5357 - val_KL_loss: 3.9961 - val_recon_loss: 138.5395\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 142.2708 - KL_loss: 4.1487 - recon_loss: 138.1221 - val_loss: 144.7629 - val_KL_loss: 4.3313 - val_recon_loss: 140.4316\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 142.3318 - KL_loss: 4.3362 - recon_loss: 137.9956 - val_loss: 142.6940 - val_KL_loss: 4.8313 - val_recon_loss: 137.8627\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 141.5754 - KL_loss: 4.1289 - recon_loss: 137.4465 - val_loss: 141.3410 - val_KL_loss: 4.3550 - val_recon_loss: 136.9860\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 141.4468 - KL_loss: 4.2875 - recon_loss: 137.1594 - val_loss: 140.7912 - val_KL_loss: 3.9579 - val_recon_loss: 136.8333\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 141.2306 - KL_loss: 4.2195 - recon_loss: 137.0111 - val_loss: 141.4360 - val_KL_loss: 3.9583 - val_recon_loss: 137.4776\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 141.3811 - KL_loss: 4.4271 - recon_loss: 136.9541 - val_loss: 140.4525 - val_KL_loss: 4.4210 - val_recon_loss: 136.0315\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 141.0403 - KL_loss: 4.3893 - recon_loss: 136.6510 - val_loss: 142.3153 - val_KL_loss: 3.0877 - val_recon_loss: 139.2276\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 140.9140 - KL_loss: 4.2926 - recon_loss: 136.6215 - val_loss: 140.7682 - val_KL_loss: 4.8809 - val_recon_loss: 135.8872\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 140.8121 - KL_loss: 4.4045 - recon_loss: 136.4077 - val_loss: 141.2806 - val_KL_loss: 4.1157 - val_recon_loss: 137.1649\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 140.6029 - KL_loss: 4.3606 - recon_loss: 136.2423 - val_loss: 140.5449 - val_KL_loss: 3.7979 - val_recon_loss: 136.7470\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 140.5989 - KL_loss: 4.3988 - recon_loss: 136.2001 - val_loss: 140.2917 - val_KL_loss: 4.0934 - val_recon_loss: 136.1983\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 140.4978 - KL_loss: 4.3687 - recon_loss: 136.1291 - val_loss: 141.9959 - val_KL_loss: 5.3813 - val_recon_loss: 136.6146\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 140.2763 - KL_loss: 4.3624 - recon_loss: 135.9139 - val_loss: 139.8976 - val_KL_loss: 4.3268 - val_recon_loss: 135.5708\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 140.3364 - KL_loss: 4.5332 - recon_loss: 135.8032 - val_loss: 140.4828 - val_KL_loss: 4.4065 - val_recon_loss: 136.0764\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 140.5433 - KL_loss: 4.4553 - recon_loss: 136.0880 - val_loss: 139.7373 - val_KL_loss: 4.2785 - val_recon_loss: 135.4588\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 140.3784 - KL_loss: 4.3638 - recon_loss: 136.0146 - val_loss: 140.0504 - val_KL_loss: 4.2831 - val_recon_loss: 135.7673\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 139.9300 - KL_loss: 4.4458 - recon_loss: 135.4842 - val_loss: 140.8730 - val_KL_loss: 4.5825 - val_recon_loss: 136.2906\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 140.3099 - KL_loss: 4.5394 - recon_loss: 135.7705 - val_loss: 139.5639 - val_KL_loss: 4.0949 - val_recon_loss: 135.4690\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 140.2642 - KL_loss: 4.6703 - recon_loss: 135.5938 - val_loss: 141.0158 - val_KL_loss: 4.8607 - val_recon_loss: 136.1551\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 139.8436 - KL_loss: 4.4174 - recon_loss: 135.4262 - val_loss: 139.1756 - val_KL_loss: 4.2636 - val_recon_loss: 134.9120\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 0s 7us/sample - loss: 139.8060 - KL_loss: 4.4489 - recon_loss: 135.3570 - val_loss: 139.4606 - val_KL_loss: 4.4766 - val_recon_loss: 134.9840\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 139.9132 - KL_loss: 4.4987 - recon_loss: 135.4145 - val_loss: 139.8504 - val_KL_loss: 4.3607 - val_recon_loss: 135.4897\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 139.6171 - KL_loss: 4.3732 - recon_loss: 135.2439 - val_loss: 140.0117 - val_KL_loss: 4.1428 - val_recon_loss: 135.8689\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 139.7582 - KL_loss: 4.5754 - recon_loss: 135.1827 - val_loss: 139.8688 - val_KL_loss: 4.0400 - val_recon_loss: 135.8288\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 139.4468 - KL_loss: 4.4119 - recon_loss: 135.0350 - val_loss: 139.0125 - val_KL_loss: 4.4549 - val_recon_loss: 134.5576\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 8us/sample - loss: 139.7568 - KL_loss: 4.5195 - recon_loss: 135.2373 - val_loss: 139.2324 - val_KL_loss: 4.4960 - val_recon_loss: 134.7364\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 139.3792 - KL_loss: 4.4109 - recon_loss: 134.9684 - val_loss: 139.7779 - val_KL_loss: 4.4721 - val_recon_loss: 135.3058\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 139.5557 - KL_loss: 4.5280 - recon_loss: 135.0277 - val_loss: 139.2949 - val_KL_loss: 4.4216 - val_recon_loss: 134.8734\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 139.4777 - KL_loss: 4.4096 - recon_loss: 135.0682 - val_loss: 138.7318 - val_KL_loss: 4.2364 - val_recon_loss: 134.4954\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 139.8031 - KL_loss: 4.7697 - recon_loss: 135.0335 - val_loss: 139.8692 - val_KL_loss: 5.3173 - val_recon_loss: 134.5518\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 139.5053 - KL_loss: 4.4560 - recon_loss: 135.0493 - val_loss: 140.1355 - val_KL_loss: 4.9315 - val_recon_loss: 135.2039\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 139.2578 - KL_loss: 4.3832 - recon_loss: 134.8746 - val_loss: 139.8074 - val_KL_loss: 4.4354 - val_recon_loss: 135.3720\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 0s 8us/sample - loss: 139.1186 - KL_loss: 4.3177 - recon_loss: 134.8009 - val_loss: 139.4775 - val_KL_loss: 4.1763 - val_recon_loss: 135.3011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 139.4014 - KL_loss: 4.4712 - recon_loss: 134.9302 - val_loss: 139.0954 - val_KL_loss: 4.1776 - val_recon_loss: 134.9178\n"
     ]
    }
   ],
   "source": [
    "cvae_hist = CVAE.fit([X_train, y_train], X_train, verbose = 1, batch_size=batch_size, epochs=n_epoch,\n",
    "                      validation_data = ([X_test, y_test], X_test),\n",
    "                      callbacks = [EarlyStopping(patience = 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55068890",
   "metadata": {},
   "source": [
    "## Predicción\n",
    "\n",
    "Por defecto utilizamos un vector latente de ceros. Para variar el output se puede cambiar el vector latente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b53e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros(shape=(1, latent_dim)) # latent vector\n",
    "label = np.array([[0,1,0,0,0,0,0,0,0,0]]) # label in one hot encoding\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(decoder.predict([z, label]).reshape(28,28), cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9744d4bf",
   "metadata": {},
   "source": [
    " # CVAE con capas convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f9dff",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a5384",
   "metadata": {},
   "outputs": [],
   "source": [
    "(imgs_train, labels_train), (imgs_test, labels_test) = mnist.load_data()\n",
    "imgs_train = (imgs_train.astype('float32') / 255)[:, :, :, np.newaxis]\n",
    "imgs_test = (imgs_test.astype('float32') / 255)[:, :, :, np.newaxis]\n",
    "\n",
    "labels_train = to_categorical(labels_train)\n",
    "labels_test = to_categorical(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db110f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"image shape:\", imgs_train.shape[1:])\n",
    "print(\"n_cat shape:\", labels_train.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddfe036",
   "metadata": {},
   "source": [
    "## Modelamiento\n",
    "### Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf290c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 250 # batch size\n",
    "latent_dim = 2 # latent space size\n",
    "optim = Adam(lr=0.001)\n",
    "shape_img = imgs_train.shape[1:]\n",
    "n_cat = labels_train.shape[1]\n",
    "n_epoch = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9038f4d2",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input_image = Input(shape=(shape_img), name=\"input_image\")\n",
    "enc_input_label = Input(shape=(n_cat), name=\"input_label\")\n",
    "\n",
    "# convolutionals block\n",
    "conv1 = Conv2D(filters=32, kernel_size=3, strides=2, activation=\"relu\")(enc_input_image)\n",
    "conv2 = Conv2D(filters=64, kernel_size=3, strides=2, activation='relu')(conv1)\n",
    "\n",
    "# concat\n",
    "flattened = Flatten()(conv2)\n",
    "enc_concat = Concatenate()([flattened, enc_input_label])\n",
    "\n",
    "encoder_hidden = Dense(512, name=\"hidden_layer\")(enc_concat)\n",
    "mu = Dense(latent_dim, activation='linear', name=\"mu\")(encoder_hidden)\n",
    "l_sigma = Dense(latent_dim, activation='linear', name=\"l_sigma\")(encoder_hidden)\n",
    "def sample_z(args):\n",
    "    mu, l_sigma = args\n",
    "    eps = K.random_normal(shape=(latent_dim, ), mean=0., stddev=1.) # shape antes => (batch_size, latent_dim)\n",
    "    return mu + K.exp(l_sigma / 2) * eps\n",
    "z = Lambda(sample_z, output_shape = (latent_dim, ), name=\"latent_vector\")([mu, l_sigma]) # output encoder\n",
    "\n",
    "encoder = Model([enc_input_image, enc_input_label], z, name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976f82df",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e58de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_inp_latent_vector = Input(shape=(latent_dim), name=\"input_latent_vector\")\n",
    "decoder_inp_label = Input(shape=(n_cat), name = \"input_label\")\n",
    "dec_concat = Concatenate(name=\"decoder_concat\")([dec_inp_latent_vector, decoder_inp_label])\n",
    "\n",
    "decoder_hidden = Dense(512, activation=\"relu\", name=\"hidden_layer\")(dec_concat)\n",
    "decoder_hidden = Dense(7*7*32, activation=\"relu\", name=\"hidden_layer2\")(decoder_hidden)\n",
    "reshaped = Reshape(target_shape=(7,7,32))(decoder_hidden)\n",
    "\n",
    "# convolutionals block\n",
    "dec_conv1 = Conv2DTranspose(filters=64, kernel_size=3, strides=2, activation=\"relu\", padding='same')(reshaped)\n",
    "dec_conv2 = Conv2DTranspose(filters=32, kernel_size=3, strides=2, activation=\"relu\", padding='same')(dec_conv1)\n",
    "dec_output_img = Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same')(dec_conv2)\n",
    "dec_output_img = Flatten()(dec_output_img)\n",
    "decoder = Model([dec_inp_latent_vector, decoder_inp_label], dec_output_img, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186ae3e3",
   "metadata": {},
   "source": [
    "### Conditional Variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21647254",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vector = encoder(inputs=[enc_input_image, enc_input_label]) # z\n",
    "output_img = decoder(inputs=[latent_vector, enc_input_label])\n",
    "CVAE = Model(inputs=[enc_input_image, enc_input_label], outputs=output_img, name=\"CVAE\")\n",
    "CVAE.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f6aa1",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317a581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(y_true, y_pred):\n",
    "    recon = recon_loss(y_true, y_pred)\n",
    "    kl = KL_loss(y_true, y_pred)\n",
    "    return recon + kl\n",
    "\n",
    "def KL_loss(y_true, y_pred): # it doesnt use y_true and y_pred but the parameters are necessary for compiling\n",
    "     # importante se usan las capas de mu y sigma del encoder\n",
    "    return(0.5 * K.sum(K.exp(l_sigma) + K.square(mu) - 1. - l_sigma, axis=1))\n",
    "\n",
    "def recon_loss(y_true, y_pred):\n",
    "    return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db01a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "CVAE.compile(optimizer=optim, loss=vae_loss, metrics=[KL_loss, recon_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d053a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the output of the decoder is a flattened img, \n",
    "# so we need to flatten the true values (input images from (28,28,1) => 784)\n",
    "y_train = imgs_train.reshape(imgs_train.shape[0], -1)\n",
    "y_test = imgs_test.reshape(imgs_test.shape[0], -1)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29281cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cvae_hist = CVAE.fit([imgs_train, labels_train], y_train, verbose = 1, batch_size=batch_size, epochs=n_epoch,\n",
    "                      validation_data = ([imgs_test, labels_test], y_test),\n",
    "                      callbacks = [EarlyStopping(patience = 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc4e6c7",
   "metadata": {},
   "source": [
    "## Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros(shape=(1, latent_dim))  # latent vector\n",
    "label = np.array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])  # label in one hot encoding\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(decoder.predict([z, label]).reshape(28, 28), cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4090cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data science",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
